{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c67a3ba92fa1b",
   "metadata": {},
   "source": [
    "# Part A: Build a code understanding model. Upload your own custom code files to the model and ask questions based on the code file as context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c36582a0-d970-447d-a000-341dba4bf1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5c9f62b-cb66-40ff-8a31-90942f2524e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "encoded_key = \"c2stcHJvai1taDlMZEZteThyV1g2OW04bjYyb1QzQmxia0ZKRUVwbjZYVnFhU3BKUVBvdkhHSVM=\"\n",
    "api_key = base64.b64decode(encoded_key).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03f6c271262f5ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T02:23:19.283699Z",
     "start_time": "2024-05-06T02:23:19.270937Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "print(openai.__version__)\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40901cadee3209b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T02:40:31.183233Z",
     "start_time": "2024-05-06T02:40:31.124871Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am a language model AI created by OpenAI. I am here to assist you with any questions or tasks you may have. How can I help you today?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask_gpt(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    This method will make a API call to the OPEN-AI server and get the response.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "ask_gpt(\"who are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ef4224ffff17ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_gpt_with_context(prompt, model=\"gpt-3.5-turbo\", context=None):\n",
    "    \"\"\"\n",
    "    This method talk to OPEN-AI server and also update the context with the\n",
    "    communication and keep all the communication and context at one place, which\n",
    "    can be later used for  queries.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    if context:\n",
    "        messages.extend(context)\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"], messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "819962b8-94f6-4b66-a739-401e8366b6c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "code = \"https://raw.githubusercontent.com/anjali-ojha/customer_segmentation/main/scripts/data_ingestion.py\"\n",
    "\n",
    "questions = [\n",
    "    \"Load data from website - https://raw.githubusercontent.com/anjali-ojha/customer_segmentation/main/scripts/data_ingestion.py\",\n",
    "    \"what language this code written\",\n",
    "    \"what it do?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b7b3537-eae6-45e6-90a2-0f8728d5116d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User : Load data from website - https://raw.githubusercontent.com/anjali-ojha/customer_segmentation/main/scripts/data_ingestion.py\n",
      "\n",
      "Assistant: e kafka topic.\n",
      "        it also performs the transformation on the data, by converting the json string to the dataframe.\n",
      "        \"\"\"\n",
      "        topicName = \"reviews\"\n",
      "        stream_df = self.read_from_topic(spark, topicName)\n",
      "        schema = StructType([\n",
      "            StructField(\"business_id\", StringType(), True),\n",
      "            StructField(\"cool\", LongType(), True),\n",
      "            StructField(\"date\", StringType(), True),\n",
      "            StructField(\"funny\", LongType(), True),\n",
      "            StructField(\"review_id\", StringType(), True),\n",
      "            StructField(\"stars\", DoubleType(), True),\n",
      "            StructField(\"text\", StringType(), True),\n",
      "            StructField(\"useful\", LongType(), True),\n",
      "            StructField(\"user_id\", StringType(), True),\n",
      "        ])\n",
      "        df_result = stream_df.select(from_json(col(\"json_string\"), schema).alias(\"data\"))\n",
      "        self.write_stream(df_result, topicName)\n",
      "\n",
      "    def process_review_data(self, spark):\n",
      "        \"\"\"\n",
      "        This method will process the review data stream.\n",
      "        it will read the data from the kafka topic, perform transformations,\n",
      "        sentiment analysis, tokenization, and write the data to parquet files.\n",
      "        \"\"\"\n",
      "        topicName = \"reviews\"\n",
      "        stream_df = self.read_from_topic(spark, topicName)\n",
      "        schema = StructType([\n",
      "            StructField(\"business_id\", StringType(), True),\n",
      "            StructField(\"cool\", LongType(), True),\n",
      "            StructField(\"date\", StringType(), True),\n",
      "            StructField(\"funny\", LongType(), True),\n",
      "            StructField(\"review_id\", StringType(), True),\n",
      "            StructField(\"stars\", DoubleType(), True),\n",
      "            StructField(\"text\", StringType(), True),\n",
      "            StructField(\"useful\", LongType(), True),\n",
      "            StructField(\"user_id\", StringType(), True),\n",
      "        ])\n",
      "        df_result = stream_df.select(from_json(col(\"json_string\"), schema).alias(\"data\"))\n",
      "\n",
      "        df_result = df_result \\\n",
      "            .withColumn(\"date\", col(\"data.date\").cast(\"timestamp\")) \\\n",
      "            .withColumn(\"sentiment\", get_sentiment(col(\"data.text\"))) \\\n",
      "            .withColumn(\"frequent_words\", tokenize_and_get_top_words(col(\"data.text\")))\n",
      "\n",
      "        df_result.printSchema()\n",
      "        df_result.repartition(1).write.mode(\"append\").parquet(f\"{self.output_path}/{topicName}/data\")\n",
      "```\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "User : what language this code written\n",
      "\n",
      "Assistant: This code is written in Python.\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "User : what it do?\n",
      "\n",
      "Assistant: This code defines a class called `Consumer` that is responsible for consuming data from a Kafka topic and writing it to Parquet files. The class performs various transformations on the data while writing to the Parquet files. It also includes methods for reading different types of data (checkins, tips, reviews) from Kafka topics, processing the review data batch by batch, performing sentiment analysis, tokenizing words, and writing the processed data to Parquet files.\n",
      "\n",
      "Here is a summary of what the code does:\n",
      "1. Reads data from a Kafka topic and converts the JSON string to a DataFrame.\n",
      "2. Writes the stream data to Parquet files in append mode with a trigger to write data every 10 seconds.\n",
      "3. Reads checkins and tips data from Kafka topics, performs transformations, and writes the data to Parquet files.\n",
      "4. Processes review data batch by batch, performs sentiment analysis, tokenizes words, and writes the processed data to Parquet files.\n",
      "5. Reads review data from a Kafka topic, performs transformations, sentiment analysis, tokenization, and writes the data to Parquet files.\n",
      "\n",
      "Overall, the `Consumer` class is designed to handle the ingestion, processing, and storage of streaming data from Kafka topics using Apache Spark.\n",
      "\n",
      "------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running a sequence of the questions though the GPT server.\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_website_text(website_url):\n",
    "    \"\"\" This method will read the webpage fromn the link and return the content of it.\"\"\"\n",
    "    response = requests.get(website_url)\n",
    "    website_text = response.content\n",
    "    return website_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "context = None\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nUser : {question}\")\n",
    "    question = question.strip()\n",
    "\n",
    "    if question.lower().startswith(\"load\"):\n",
    "\n",
    "        extra_data = \"\"\n",
    "        web_url = [x for x in question.split(\" \") if x.startswith(\"https://\")][0]\n",
    "        # print(\"url = \", web_url)\n",
    "        website_data = extract_website_text(web_url)\n",
    "        extra_data = website_data[:5000]\n",
    "        # print(f\"{extra_data = }\")\n",
    "        question = f\"\"\" remember the data\n",
    "\n",
    "        ```{extra_data}```\n",
    "        \"\"\"\n",
    "\n",
    "    else:\n",
    "        question = question\n",
    "\n",
    "    # print(question)\n",
    "    response, new_context = ask_gpt_with_context(question, context=context)\n",
    "    new_context.append({\"role\": \"assistant\", \"content\" : response})\n",
    "    context = new_context\n",
    "\n",
    "    print(f\"\\nAssistant: {response}\")\n",
    "    print(\"\\n------------------------------------\\n\")\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4b94992e8378f",
   "metadata": {},
   "source": [
    "# Part B: Write a chatbot prompt to iteratively create a sequence of chats on one particular custom data.\n",
    "1. The chatbot should be able to answer the questions based on the text data or multiple documents.\n",
    "2. The chatbot should save the conversation in the memory.\n",
    "2. Summarize the chats at the end of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae913ffd-19e0-4782-90d5-6ea2f7bdfc23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hims/anaconda3/envs/python310/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=openai.api_key, temperature=0.0)\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b740109-9ead-4b27-8d57-e0fb4f631eda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human : Hi, my name is Anjali, and Who are you?\n",
      "\n",
      "AI    : Hello Anjali! I am an AI assistant designed to help answer your questions and provide information. My name is Assistant. How can I assist you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = conversation.predict(input=\"Hi, my name is Anjali, and Who are you?\")\n",
    "resp = memory.chat_memory.messages[-1].content\n",
    "print(f\"\"\"\n",
    "Human : {memory.chat_memory.messages[-2].content}\n",
    "\n",
    "AI    : {resp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30967e32-447d-42c9-a110-28e01dee8afc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have remembered the context provided. How can I assist you with the information from the context?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_website_text(website_urls):\n",
    "    \"\"\" This method will read the webpage fromn the link and return the content of it.\"\"\"\n",
    "    res = []\n",
    "    for website_url in website_urls:\n",
    "        response = requests.get(website_url)\n",
    "        # website_text = response.content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        website_text = '\\n'.join([p.get_text() for p in soup.find_all('p')])\n",
    "        res.append(website_text)\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "knowledge_base = extract_website_text([\"https://medium.com/@jheltzer/travel-guide-yosemite-national-park-2e83c8d6c2e9\", \"https://medium.com/@alissaalterishea/mount-rainier-national-park-washington-fe29c7dc1510\"])\n",
    "\n",
    "source_knowledge = \"\\n\".join(knowledge_base)\n",
    "\n",
    "context = f\"\"\"Rememer this context given in ``` and answer all question using that when asked. Acknowledge once data remeberd. \n",
    "\n",
    "```{source_knowledge}```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "x = conversation.predict(input=context)\n",
    "memory.chat_memory.messages[-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84741ee1-fa07-4385-89c2-1a87735aaa99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human : Where is Yosemite located?\n",
      "\n",
      "AI    : Yosemite National Park is located in northeast California, east of the fertile San Joaquin Valley and just west of the border with Nevada. It is 167 miles straight east of San Francisco and covers almost 1,200 square miles.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"Where is Yosemite located?\")\n",
    "resp = memory.chat_memory.messages[-1].content\n",
    "print(f\"\"\"\n",
    "Human : {memory.chat_memory.messages[-2].content}\n",
    "\n",
    "AI    : {resp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "933cbb9a-9ded-49e5-9a28-5fdfde713cec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human : What are top locations in Yosemite?\n",
      "\n",
      "AI    : Some of the top locations in Yosemite National Park include Glacier Point, Tunnel View, Lower Yosemite Falls, El Capitan, Mariposa Grove, Olmsted Point, Half Dome, and the Valley Floor Loop Trail. These locations offer stunning views, waterfalls, rock formations, and opportunities for hiking and exploring the park.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"What are top locations in Yosemite?\")\n",
    "resp = memory.chat_memory.messages[-1].content\n",
    "print(f\"\"\"\n",
    "Human : {memory.chat_memory.messages[-2].content}\n",
    "\n",
    "AI    : {resp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f82035e2-8b25-46fb-9d14-4f08c2bc09e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human : Where is Mount Rainer Park located?\n",
      "\n",
      "AI    : Mount Rainier National Park is located in Washington state, just a couple of hours from Seattle. It is home to the tallest peak in the Cascade Range and is known for its active volcano, Mount Rainier.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"Where is Mount Rainer Park located?\")\n",
    "resp = memory.chat_memory.messages[-1].content\n",
    "print(f\"\"\"\n",
    "Human : {memory.chat_memory.messages[-2].content}\n",
    "\n",
    "AI    : {resp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95a59471-0ae2-416c-a698-f0682e4d6e49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human : Which is the famous trail for the mount rainer\n",
      "\n",
      "AI    : One of the famous trails in Mount Rainier National Park is the Skyline Trail, which offers rugged terrain, snow-capped peaks, glacier-clad slopes, fields of wildflowers, waterfalls, and stunning views. It is a steep 5.5 mile trek that is highly recommended for hikers and adventurers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"Which is the famous trail for the mount rainer\")\n",
    "resp = memory.chat_memory.messages[-1].content\n",
    "print(f\"\"\"\n",
    "Human : {memory.chat_memory.messages[-2].content}\n",
    "\n",
    "AI    : {resp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61e9ee0f-2f02-4377-b3ba-0df28fd9f48d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human : Which park is better?\n",
      "\n",
      "AI    : As an AI, I don't have personal preferences. Both Yosemite National Park and Mount Rainier National Park are unique and beautiful in their own ways. Yosemite is known for its iconic rock formations, waterfalls, and diverse landscapes, while Mount Rainier offers stunning views of an active volcano, glaciers, and wildflower-filled meadows. It ultimately depends on your preferences and what you're looking to experience in a national park.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"Which park is better?\")\n",
    "resp = memory.chat_memory.messages[-1].content\n",
    "print(f\"\"\"\n",
    "Human : {memory.chat_memory.messages[-2].content}\n",
    "\n",
    "AI    : {resp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f181be2-fbe6-400a-b39d-95fd2b02785c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human : Give me the whole conversation Summary?\n",
      "\n",
      "AI    : The conversation covered information about Yosemite National Park and Mount Rainier National Park. Yosemite is located in northeast California and covers almost 1,200 square miles, with top locations including Glacier Point, Tunnel View, Lower Yosemite Falls, El Capitan, and more. Mount Rainier National Park is located in Washington state, near Seattle, and features the Skyline Trail as a famous hiking destination. Both parks offer unique and beautiful landscapes for visitors to explore.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"Give me the whole conversation Summary?\")\n",
    "resp = memory.chat_memory.messages[-1].content\n",
    "print(f\"\"\"\n",
    "Human : {memory.chat_memory.messages[-2].content}\n",
    "\n",
    "AI    : {resp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fcc9c6d-8a13-445a-87ce-1ea178945657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hims/anaconda3/envs/python310/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The article provides tips and recommendations for visiting Yosemite National Park, including lodging options, transportation, and popular attractions\n",
      "\n",
      "It also discusses the challenges and highlights of various hiking trails in the park\n",
      "\n",
      "The writer also briefly mentions their visit to Mount Rainier National Park and their experience as a teacher, traveler, and outdoor enthusiast\n",
      "\n",
      "Both parks offer unique landscapes and popular hiking trails for visitors to enjoy.\n"
     ]
    }
   ],
   "source": [
    "# Create Conversation Summary\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def create_summary(memory):\n",
    "    llm = OpenAI(temperature=0, openai_api_key=openai.api_key)\n",
    "    \n",
    "    text = \"\\n\".join([x.content for x in memory.chat_memory.messages])\n",
    "    num_tokens = llm.get_num_tokens(text)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=5000, chunk_overlap=350)\n",
    "    docs = text_splitter.create_documents([text])\n",
    "\n",
    "    chain = load_summarize_chain(llm=llm, chain_type='map_reduce') \n",
    "    return chain.run(docs)\n",
    "\n",
    "summary = create_summary(memory)\n",
    "print(\"\\n\\n\".join(summary.replace(\"\\\\n\", \"\").split(\". \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f952f89d-1063-42e9-b550-07052a0a0c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
