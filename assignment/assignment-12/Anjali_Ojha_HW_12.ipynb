{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987aae86",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/anjali-ojha/deep-learning/blob/lab2/assignment/assignment-12/Anjali_Ojha_HW_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c67a3ba92fa1b",
   "metadata": {
    "id": "28c67a3ba92fa1b"
   },
   "source": [
    "GitHub Link -  https://github.com/anjali-ojha/deep-learning/blob/lab2/assignment/assignment-12/Anjali_Ojha_HW_12.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e803ef-edd1-44ab-a02e-e9587db1c135",
   "metadata": {
    "id": "26e803ef-edd1-44ab-a02e-e9587db1c135"
   },
   "source": [
    "# Part A: Build a code understanding model. Upload your own custom code files to the model and ask questions based on the code file as context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c9f62b-cb66-40ff-8a31-90942f2524e5",
   "metadata": {
    "id": "b5c9f62b-cb66-40ff-8a31-90942f2524e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "encoded_key = \"c2stcHJvai1hVDdXU1FEVTJPcFhIUFVSTDF4V1QzQmxia0ZKVnk2WjlQTU0wT0tZYm9lMEhOa1Q=\"\n",
    "api_key = base64.b64decode(encoded_key).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f6c271262f5ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T02:23:19.283699Z",
     "start_time": "2024-05-06T02:23:19.270937Z"
    },
    "id": "e03f6c271262f5ff",
    "outputId": "2813da0d-8bee-44f3-ad4b-9b531f4fb45c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "print(openai.__version__)\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40901cadee3209b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T02:40:31.183233Z",
     "start_time": "2024-05-06T02:40:31.124871Z"
    },
    "id": "40901cadee3209b9",
    "outputId": "f6ddbb20-1a5e-4bf1-ebc8-6927994eaa2b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am a language model AI created to assist and provide information to users. How can I help you today?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask_gpt(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    This method will make a API call to the OPEN-AI server and get the response.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "ask_gpt(\"who are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4224ffff17ab8",
   "metadata": {
    "id": "5ef4224ffff17ab8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_gpt_with_context(prompt, model=\"gpt-3.5-turbo\", context=None):\n",
    "    \"\"\"\n",
    "    This method talk to OPEN-AI server and also update the context with the\n",
    "    communication and keep all the communication and context at one place, which\n",
    "    can be later used for  queries.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    if context:\n",
    "        messages.extend(context)\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"], messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819962b8-94f6-4b66-a739-401e8366b6c2",
   "metadata": {
    "id": "819962b8-94f6-4b66-a739-401e8366b6c2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "code = \"https://raw.githubusercontent.com/anjali-ojha/customer_segmentation/main/scripts/data_ingestion.py\"\n",
    "\n",
    "questions = [\n",
    "    \"Load data from website - https://raw.githubusercontent.com/anjali-ojha/customer_segmentation/main/scripts/data_ingestion.py\",\n",
    "    \"what language this code written\",\n",
    "    \"what it do?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c8745a-e57e-449b-837c-2b61321876bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_website_text(website_url):\n",
    "    \"\"\" This method will read the webpage fromn the link and return the content of it.\"\"\"\n",
    "    response = requests.get(website_url)\n",
    "    website_text = response.content\n",
    "    return website_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b3537-eae6-45e6-90a2-0f8728d5116d",
   "metadata": {
    "id": "4b7b3537-eae6-45e6-90a2-0f8728d5116d",
    "outputId": "b63d6d28-4e62-4e56-bd48-6d0242791730",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User : Load data from website - https://raw.githubusercontent.com/anjali-ojha/customer_segmentation/main/scripts/data_ingestion.py\n",
      "\n",
      "Assistant: e kafka topic.\n",
      "        it also performs the transformation on the data, by converting the json string to the dataframe.\n",
      "        \"\"\"\n",
      "        topicName = \"reviews\"\n",
      "        stream_df = self.read_from_topic(spark, topicName)\n",
      "        schema = StructType([\n",
      "            StructField(\"business_id\", StringType(), True),\n",
      "            StructField(\"cool\", LongType(), True),\n",
      "            StructField(\"date\", StringType(), True),\n",
      "            StructField(\"funny\", LongType(), True),\n",
      "            StructField(\"review_id\", StringType(), True),\n",
      "            StructField(\"stars\", DoubleType(), True),\n",
      "            StructField(\"text\", StringType(), True),\n",
      "            StructField(\"useful\", LongType(), True),\n",
      "            StructField(\"user_id\", StringType(), True),\n",
      "        ])\n",
      "        df_result = stream_df.select(from_json(col(\"json_string\"), schema).alias(\"data\"))\n",
      "        self.write_stream(df_result, topicName)\n",
      "\n",
      "    def process_review_data(self, spark):\n",
      "        \"\"\"\n",
      "        This method will process the review data stream.\n",
      "        it will read the data from the kafka topic, perform transformations,\n",
      "        sentiment analysis, tokenization, and write the data to parquet files.\n",
      "        \"\"\"\n",
      "        topicName = \"reviews\"\n",
      "        stream_df = self.read_from_topic(spark, topicName)\n",
      "        schema = StructType([\n",
      "            StructField(\"business_id\", StringType(), True),\n",
      "            StructField(\"cool\", LongType(), True),\n",
      "            StructField(\"date\", StringType(), True),\n",
      "            StructField(\"funny\", LongType(), True),\n",
      "            StructField(\"review_id\", StringType(), True),\n",
      "            StructField(\"stars\", DoubleType(), True),\n",
      "            StructField(\"text\", StringType(), True),\n",
      "            StructField(\"useful\", LongType(), True),\n",
      "            StructField(\"user_id\", StringType(), True),\n",
      "        ])\n",
      "        df_result = stream_df.select(from_json(col(\"json_string\"), schema).alias(\"data\"))\n",
      "\n",
      "        df_result = df_result \\\n",
      "            .withColumn(\"date\", col(\"data.date\").cast(\"timestamp\")) \\\n",
      "            .withColumn(\"sentiment\", get_sentiment(col(\"data.text\"))) \\\n",
      "            .withColumn(\"frequent_words\", tokenize_and_get_top_words(col(\"data.text\")))\n",
      "\n",
      "        df_result.printSchema()\n",
      "        df_result.repartition(1).write.mode(\"append\").parquet(f\"{self.output_path}/{topicName}/data\")\n",
      "```\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "User : what language this code written\n",
      "\n",
      "Assistant: This code is written in Python.\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "User : what it do?\n",
      "\n",
      "Assistant: This code defines a class called `Consumer` that is responsible for consuming data from a Kafka topic and writing it to Parquet files. The class performs various transformations on the data while writing to the Parquet files. It also includes methods for reading different types of data (checkins, tips, reviews) from Kafka topics, processing the review data batch by batch, performing sentiment analysis, tokenizing words, and writing the processed data to Parquet files.\n",
      "\n",
      "Here is a summary of what the code does:\n",
      "1. Reads data from a Kafka topic and converts the JSON string to a DataFrame.\n",
      "2. Writes the stream data to Parquet files in append mode with a trigger to write data every 10 seconds.\n",
      "3. Reads checkins and tips data from Kafka topics, performs transformations, and writes the data to Parquet files.\n",
      "4. Processes review data batch by batch, performs sentiment analysis, tokenizes words, and writes the processed data to Parquet files.\n",
      "5. Reads review data from a Kafka topic, performs transformations, sentiment analysis, tokenization, and writes the data to Parquet files.\n",
      "\n",
      "Overall, the `Consumer` class is designed to consume streaming data from Kafka, perform various transformations and analyses on the data, and store the processed data in Parquet format.\n",
      "\n",
      "------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Going through the list of questions one by one\n",
    "\n",
    "context = None\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nUser : {question}\")\n",
    "    question = question.strip()\n",
    "\n",
    "    if question.lower().startswith(\"load\"):\n",
    "\n",
    "        extra_data = \"\"\n",
    "        web_url = [x for x in question.split(\" \") if x.startswith(\"https://\")][0]\n",
    "        # print(\"url = \", web_url)\n",
    "        website_data = extract_website_text(web_url)\n",
    "        extra_data = website_data[:5000]\n",
    "        # print(f\"{extra_data = }\")\n",
    "        question = f\"\"\" remember the data\n",
    "\n",
    "        ```{extra_data}```\n",
    "        \"\"\"\n",
    "\n",
    "    else:\n",
    "        question = question\n",
    "\n",
    "    # print(question)\n",
    "    response, new_context = ask_gpt_with_context(question, context=context)\n",
    "    new_context.append({\"role\": \"assistant\", \"content\" : response})\n",
    "    context = new_context\n",
    "\n",
    "    print(f\"\\nAssistant: {response}\")\n",
    "    print(\"\\n------------------------------------\\n\")\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4b94992e8378f",
   "metadata": {
    "id": "1cf4b94992e8378f"
   },
   "source": [
    "# Part B: Write a chatbot prompt to iteratively create a sequence of chats on one particular custom data.\n",
    "1. The chatbot should be able to answer the questions based on the text data or multiple documents.\n",
    "2. The chatbot should save the conversation in the memory.\n",
    "2. Summarize the chats at the end of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae913ffd-19e0-4782-90d5-6ea2f7bdfc23",
   "metadata": {
    "id": "ae913ffd-19e0-4782-90d5-6ea2f7bdfc23",
    "outputId": "dd25d79b-afac-4991-f0bd-4530173831c7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hims/anaconda3/envs/python310/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=openai.api_key, temperature=0.0)\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b740109-9ead-4b27-8d57-e0fb4f631eda",
   "metadata": {
    "id": "2b740109-9ead-4b27-8d57-e0fb4f631eda",
    "outputId": "bcec2bcb-647c-49d1-852c-e364aee5bbcd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human : Hi, my name is Anjali, and Who are you?\n",
      "\n",
      "AI    : Hello Anjali! I am an AI assistant designed to help answer your questions and provide information. My name is Assistant. How can I assist you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = conversation.predict(input=\"Hi, my name is Anjali, and Who are you?\")\n",
    "resp = memory.chat_memory.messages[-1].content\n",
    "print(f\"\"\"\n",
    "Human : {memory.chat_memory.messages[-2].content}\n",
    "\n",
    "AI    : {resp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30967e32-447d-42c9-a110-28e01dee8afc",
   "metadata": {
    "id": "30967e32-447d-42c9-a110-28e01dee8afc",
    "outputId": "3d0263e0-037f-4116-b71b-fa61530709ec",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have remembered the context provided. How can I assist you with the information from the context?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_website_text(website_urls):\n",
    "    \"\"\" This method will read the webpage fromn the link and return the content of it.\"\"\"\n",
    "    res = []\n",
    "    for website_url in website_urls:\n",
    "        response = requests.get(website_url)\n",
    "        # website_text = response.content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        website_text = '\\n'.join([p.get_text() for p in soup.find_all('p')])\n",
    "        res.append(website_text)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "knowledge_base = extract_website_text([\"https://medium.com/@jheltzer/travel-guide-yosemite-national-park-2e83c8d6c2e9\", \"https://medium.com/@alissaalterishea/mount-rainier-national-park-washington-fe29c7dc1510\"])\n",
    "\n",
    "source_knowledge = \"\\n\".join(knowledge_base)\n",
    "\n",
    "context = f\"\"\"Rememer this context given in ``` and answer all question using that when asked. Acknowledge once data remeberd.\n",
    "\n",
    "```{source_knowledge}```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "x = conversation.predict(input=context)\n",
    "memory.chat_memory.messages[-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84741ee1-fa07-4385-89c2-1a87735aaa99",
   "metadata": {
    "id": "84741ee1-fa07-4385-89c2-1a87735aaa99",
    "outputId": "eae72fd8-517c-4769-d2f8-063b53e36ca4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human : Where is Yosemite located?\n",
      "\n",
      "AI    : Yosemite National Park is located in northeast California, east of the fertile San Joaquin Valley and just west of the border with Nevada. It is 167 miles straight east of San Francisco and covers almost 1,200 square miles.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"Where is Yosemite located?\")\n",
    "resp = memory.chat_memory.messages[-1].content\n",
    "print(f\"\"\"\n",
    "Human : {memory.chat_memory.messages[-2].content}\n",
    "\n",
    "AI    : {resp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cbb9a-9ded-49e5-9a28-5fdfde713cec",
   "metadata": {
    "id": "933cbb9a-9ded-49e5-9a28-5fdfde713cec",
    "outputId": "5a14fab1-1f74-4a5a-9ce6-fc39af421ca9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human : What are top locations in Yosemite?\n",
      "\n",
      "AI    : Some of the top locations in Yosemite National Park include Glacier Point, Tunnel View, Lower Yosemite Falls, El Capitan, Mariposa Grove, Olmsted Point, Half Dome, and many more. Each of these locations offers stunning views and unique experiences within the park.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"What are top locations in Yosemite?\")\n",
    "resp = memory.chat_memory.messages[-1].content\n",
    "print(f\"\"\"\n",
    "Human : {memory.chat_memory.messages[-2].content}\n",
    "\n",
    "AI    : {resp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82035e2-8b25-46fb-9d14-4f08c2bc09e5",
   "metadata": {
    "id": "f82035e2-8b25-46fb-9d14-4f08c2bc09e5",
    "outputId": "4a67dd2d-a400-47ae-b7cd-57363eb7ff0f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human : Where is Mount Rainer Park located?\n",
      "\n",
      "AI    : Mount Rainier National Park is located in Washington state, just a couple of hours from Seattle. It is home to the tallest peak in the Cascade Range and is known for its active volcano, Mount Rainier.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"Where is Mount Rainer Park located?\")\n",
    "resp = memory.chat_memory.messages[-1].content\n",
    "print(f\"\"\"\n",
    "Human : {memory.chat_memory.messages[-2].content}\n",
    "\n",
    "AI    : {resp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a59471-0ae2-416c-a698-f0682e4d6e49",
   "metadata": {
    "id": "95a59471-0ae2-416c-a698-f0682e4d6e49",
    "outputId": "f0dc1402-d843-4bd7-aca1-27be779eaf7b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human : Which is the famous trail for the mount rainer\n",
      "\n",
      "AI    : One of the famous trails at Mount Rainier National Park is the Skyline Trail, which offers rugged terrain, snow-capped peaks, glacier-clad slopes, fields of wildflowers, waterfalls, and fantastic views. It is a steep, 5.5 mile trek that provides a memorable hiking experience.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"Which is the famous trail for the mount rainer\")\n",
    "resp = memory.chat_memory.messages[-1].content\n",
    "print(f\"\"\"\n",
    "Human : {memory.chat_memory.messages[-2].content}\n",
    "\n",
    "AI    : {resp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e9ee0f-2f02-4377-b3ba-0df28fd9f48d",
   "metadata": {
    "id": "61e9ee0f-2f02-4377-b3ba-0df28fd9f48d",
    "outputId": "4b9914de-38c7-43a8-b605-ad08d1a55da1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human : Which park is better?\n",
      "\n",
      "AI    : Both Yosemite National Park and Mount Rainier National Park offer unique and beautiful experiences. Yosemite is known for its iconic rock formations, waterfalls, and diverse landscapes, while Mount Rainier is famous for its active volcano, glaciers, and stunning views of the Cascade Range. The choice of which park is better ultimately depends on personal preferences and what type of natural beauty and outdoor activities you are looking for.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"Which park is better?\")\n",
    "resp = memory.chat_memory.messages[-1].content\n",
    "print(f\"\"\"\n",
    "Human : {memory.chat_memory.messages[-2].content}\n",
    "\n",
    "AI    : {resp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f181be2-fbe6-400a-b39d-95fd2b02785c",
   "metadata": {
    "id": "1f181be2-fbe6-400a-b39d-95fd2b02785c",
    "outputId": "b26a53a9-c557-4286-c371-b85169010153",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human : Give me the whole conversation Summary?\n",
      "\n",
      "AI    : The conversation included a detailed context about a trip to Yosemite National Park, including information about the park's location, top locations to visit, accommodations, wildlife, hiking trails, and tips for visiting. The conversation also touched on a spontaneous visit to Mount Rainier National Park in Washington, highlighting the Skyline Trail and the Grove of Patriarchs. The AI provided information about both parks and their unique features, leaving the choice of which park is better up to personal preferences.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation.predict(input=\"Give me the whole conversation Summary?\")\n",
    "resp = memory.chat_memory.messages[-1].content\n",
    "print(f\"\"\"\n",
    "Human : {memory.chat_memory.messages[-2].content}\n",
    "\n",
    "AI    : {resp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcc9c6d-8a13-445a-87ce-1ea178945657",
   "metadata": {
    "id": "5fcc9c6d-8a13-445a-87ce-1ea178945657",
    "outputId": "7f2ab33b-a9c5-4d54-bf3b-b97fc779139e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hims/anaconda3/envs/python310/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The article discusses tips and recommendations for visiting Yosemite National Park, including lodging options, transportation, and popular attractions\n",
      "\n",
      "It also mentions the importance of proper gear and preparation for hiking trails\n",
      "\n",
      "The writer shares their experience of visiting Mount Rainier National Park and their upcoming plans for Seattle\n",
      "\n",
      "The AI assistant provides information about both parks and leaves the decision of which park is better up to personal preferences.\n"
     ]
    }
   ],
   "source": [
    "# Create Conversation Summary\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def create_summary(memory):\n",
    "    \"\"\" Based on the memory object and all the converstations with the chat, this function will create a summary of that.\"\"\"\n",
    "    llm = OpenAI(temperature=0, openai_api_key=openai.api_key)\n",
    "\n",
    "    text = \"\\n\".join([x.content for x in memory.chat_memory.messages])\n",
    "    num_tokens = llm.get_num_tokens(text)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=5000, chunk_overlap=350)\n",
    "    docs = text_splitter.create_documents([text])\n",
    "\n",
    "    chain = load_summarize_chain(llm=llm, chain_type='map_reduce')\n",
    "    return chain.run(docs)\n",
    "\n",
    "summary = create_summary(memory)\n",
    "print(\"\\n\\n\".join(summary.replace(\"\\\\n\", \"\").split(\". \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f952f89d-1063-42e9-b550-07052a0a0c4a",
   "metadata": {
    "id": "f952f89d-1063-42e9-b550-07052a0a0c4a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
