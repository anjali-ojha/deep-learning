{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQ4EwBuxYaimjT4GNg88tS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjali-ojha/deep-learning/blob/main/assignment/assignment-2/Anjali_Ojha_HW_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homwwork-2 - Pytorch\n",
        "\n",
        "## Use the code provided in demo 02 to complete this assignment.\n",
        "\n",
        "## Step 1. Follow along with the tutorial to gain an understanding of the process."
      ],
      "metadata": {
        "id": "i37RBRNDqi59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MvVVdrrgVMRJ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "tUeu4AhCVYI7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2. In a new .ipynb notebook, reproduce the results utilizing the \"QMNIST\" dataset"
      ],
      "metadata": {
        "id": "oWEU8TvyqtvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Fashion MNIST dataset and preprocess\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = torchvision.datasets.QMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.QMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTHOCrqVtGYN",
        "outputId": "aecf9568-9835-4da7-9618-09462c11a112"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-train-images-idx3-ubyte.gz to ./data/QMNIST/raw/qmnist-train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9704059/9704059 [00:00<00:00, 63708309.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/QMNIST/raw/qmnist-train-images-idx3-ubyte.gz to ./data/QMNIST/raw\n",
            "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-train-labels-idx2-int.gz to ./data/QMNIST/raw/qmnist-train-labels-idx2-int.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 463024/463024 [00:00<00:00, 12283999.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/QMNIST/raw/qmnist-train-labels-idx2-int.gz to ./data/QMNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-test-images-idx3-ubyte.gz to ./data/QMNIST/raw/qmnist-test-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9742279/9742279 [00:00<00:00, 77586325.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/QMNIST/raw/qmnist-test-images-idx3-ubyte.gz to ./data/QMNIST/raw\n",
            "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-test-labels-idx2-int.gz to ./data/QMNIST/raw/qmnist-test-labels-idx2-int.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 526800/526800 [00:00<00:00, 13617148.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/QMNIST/raw/qmnist-test-labels-idx2-int.gz to ./data/QMNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_data(data):\n",
        "    labels_map = {\n",
        "        0: \"Zero\",\n",
        "        1: \"One\",\n",
        "        2: \"Two\",\n",
        "        3: \"Three\",\n",
        "        4: \"Four\",\n",
        "        5: \"Five\",\n",
        "        6: \"Six\",\n",
        "        7: \"Seven\",\n",
        "        8: \"Eight\",\n",
        "        9: \"Nine\",\n",
        "    }\n",
        "    figure = plt.figure(figsize=(8, 8))\n",
        "    cols, rows = 3, 3\n",
        "    for i in range(1, cols * rows + 1):\n",
        "        sample_idx = torch.randint(len(data), size=(1,)).item()\n",
        "        img, label = data[sample_idx]\n",
        "        figure.add_subplot(rows, cols, i)\n",
        "        plt.title(labels_map[label])\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ds8M7vMTtJBP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_data(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "1FeroBKDtTBU",
        "outputId": "96711c74-6454-47e0-8415-16648d652ecb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training(train_loader, num_epochs, model, criterion, optimizer, verbose=0):\n",
        "    \"\"\"\n",
        "    Train the neural network\n",
        "    \"\"\"\n",
        "    running_loss = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            labels_onehot = nn.functional.one_hot(labels, num_classes=10).float()  # Convert labels to one-hot encoding\n",
        "\n",
        "            loss = criterion(outputs, labels_onehot)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            if verbose == 0 and i % 100 == 99:  # print every 100 mini-batches\n",
        "                print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "                running_loss = 0.0\n",
        "        if verbose == 1:\n",
        "            print(f'Epoch {epoch + 1}, Loss: {running_loss / 100}')\n",
        "\n",
        "    print(f'Finished Training with loss = {running_loss / 100}')\n",
        "    return model, running_loss/100"
      ],
      "metadata": {
        "id": "GvCT50But9il"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model, test_data):\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_data:\n",
        "            images, labels = data\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            predictions.extend(predicted.numpy())  # Store predictions\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy on test set: {correct / total * 100}%')\n",
        "    return correct, total, predictions\n"
      ],
      "metadata": {
        "id": "Yobw5mlrt_s6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_sample_result(model, images, labels):\n",
        "    # Get one test image and its label\n",
        "    image, label = images[1], labels[1]\n",
        "\n",
        "    # Reshape the image tensor to a 28x28 shape\n",
        "    image = image.view(28, 28)\n",
        "\n",
        "    # Convert the image tensor to a numpy array for visualization\n",
        "    image_numpy = image.numpy()\n",
        "\n",
        "    # Show the image\n",
        "    plt.imshow(image_numpy, cmap='gray')\n",
        "    plt.title(f'Predicted Label: {predictions[1]}, Actual Label: {label.item()}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "6Yu3RLjFue9L"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3. Report on the results in terms of prediction accuracy on the train and test datasets"
      ],
      "metadata": {
        "id": "xotJ97xYq3RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the neural network\n",
        "#Define the neural network architecture\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = MLP()\n",
        "model, _ = training(train_loader = train_loader,\n",
        "                    num_epochs=5,\n",
        "                    model=model,\n",
        "                    criterion = nn.CrossEntropyLoss(),\n",
        "                    optimizer = optim.Adam(model.parameters(), lr=0.001))\n",
        "correct, total, predictions = evaluation(model=model, test_data=test_loader)\n",
        "# show_sample_result(model=model, )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8-05hC2oRjF",
        "outputId": "7960e269-0972-441e-896f-9ff0fc79b8c2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 1.0403295677900315\n",
            "Epoch 1, Batch 200, Loss: 0.4514515769481659\n",
            "Epoch 1, Batch 300, Loss: 0.3887970148026943\n",
            "Epoch 1, Batch 400, Loss: 0.35856480166316035\n",
            "Epoch 1, Batch 500, Loss: 0.3227876826375723\n",
            "Epoch 1, Batch 600, Loss: 0.28552216179668904\n",
            "Epoch 1, Batch 700, Loss: 0.2731552179902792\n",
            "Epoch 1, Batch 800, Loss: 0.2573801130801439\n",
            "Epoch 1, Batch 900, Loss: 0.2621749038994312\n",
            "Epoch 2, Batch 100, Loss: 0.2232590626180172\n",
            "Epoch 2, Batch 200, Loss: 0.2011128705739975\n",
            "Epoch 2, Batch 300, Loss: 0.20308306265622378\n",
            "Epoch 2, Batch 400, Loss: 0.18551764529198408\n",
            "Epoch 2, Batch 500, Loss: 0.19707779645919798\n",
            "Epoch 2, Batch 600, Loss: 0.20363991148769855\n",
            "Epoch 2, Batch 700, Loss: 0.17986039992421865\n",
            "Epoch 2, Batch 800, Loss: 0.1719306116178632\n",
            "Epoch 2, Batch 900, Loss: 0.161939442679286\n",
            "Epoch 3, Batch 100, Loss: 0.14251200761646032\n",
            "Epoch 3, Batch 200, Loss: 0.15314252011477947\n",
            "Epoch 3, Batch 300, Loss: 0.14296368904411794\n",
            "Epoch 3, Batch 400, Loss: 0.1291934664361179\n",
            "Epoch 3, Batch 500, Loss: 0.15999933499842883\n",
            "Epoch 3, Batch 600, Loss: 0.13425169611349702\n",
            "Epoch 3, Batch 700, Loss: 0.1351630167849362\n",
            "Epoch 3, Batch 800, Loss: 0.12149443039670586\n",
            "Epoch 3, Batch 900, Loss: 0.11996061563491821\n",
            "Epoch 4, Batch 100, Loss: 0.11496749071404339\n",
            "Epoch 4, Batch 200, Loss: 0.11580195527523757\n",
            "Epoch 4, Batch 300, Loss: 0.11670950047671795\n",
            "Epoch 4, Batch 400, Loss: 0.10979836948215961\n",
            "Epoch 4, Batch 500, Loss: 0.10571382660418749\n",
            "Epoch 4, Batch 600, Loss: 0.11553370878100395\n",
            "Epoch 4, Batch 700, Loss: 0.11078091906383633\n",
            "Epoch 4, Batch 800, Loss: 0.11487677247729153\n",
            "Epoch 4, Batch 900, Loss: 0.11194509148597717\n",
            "Epoch 5, Batch 100, Loss: 0.0922467858158052\n",
            "Epoch 5, Batch 200, Loss: 0.10726466571912169\n",
            "Epoch 5, Batch 300, Loss: 0.08649035755544901\n",
            "Epoch 5, Batch 400, Loss: 0.08843762665521354\n",
            "Epoch 5, Batch 500, Loss: 0.0979673551209271\n",
            "Epoch 5, Batch 600, Loss: 0.11335285827517509\n",
            "Epoch 5, Batch 700, Loss: 0.0931163958273828\n",
            "Epoch 5, Batch 800, Loss: 0.09068257831037045\n",
            "Epoch 5, Batch 900, Loss: 0.08467121965251863\n",
            "Finished Training\n",
            "Accuracy on test set: 96.79166666666667%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4. Choose one of the proposed modifications below:\n",
        "\n",
        "### 1 - Add another Dense layer of 128 nodes"
      ],
      "metadata": {
        "id": "qGhsZdYAxh5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the neural network architecture\n",
        "class MLP_New_Layer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP_New_Layer, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the neural network\n",
        "model_new_layer = MLP_New_Layer()\n",
        "\n",
        "model_new_layer, _ = training(num_epochs=5,\n",
        "                              model=model_new_layer,\n",
        "                              criterion = nn.CrossEntropyLoss(),\n",
        "                              optimizer = optim.Adam(model_new_layer.parameters(), lr=0.001))\n",
        "\n",
        "correct_new_layer, total_new_layer, predictions_new_layer = evaluation(model=model_new_layer, test_data=test_loader)"
      ],
      "metadata": {
        "id": "TJA6RrUpuhdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Increase the current number of nodes in the layer to 256"
      ],
      "metadata": {
        "id": "HSUuTyzlxwZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the neural network architecture\n",
        "class MLP_Wide_Layer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP_Wide_Layer, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the neural network\n",
        "model_wide_layer = MLP_Wide_Layer()\n",
        "model_wide_layer, _ = training(num_epochs = 5,\n",
        "                                model = model_wide_layer,\n",
        "                                criterion = nn.CrossEntropyLoss(),\n",
        "                                optimizer = optim.Adam(model_wide_layer.parameters(), lr=0.001))\n",
        "\n",
        "\n",
        "correct_wide_layer, total_wide_layer, predictions_wide_layer = evaluation(model=model_wide_layer, test_data=test_loader)"
      ],
      "metadata": {
        "id": "alHwpwPny3dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6. Report on the results of the modified model and if it matches your hypothesis"
      ],
      "metadata": {
        "id": "yQ_O--zmyquL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the percentages\n",
        "base_accuracy = correct / total * 100\n",
        "new_layer_accuracy = correct_new_layer / total * 100\n",
        "wide_accuracy = correct_wide_layer / total * 100\n",
        "\n",
        "# Define the labels for the bars\n",
        "labels = ['Base Network', 'Extra Layer Network', 'Wide Network']\n",
        "\n",
        "# Define the values for the bars\n",
        "values = [base_accuracy, new_layer_accuracy, wide_accuracy]\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(5, 3))\n",
        "bars = plt.bar(labels, values, color=['blue', 'green', 'yellow'])\n",
        "\n",
        "# Add percentage values on top of the bars\n",
        "for bar, value in zip(bars, values):\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1, f'{value:.3f}%', ha='center', va='bottom')\n",
        "\n",
        "plt.ylim(0, 110)\n",
        "# Add title and labels\n",
        "plt.title('Comparison of Percentages')\n",
        "plt.xlabel('Different Models')\n",
        "plt.ylabel('Testing Accuracy')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "XBF53IEAyvZB",
        "outputId": "eb699bf9-3e8c-4c6d-aab4-8b4642cdb41d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7. Experiment with different optimizers, loss functions, dropout, and activation functions, and observe the change in performance as you tune these hyperparameters."
      ],
      "metadata": {
        "id": "9hMgygYPywMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the neural network architecture\n",
        "class MLP_Flex(nn.Module):\n",
        "    def __init__(self, activation_function, dropout):\n",
        "        super(MLP_Flex, self).__init__()\n",
        "        self.activation_function = activation_function\n",
        "        self.dropout = dropout\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "        self.dropout_fuction = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = self.activation_function(self.fc1(x))\n",
        "        x = self.dropout_fuction(x)\n",
        "        x = self.activation_function(self.fc2(x))\n",
        "        x = self.dropout_fuction(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "30ATDMXySdV_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = [optim.Adam, optim.SGD, optim.RMSprop]\n",
        "loss_functions = [nn.MSELoss(), nn.CrossEntropyLoss(), ]\n",
        "dropouts = [0.0, 0.2, 0.5]\n",
        "activation_functions = [nn.ReLU(), nn.Sigmoid()]\n",
        "\n",
        "result = {\"optimizer\":[], \"loss_function\": [], \"dropout\":[],\n",
        "          \"activation_function\": [],\n",
        "          \"training_loss\": [], \"test_accuracy\": [], \"name\": []}\n",
        "\n",
        "for optimizer in optimizers:\n",
        "    for loss_function in loss_functions:\n",
        "        for dropout in dropouts:\n",
        "            for activation_function in activation_functions:\n",
        "\n",
        "                result[\"optimizer\"].append(optimizer.__name__)\n",
        "                result[\"loss_function\"].append(loss_function.__class__.__name__)\n",
        "                result[\"activation_function\"].append(activation_function.__class__.__name__)\n",
        "                result[\"dropout\"].append(dropout)\n",
        "\n",
        "                name = []\n",
        "                for key in [\"optimizer\", \"loss_function\", \"activation_function\", \"dropout\"]:\n",
        "                    name.append(f'{key}={result[key][-1]}')\n",
        "\n",
        "                result[\"name\"].append(\",\".join(name))\n",
        "\n",
        "                print(f'''\\n\\tTraining {result[\"name\"][-1]}\\n''')\n",
        "\n",
        "                model = MLP_Flex(activation_function=activation_function, dropout=dropout)\n",
        "                model, training_loss = training(num_epochs = 5,\n",
        "                                                model = model,\n",
        "                                                criterion = loss_function,\n",
        "                                                optimizer = optimizer(model.parameters(), lr=0.001),\n",
        "                                                verbose = False)\n",
        "                correct, total, predictions = evaluation(model=model, test_data=test_loader)\n",
        "\n",
        "                result[\"training_loss\"].append(training_loss)\n",
        "                result[\"test_accuracy\"].append(correct/total*100)\n",
        "\n",
        "                print('\\n')\n",
        "\n",
        "import pandas as pd\n",
        "result_df = pd.DataFrame(result)\n",
        "result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "73Lz9LoC1cP8",
        "outputId": "41f4ee5b-6af6-47b5-ce05-111e1123afef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tTraining optimizer=Adam,loss_function=MSELoss,activation_function=ReLU,dropout=0.0\n",
            "\n",
            "Epoch 1, Loss: 0.18697951362933962\n",
            "Epoch 2, Loss: 0.09308258606120944\n",
            "Epoch 3, Loss: 0.07442031439160929\n",
            "Epoch 4, Loss: 0.06530307362554595\n",
            "Epoch 5, Loss: 0.059944613045081495\n",
            "Finished Training\n",
            "Accuracy on test set: 96.55333333333334%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.0\n",
            "\n",
            "Epoch 1, Loss: 0.31904714109376076\n",
            "Epoch 2, Loss: 0.13636679910123348\n",
            "Epoch 3, Loss: 0.11085610748268664\n",
            "Epoch 4, Loss: 0.0957721091923304\n",
            "Epoch 5, Loss: 0.08517300349427387\n",
            "Finished Training\n",
            "Accuracy on test set: 95.61833333333334%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=MSELoss,activation_function=ReLU,dropout=0.2\n",
            "\n",
            "Epoch 1, Loss: 0.29067599336616695\n",
            "Epoch 2, Loss: 0.18790761347860097\n",
            "Epoch 3, Loss: 0.1692900667525828\n",
            "Epoch 4, Loss: 0.16084475022740663\n",
            "Epoch 5, Loss: 0.15416608817875385\n",
            "Finished Training\n",
            "Accuracy on test set: 95.1%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.2\n",
            "\n",
            "Epoch 1, Loss: 0.409739957889542\n",
            "Epoch 2, Loss: 0.18975297174416483\n",
            "Epoch 3, Loss: 0.15324664957821368\n",
            "Epoch 4, Loss: 0.13354261924512684\n",
            "Epoch 5, Loss: 0.12190480670891703\n",
            "Finished Training\n",
            "Accuracy on test set: 95.085%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=MSELoss,activation_function=ReLU,dropout=0.5\n",
            "\n",
            "Epoch 1, Loss: 0.5522825619578362\n",
            "Epoch 2, Loss: 0.45493657387793063\n",
            "Epoch 3, Loss: 0.4376021756976843\n",
            "Epoch 4, Loss: 0.42173521131277086\n",
            "Epoch 5, Loss: 0.41638062335550785\n",
            "Finished Training\n",
            "Accuracy on test set: 90.28%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.5\n",
            "\n",
            "Epoch 1, Loss: 0.6210330144315958\n",
            "Epoch 2, Loss: 0.3445489769987762\n",
            "Epoch 3, Loss: 0.28286248898133637\n",
            "Epoch 4, Loss: 0.2560787641070783\n",
            "Epoch 5, Loss: 0.24489592261612414\n",
            "Finished Training\n",
            "Accuracy on test set: 93.11%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.0\n",
            "\n",
            "Epoch 1, Loss: 3.703755075149238\n",
            "Epoch 2, Loss: 1.8227195481210947\n",
            "Epoch 3, Loss: 1.3174776878766716\n",
            "Epoch 4, Loss: 1.0795392560213803\n",
            "Epoch 5, Loss: 0.90187743447721\n",
            "Finished Training\n",
            "Accuracy on test set: 96.52666666666667%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.0\n",
            "\n",
            "Epoch 1, Loss: 6.090755986198783\n",
            "Epoch 2, Loss: 2.01584095377475\n",
            "Epoch 3, Loss: 1.3999045838229358\n",
            "Epoch 4, Loss: 1.0857437631674112\n",
            "Epoch 5, Loss: 0.8990540851838886\n",
            "Finished Training\n",
            "Accuracy on test set: 96.56166666666667%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.2\n",
            "\n",
            "Epoch 1, Loss: 4.5267048916220665\n",
            "Epoch 2, Loss: 2.353687482587993\n",
            "Epoch 3, Loss: 1.973208016976714\n",
            "Epoch 4, Loss: 1.7104877291060985\n",
            "Epoch 5, Loss: 1.573557266574353\n",
            "Finished Training\n",
            "Accuracy on test set: 95.705%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.2\n",
            "\n",
            "Epoch 1, Loss: 6.799218058437109\n",
            "Epoch 2, Loss: 2.827330116927624\n",
            "Epoch 3, Loss: 2.232959817573428\n",
            "Epoch 4, Loss: 1.879485765248537\n",
            "Epoch 5, Loss: 1.664715658482164\n",
            "Finished Training\n",
            "Accuracy on test set: 95.795%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.5\n",
            "\n",
            "Epoch 1, Loss: 7.780219544172287\n",
            "Epoch 2, Loss: 4.870613948106766\n",
            "Epoch 3, Loss: 4.403841688632965\n",
            "Epoch 4, Loss: 4.118341653048992\n",
            "Epoch 5, Loss: 3.900216255337\n",
            "Finished Training\n",
            "Accuracy on test set: 93.565%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.5\n",
            "\n",
            "Epoch 1, Loss: 9.269251502156258\n",
            "Epoch 2, Loss: 4.558648357391357\n",
            "Epoch 3, Loss: 3.796129535138607\n",
            "Epoch 4, Loss: 3.3982807125896217\n",
            "Epoch 5, Loss: 3.1643730099499225\n",
            "Finished Training\n",
            "Accuracy on test set: 94.28999999999999%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=MSELoss,activation_function=ReLU,dropout=0.0\n",
            "\n",
            "Epoch 1, Loss: 0.864654155522585\n",
            "Epoch 2, Loss: 0.808982392847538\n",
            "Epoch 3, Loss: 0.7779351277649402\n",
            "Epoch 4, Loss: 0.7503331048041582\n",
            "Epoch 5, Loss: 0.7241731809824705\n",
            "Finished Training\n",
            "Accuracy on test set: 54.04666666666667%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.0\n",
            "\n",
            "Epoch 1, Loss: 0.9893235157430172\n",
            "Epoch 2, Loss: 0.8450966493785381\n",
            "Epoch 3, Loss: 0.844265318736434\n",
            "Epoch 4, Loss: 0.8436043882369995\n",
            "Epoch 5, Loss: 0.8429385121166706\n",
            "Finished Training\n",
            "Accuracy on test set: 14.7%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=MSELoss,activation_function=ReLU,dropout=0.2\n",
            "\n",
            "Epoch 1, Loss: 0.8914229872077704\n",
            "Epoch 2, Loss: 0.84496711820364\n",
            "Epoch 3, Loss: 0.821622953042388\n",
            "Epoch 4, Loss: 0.8017835268378257\n",
            "Epoch 5, Loss: 0.7820259592682123\n",
            "Finished Training\n",
            "Accuracy on test set: 54.708333333333336%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.2\n",
            "\n",
            "Epoch 1, Loss: 1.2038388697057962\n",
            "Epoch 2, Loss: 1.0539630572497845\n",
            "Epoch 3, Loss: 1.043664588034153\n",
            "Epoch 4, Loss: 1.038140375763178\n",
            "Epoch 5, Loss: 1.0266603782027959\n",
            "Finished Training\n",
            "Accuracy on test set: 20.596666666666668%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=MSELoss,activation_function=ReLU,dropout=0.5\n",
            "\n",
            "Epoch 1, Loss: 1.0289157609641553\n",
            "Epoch 2, Loss: 0.9261820038408041\n",
            "Epoch 3, Loss: 0.890520158559084\n",
            "Epoch 4, Loss: 0.8690337435156107\n",
            "Epoch 5, Loss: 0.8513857178390026\n",
            "Finished Training\n",
            "Accuracy on test set: 39.931666666666665%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.5\n",
            "\n",
            "Epoch 1, Loss: 1.7312801325321197\n",
            "Epoch 2, Loss: 1.4761437721550466\n",
            "Epoch 3, Loss: 1.4008738645911216\n",
            "Epoch 4, Loss: 1.3261534002423288\n",
            "Epoch 5, Loss: 1.2778557365387677\n",
            "Finished Training\n",
            "Accuracy on test set: 14.903333333333332%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.0\n",
            "\n",
            "Epoch 1, Loss: 20.93118777036667\n",
            "Epoch 2, Loss: 18.63777444601059\n",
            "Epoch 3, Loss: 14.390253019332885\n",
            "Epoch 4, Loss: 10.107039904594421\n",
            "Epoch 5, Loss: 7.5869348150491716\n",
            "Finished Training\n",
            "Accuracy on test set: 81.98166666666667%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.0\n",
            "\n",
            "Epoch 1, Loss: 21.637431519031523\n",
            "Epoch 2, Loss: 21.56495846748352\n",
            "Epoch 3, Loss: 21.543024883270263\n",
            "Epoch 4, Loss: 21.523460569381715\n",
            "Epoch 5, Loss: 21.503117299079896\n",
            "Finished Training\n",
            "Accuracy on test set: 11.318333333333333%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.2\n",
            "\n",
            "Epoch 1, Loss: 21.11683609008789\n",
            "Epoch 2, Loss: 19.564959486722945\n",
            "Epoch 3, Loss: 16.600767418146134\n",
            "Epoch 4, Loss: 13.147922334671021\n",
            "Epoch 5, Loss: 10.630294513702392\n",
            "Finished Training\n",
            "Accuracy on test set: 77.91333333333334%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.2\n",
            "\n",
            "Epoch 1, Loss: 21.850173637866973\n",
            "Epoch 2, Loss: 21.65803345441818\n",
            "Epoch 3, Loss: 21.630241117477418\n",
            "Epoch 4, Loss: 21.603471925258635\n",
            "Epoch 5, Loss: 21.588386430740357\n",
            "Finished Training\n",
            "Accuracy on test set: 11.318333333333333%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.5\n",
            "\n",
            "Epoch 1, Loss: 21.216136541366577\n",
            "Epoch 2, Loss: 19.97928829550743\n",
            "Epoch 3, Loss: 17.975855770111085\n",
            "Epoch 4, Loss: 15.63265721321106\n",
            "Epoch 5, Loss: 13.58070799946785\n",
            "Finished Training\n",
            "Accuracy on test set: 75.88166666666667%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.5\n",
            "\n",
            "Epoch 1, Loss: 22.057162029743196\n",
            "Epoch 2, Loss: 21.87766940355301\n",
            "Epoch 3, Loss: 21.822209446430207\n",
            "Epoch 4, Loss: 21.801600198745728\n",
            "Epoch 5, Loss: 21.778574843406677\n",
            "Finished Training\n",
            "Accuracy on test set: 11.318333333333333%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=MSELoss,activation_function=ReLU,dropout=0.0\n",
            "\n",
            "Epoch 1, Loss: 0.3194156994204968\n",
            "Epoch 2, Loss: 0.12446226528845727\n",
            "Epoch 3, Loss: 0.09240635751280933\n",
            "Epoch 4, Loss: 0.07646052691387012\n",
            "Epoch 5, Loss: 0.06706241970299744\n",
            "Finished Training\n",
            "Accuracy on test set: 95.35%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.0\n",
            "\n",
            "Epoch 1, Loss: 0.25061460421886295\n",
            "Epoch 2, Loss: 0.12725048513151704\n",
            "Epoch 3, Loss: 0.10186376099940389\n",
            "Epoch 4, Loss: 0.0854252575431019\n",
            "Epoch 5, Loss: 0.0730301087978296\n",
            "Finished Training\n",
            "Accuracy on test set: 96.12%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=MSELoss,activation_function=ReLU,dropout=0.2\n",
            "\n",
            "Epoch 1, Loss: 0.40402123622596264\n",
            "Epoch 2, Loss: 0.20696366026066243\n",
            "Epoch 3, Loss: 0.17945871111936867\n",
            "Epoch 4, Loss: 0.16765329659916461\n",
            "Epoch 5, Loss: 0.16077668638899922\n",
            "Finished Training\n",
            "Accuracy on test set: 94.78999999999999%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.2\n",
            "\n",
            "Epoch 1, Loss: 0.3511364272516221\n",
            "Epoch 2, Loss: 0.17277975724078715\n",
            "Epoch 3, Loss: 0.13809513206128032\n",
            "Epoch 4, Loss: 0.12139556356240064\n",
            "Epoch 5, Loss: 0.11051671667024493\n",
            "Finished Training\n",
            "Accuracy on test set: 95.26833333333333%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=MSELoss,activation_function=ReLU,dropout=0.5\n",
            "\n",
            "Epoch 1, Loss: 0.5917705017328262\n",
            "Epoch 2, Loss: 0.4146963763982058\n",
            "Epoch 3, Loss: 0.3821000007726252\n",
            "Epoch 4, Loss: 0.36646744556725025\n",
            "Epoch 5, Loss: 0.35716873651370407\n",
            "Finished Training\n",
            "Accuracy on test set: 90.92333333333333%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.5\n",
            "\n",
            "Epoch 1, Loss: 0.5115665802545846\n",
            "Epoch 2, Loss: 0.29073593418113886\n",
            "Epoch 3, Loss: 0.2534234482422471\n",
            "Epoch 4, Loss: 0.23625445012934507\n",
            "Epoch 5, Loss: 0.22584562617354095\n",
            "Finished Training\n",
            "Accuracy on test set: 93.965%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.0\n",
            "\n",
            "Epoch 1, Loss: 3.875915119200945\n",
            "Epoch 2, Loss: 1.9038695619255304\n",
            "Epoch 3, Loss: 1.4338108671084047\n",
            "Epoch 4, Loss: 1.1883737382106483\n",
            "Epoch 5, Loss: 1.0188348816288635\n",
            "Finished Training\n",
            "Accuracy on test set: 96.25833333333334%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.0\n",
            "\n",
            "Epoch 1, Loss: 4.9751614506542685\n",
            "Epoch 2, Loss: 2.00725337639451\n",
            "Epoch 3, Loss: 1.4414237415045499\n",
            "Epoch 4, Loss: 1.1396275918092578\n",
            "Epoch 5, Loss: 0.9529443097673357\n",
            "Finished Training\n",
            "Accuracy on test set: 96.37%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.2\n",
            "\n",
            "Epoch 1, Loss: 4.76647608667612\n",
            "Epoch 2, Loss: 2.6513633703812958\n",
            "Epoch 3, Loss: 2.217452756650746\n",
            "Epoch 4, Loss: 1.9715422013029456\n",
            "Epoch 5, Loss: 1.8185149179399014\n",
            "Finished Training\n",
            "Accuracy on test set: 95.87666666666667%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.2\n",
            "\n",
            "Epoch 1, Loss: 5.772691947221756\n",
            "Epoch 2, Loss: 2.722298213019967\n",
            "Epoch 3, Loss: 2.1254307962954044\n",
            "Epoch 4, Loss: 1.788667696043849\n",
            "Epoch 5, Loss: 1.544201612304896\n",
            "Finished Training\n",
            "Accuracy on test set: 95.75666666666666%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.5\n",
            "\n",
            "Epoch 1, Loss: 7.682619798779488\n",
            "Epoch 2, Loss: 5.134904536753893\n",
            "Epoch 3, Loss: 4.6502130420506\n",
            "Epoch 4, Loss: 4.330919222384691\n",
            "Epoch 5, Loss: 4.2426882015168665\n",
            "Finished Training\n",
            "Accuracy on test set: 93.06166666666667%\n",
            "\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.5\n",
            "\n",
            "Epoch 1, Loss: 8.126614939570427\n",
            "Epoch 2, Loss: 4.3858001455664635\n",
            "Epoch 3, Loss: 3.709215485751629\n",
            "Epoch 4, Loss: 3.373957010358572\n",
            "Epoch 5, Loss: 3.0911639677733183\n",
            "Finished Training\n",
            "Accuracy on test set: 94.04666666666667%\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   optimizer     loss_function  dropout activation_function  training_loss  \\\n",
              "0       Adam           MSELoss      0.0                ReLU       0.059945   \n",
              "1       Adam           MSELoss      0.0             Sigmoid       0.085173   \n",
              "2       Adam           MSELoss      0.2                ReLU       0.154166   \n",
              "3       Adam           MSELoss      0.2             Sigmoid       0.121905   \n",
              "4       Adam           MSELoss      0.5                ReLU       0.416381   \n",
              "5       Adam           MSELoss      0.5             Sigmoid       0.244896   \n",
              "6       Adam  CrossEntropyLoss      0.0                ReLU       0.901877   \n",
              "7       Adam  CrossEntropyLoss      0.0             Sigmoid       0.899054   \n",
              "8       Adam  CrossEntropyLoss      0.2                ReLU       1.573557   \n",
              "9       Adam  CrossEntropyLoss      0.2             Sigmoid       1.664716   \n",
              "10      Adam  CrossEntropyLoss      0.5                ReLU       3.900216   \n",
              "11      Adam  CrossEntropyLoss      0.5             Sigmoid       3.164373   \n",
              "12       SGD           MSELoss      0.0                ReLU       0.724173   \n",
              "13       SGD           MSELoss      0.0             Sigmoid       0.842939   \n",
              "14       SGD           MSELoss      0.2                ReLU       0.782026   \n",
              "15       SGD           MSELoss      0.2             Sigmoid       1.026660   \n",
              "16       SGD           MSELoss      0.5                ReLU       0.851386   \n",
              "17       SGD           MSELoss      0.5             Sigmoid       1.277856   \n",
              "18       SGD  CrossEntropyLoss      0.0                ReLU       7.586935   \n",
              "19       SGD  CrossEntropyLoss      0.0             Sigmoid      21.503117   \n",
              "20       SGD  CrossEntropyLoss      0.2                ReLU      10.630295   \n",
              "21       SGD  CrossEntropyLoss      0.2             Sigmoid      21.588386   \n",
              "22       SGD  CrossEntropyLoss      0.5                ReLU      13.580708   \n",
              "23       SGD  CrossEntropyLoss      0.5             Sigmoid      21.778575   \n",
              "24   RMSprop           MSELoss      0.0                ReLU       0.067062   \n",
              "25   RMSprop           MSELoss      0.0             Sigmoid       0.073030   \n",
              "26   RMSprop           MSELoss      0.2                ReLU       0.160777   \n",
              "27   RMSprop           MSELoss      0.2             Sigmoid       0.110517   \n",
              "28   RMSprop           MSELoss      0.5                ReLU       0.357169   \n",
              "29   RMSprop           MSELoss      0.5             Sigmoid       0.225846   \n",
              "30   RMSprop  CrossEntropyLoss      0.0                ReLU       1.018835   \n",
              "31   RMSprop  CrossEntropyLoss      0.0             Sigmoid       0.952944   \n",
              "32   RMSprop  CrossEntropyLoss      0.2                ReLU       1.818515   \n",
              "33   RMSprop  CrossEntropyLoss      0.2             Sigmoid       1.544202   \n",
              "34   RMSprop  CrossEntropyLoss      0.5                ReLU       4.242688   \n",
              "35   RMSprop  CrossEntropyLoss      0.5             Sigmoid       3.091164   \n",
              "\n",
              "    test_accuracy                                               name  \n",
              "0       96.553333  optimizer=Adam,loss_function=MSELoss,activatio...  \n",
              "1       95.618333  optimizer=Adam,loss_function=MSELoss,activatio...  \n",
              "2       95.100000  optimizer=Adam,loss_function=MSELoss,activatio...  \n",
              "3       95.085000  optimizer=Adam,loss_function=MSELoss,activatio...  \n",
              "4       90.280000  optimizer=Adam,loss_function=MSELoss,activatio...  \n",
              "5       93.110000  optimizer=Adam,loss_function=MSELoss,activatio...  \n",
              "6       96.526667  optimizer=Adam,loss_function=CrossEntropyLoss,...  \n",
              "7       96.561667  optimizer=Adam,loss_function=CrossEntropyLoss,...  \n",
              "8       95.705000  optimizer=Adam,loss_function=CrossEntropyLoss,...  \n",
              "9       95.795000  optimizer=Adam,loss_function=CrossEntropyLoss,...  \n",
              "10      93.565000  optimizer=Adam,loss_function=CrossEntropyLoss,...  \n",
              "11      94.290000  optimizer=Adam,loss_function=CrossEntropyLoss,...  \n",
              "12      54.046667  optimizer=SGD,loss_function=MSELoss,activation...  \n",
              "13      14.700000  optimizer=SGD,loss_function=MSELoss,activation...  \n",
              "14      54.708333  optimizer=SGD,loss_function=MSELoss,activation...  \n",
              "15      20.596667  optimizer=SGD,loss_function=MSELoss,activation...  \n",
              "16      39.931667  optimizer=SGD,loss_function=MSELoss,activation...  \n",
              "17      14.903333  optimizer=SGD,loss_function=MSELoss,activation...  \n",
              "18      81.981667  optimizer=SGD,loss_function=CrossEntropyLoss,a...  \n",
              "19      11.318333  optimizer=SGD,loss_function=CrossEntropyLoss,a...  \n",
              "20      77.913333  optimizer=SGD,loss_function=CrossEntropyLoss,a...  \n",
              "21      11.318333  optimizer=SGD,loss_function=CrossEntropyLoss,a...  \n",
              "22      75.881667  optimizer=SGD,loss_function=CrossEntropyLoss,a...  \n",
              "23      11.318333  optimizer=SGD,loss_function=CrossEntropyLoss,a...  \n",
              "24      95.350000  optimizer=RMSprop,loss_function=MSELoss,activa...  \n",
              "25      96.120000  optimizer=RMSprop,loss_function=MSELoss,activa...  \n",
              "26      94.790000  optimizer=RMSprop,loss_function=MSELoss,activa...  \n",
              "27      95.268333  optimizer=RMSprop,loss_function=MSELoss,activa...  \n",
              "28      90.923333  optimizer=RMSprop,loss_function=MSELoss,activa...  \n",
              "29      93.965000  optimizer=RMSprop,loss_function=MSELoss,activa...  \n",
              "30      96.258333  optimizer=RMSprop,loss_function=CrossEntropyLo...  \n",
              "31      96.370000  optimizer=RMSprop,loss_function=CrossEntropyLo...  \n",
              "32      95.876667  optimizer=RMSprop,loss_function=CrossEntropyLo...  \n",
              "33      95.756667  optimizer=RMSprop,loss_function=CrossEntropyLo...  \n",
              "34      93.061667  optimizer=RMSprop,loss_function=CrossEntropyLo...  \n",
              "35      94.046667  optimizer=RMSprop,loss_function=CrossEntropyLo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f13c8209-d6fe-4c45-83d2-03b144cc4d75\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>optimizer</th>\n",
              "      <th>loss_function</th>\n",
              "      <th>dropout</th>\n",
              "      <th>activation_function</th>\n",
              "      <th>training_loss</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adam</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>0.059945</td>\n",
              "      <td>96.553333</td>\n",
              "      <td>optimizer=Adam,loss_function=MSELoss,activatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adam</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>0.085173</td>\n",
              "      <td>95.618333</td>\n",
              "      <td>optimizer=Adam,loss_function=MSELoss,activatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adam</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.2</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>0.154166</td>\n",
              "      <td>95.100000</td>\n",
              "      <td>optimizer=Adam,loss_function=MSELoss,activatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Adam</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>0.121905</td>\n",
              "      <td>95.085000</td>\n",
              "      <td>optimizer=Adam,loss_function=MSELoss,activatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adam</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.5</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>0.416381</td>\n",
              "      <td>90.280000</td>\n",
              "      <td>optimizer=Adam,loss_function=MSELoss,activatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Adam</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>0.244896</td>\n",
              "      <td>93.110000</td>\n",
              "      <td>optimizer=Adam,loss_function=MSELoss,activatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Adam</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>0.901877</td>\n",
              "      <td>96.526667</td>\n",
              "      <td>optimizer=Adam,loss_function=CrossEntropyLoss,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Adam</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>0.899054</td>\n",
              "      <td>96.561667</td>\n",
              "      <td>optimizer=Adam,loss_function=CrossEntropyLoss,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Adam</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.2</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>1.573557</td>\n",
              "      <td>95.705000</td>\n",
              "      <td>optimizer=Adam,loss_function=CrossEntropyLoss,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Adam</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>1.664716</td>\n",
              "      <td>95.795000</td>\n",
              "      <td>optimizer=Adam,loss_function=CrossEntropyLoss,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Adam</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.5</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>3.900216</td>\n",
              "      <td>93.565000</td>\n",
              "      <td>optimizer=Adam,loss_function=CrossEntropyLoss,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Adam</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>3.164373</td>\n",
              "      <td>94.290000</td>\n",
              "      <td>optimizer=Adam,loss_function=CrossEntropyLoss,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SGD</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>0.724173</td>\n",
              "      <td>54.046667</td>\n",
              "      <td>optimizer=SGD,loss_function=MSELoss,activation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>SGD</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>0.842939</td>\n",
              "      <td>14.700000</td>\n",
              "      <td>optimizer=SGD,loss_function=MSELoss,activation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SGD</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.2</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>0.782026</td>\n",
              "      <td>54.708333</td>\n",
              "      <td>optimizer=SGD,loss_function=MSELoss,activation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>SGD</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>1.026660</td>\n",
              "      <td>20.596667</td>\n",
              "      <td>optimizer=SGD,loss_function=MSELoss,activation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>SGD</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.5</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>0.851386</td>\n",
              "      <td>39.931667</td>\n",
              "      <td>optimizer=SGD,loss_function=MSELoss,activation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>SGD</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>1.277856</td>\n",
              "      <td>14.903333</td>\n",
              "      <td>optimizer=SGD,loss_function=MSELoss,activation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>SGD</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>7.586935</td>\n",
              "      <td>81.981667</td>\n",
              "      <td>optimizer=SGD,loss_function=CrossEntropyLoss,a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>SGD</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>21.503117</td>\n",
              "      <td>11.318333</td>\n",
              "      <td>optimizer=SGD,loss_function=CrossEntropyLoss,a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>SGD</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.2</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>10.630295</td>\n",
              "      <td>77.913333</td>\n",
              "      <td>optimizer=SGD,loss_function=CrossEntropyLoss,a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>SGD</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>21.588386</td>\n",
              "      <td>11.318333</td>\n",
              "      <td>optimizer=SGD,loss_function=CrossEntropyLoss,a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>SGD</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.5</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>13.580708</td>\n",
              "      <td>75.881667</td>\n",
              "      <td>optimizer=SGD,loss_function=CrossEntropyLoss,a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>SGD</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>21.778575</td>\n",
              "      <td>11.318333</td>\n",
              "      <td>optimizer=SGD,loss_function=CrossEntropyLoss,a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>0.067062</td>\n",
              "      <td>95.350000</td>\n",
              "      <td>optimizer=RMSprop,loss_function=MSELoss,activa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>0.073030</td>\n",
              "      <td>96.120000</td>\n",
              "      <td>optimizer=RMSprop,loss_function=MSELoss,activa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.2</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>0.160777</td>\n",
              "      <td>94.790000</td>\n",
              "      <td>optimizer=RMSprop,loss_function=MSELoss,activa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>0.110517</td>\n",
              "      <td>95.268333</td>\n",
              "      <td>optimizer=RMSprop,loss_function=MSELoss,activa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.5</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>0.357169</td>\n",
              "      <td>90.923333</td>\n",
              "      <td>optimizer=RMSprop,loss_function=MSELoss,activa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>0.225846</td>\n",
              "      <td>93.965000</td>\n",
              "      <td>optimizer=RMSprop,loss_function=MSELoss,activa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>1.018835</td>\n",
              "      <td>96.258333</td>\n",
              "      <td>optimizer=RMSprop,loss_function=CrossEntropyLo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>0.952944</td>\n",
              "      <td>96.370000</td>\n",
              "      <td>optimizer=RMSprop,loss_function=CrossEntropyLo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.2</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>1.818515</td>\n",
              "      <td>95.876667</td>\n",
              "      <td>optimizer=RMSprop,loss_function=CrossEntropyLo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>1.544202</td>\n",
              "      <td>95.756667</td>\n",
              "      <td>optimizer=RMSprop,loss_function=CrossEntropyLo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.5</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>4.242688</td>\n",
              "      <td>93.061667</td>\n",
              "      <td>optimizer=RMSprop,loss_function=CrossEntropyLo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>3.091164</td>\n",
              "      <td>94.046667</td>\n",
              "      <td>optimizer=RMSprop,loss_function=CrossEntropyLo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f13c8209-d6fe-4c45-83d2-03b144cc4d75')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f13c8209-d6fe-4c45-83d2-03b144cc4d75 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f13c8209-d6fe-4c45-83d2-03b144cc4d75');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c3b960ef-b9aa-4b82-9b28-8eb4958700c1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c3b960ef-b9aa-4b82-9b28-8eb4958700c1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c3b960ef-b9aa-4b82-9b28-8eb4958700c1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5857cffa-23bc-4e55-8e45-927ee9a8241e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5857cffa-23bc-4e55-8e45-927ee9a8241e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "2iDMDRf7WQGm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = [optim.Adam, optim.SGD, optim.RMSprop]\n",
        "loss_functions = [nn.MSELoss(), nn.CrossEntropyLoss(), ]\n",
        "dropouts = [0.0, 0.1, 0.2]\n",
        "activation_functions = [nn.ReLU(), nn.Sigmoid()]\n",
        "\n",
        "result = {\"optimizer\":[], \"loss_function\": [], \"dropout\":[],\n",
        "          \"activation_function\": [],\n",
        "          \"training_loss\": [], \"test_accuracy\": [], \"name\": []}\n",
        "\n",
        "\n",
        "def train_and_evaluate(optimizer, loss_function, dropout, activation_function, train_loader, test_loader, result):\n",
        "    result[\"optimizer\"].append(optimizer.__name__)\n",
        "    result[\"loss_function\"].append(loss_function.__class__.__name__)\n",
        "    result[\"activation_function\"].append(activation_function.__class__.__name__)\n",
        "    result[\"dropout\"].append(dropout)\n",
        "\n",
        "    name = []\n",
        "    for key in [\"optimizer\", \"loss_function\", \"activation_function\", \"dropout\"]:\n",
        "        name.append(f'{key}={result[key][-1]}')\n",
        "\n",
        "    result[\"name\"].append(\",\".join(name))\n",
        "\n",
        "    print(f'''\\n\\tTraining {result[\"name\"][-1]}\\n''')\n",
        "\n",
        "    model = MLP_Flex(activation_function=activation_function, dropout=dropout)\n",
        "    model, training_loss = training(num_epochs = 5,\n",
        "                                    model = model,\n",
        "                                    criterion = loss_function,\n",
        "                                    optimizer = optimizer(model.parameters(), lr=0.001),\n",
        "                                    verbose = False)\n",
        "    correct, total, predictions = evaluation(model=model, test_data=test_loader)\n",
        "\n",
        "    result[\"training_loss\"].append(training_loss)\n",
        "    result[\"test_accuracy\"].append(correct/total*100)\n",
        "\n",
        "import threading\n",
        "\n",
        "threads = []\n",
        "for optimizer in optimizers:\n",
        "    for loss_function in loss_functions:\n",
        "        for dropout in dropouts:\n",
        "            for activation_function in activation_functions:\n",
        "                print(\"starting thread\")\n",
        "                thread = threading.Thread(\n",
        "                    target = train_and_evaluate,\n",
        "                    args = (optimizer, loss_function,\n",
        "                            dropout, activation_function,\n",
        "                            train_loader, test_loader, result)\n",
        "                )\n",
        "                threads.append(thread)\n",
        "                thread.start()\n",
        "\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "\n",
        "import pandas as pd\n",
        "result_df = pd.DataFrame(result)\n",
        "result_df"
      ],
      "metadata": {
        "id": "ViCNn2PzEYVB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e619d0d8-ba58-4fbc-ed27-be332d1d6bb3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting thread\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=MSELoss,activation_function=ReLU,dropout=0.0\n",
            "starting thread\n",
            "\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.0\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=MSELoss,activation_function=ReLU,dropout=0.1\n",
            "starting thread\n",
            "\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.1\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=MSELoss,activation_function=ReLU,dropout=0.2\n",
            "starting thread\n",
            "\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.2\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.0\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.0\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.1\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.1\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.2\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=Adam,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.2\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=MSELoss,activation_function=ReLU,dropout=0.0\n",
            "starting thread\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.0\n",
            "starting thread\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=MSELoss,activation_function=ReLU,dropout=0.1\n",
            "starting thread\n",
            "\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.1\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=MSELoss,activation_function=ReLU,dropout=0.2\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.2\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.0\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.0\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.1\n",
            "\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.1\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.2\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=SGD,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.2\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=MSELoss,activation_function=ReLU,dropout=0.0\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.0\n",
            "\n",
            "starting thread\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=MSELoss,activation_function=ReLU,dropout=0.1\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.1\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=MSELoss,activation_function=ReLU,dropout=0.2\n",
            "\n",
            "starting thread\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=MSELoss,activation_function=Sigmoid,dropout=0.2\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.0\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.0\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.1\n",
            "\n",
            "starting thread\n",
            "\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.1\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=CrossEntropyLoss,activation_function=ReLU,dropout=0.2\n",
            "\n",
            "starting thread\n",
            "\n",
            "\tTraining optimizer=RMSprop,loss_function=CrossEntropyLoss,activation_function=Sigmoid,dropout=0.2\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-656da7f0a2f7>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import threading\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import ParameterGrid\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.datasets import load_iris\n",
        "\n",
        "# # Function to train and evaluate a model with given hyperparameters\n",
        "# def train_and_evaluate_model(X_train, y_train, X_test, y_test, params, results):\n",
        "#     model = SVC(**params)\n",
        "#     model.fit(X_train, y_train)\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     accuracy = accuracy_score(y_test, y_pred)\n",
        "#     results[str(params)] = accuracy\n",
        "\n",
        "# # Load dataset\n",
        "# iris = load_iris()\n",
        "# X, y = iris.data, iris.target\n",
        "\n",
        "# # Split dataset into train and test sets\n",
        "# split_index = int(0.8 * len(X))\n",
        "# X_train, X_test = X[:split_index], X[split_index:]\n",
        "# y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "# # Define hyperparameters to search\n",
        "# param_grid = {\n",
        "#     'C': [0.1, 1, 10],\n",
        "#     'kernel': ['linear', 'rbf', 'poly'],\n",
        "#     'gamma': ['scale', 'auto']\n",
        "# }\n",
        "\n",
        "# # Create parameter combinations\n",
        "# param_combinations = list(ParameterGrid(param_grid))\n",
        "\n",
        "# # Define function to perform hyperparameter search using multi-threading\n",
        "# def hyperparameter_search(results):\n",
        "#     threads = []\n",
        "#     for params in param_combinations:\n",
        "#         print(\"Start thread\")\n",
        "#         thread = threading.Thread(\n",
        "#             target=train_and_evaluate_model, args=(X_train, y_train, X_test, y_test, params, results)\n",
        "#             )\n",
        "#         threads.append(thread)\n",
        "#         thread.start()\n",
        "\n",
        "#     for thread in threads:\n",
        "#         thread.join()\n",
        "\n",
        "# # Perform hyperparameter search\n",
        "# results = {}\n",
        "# hyperparameter_search(results)\n",
        "\n",
        "# # Print results\n",
        "# for params, accuracy in results.items():\n",
        "#     print(f\"Parameters: {params}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUekUx-u-q1F",
        "outputId": "0830c451-6712-4749-8f8b-68d62b6eff09"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Start thread\n",
            "Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}, Accuracy: 0.6667\n",
            "Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}, Accuracy: 0.0000\n",
            "Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'poly'}, Accuracy: 0.8333\n",
            "Parameters: {'C': 0.1, 'gamma': 'auto', 'kernel': 'linear'}, Accuracy: 0.6667\n",
            "Parameters: {'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}, Accuracy: 0.2667\n",
            "Parameters: {'C': 0.1, 'gamma': 'auto', 'kernel': 'poly'}, Accuracy: 0.8000\n",
            "Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}, Accuracy: 0.8667\n",
            "Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}, Accuracy: 0.7000\n",
            "Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'poly'}, Accuracy: 0.8333\n",
            "Parameters: {'C': 1, 'gamma': 'auto', 'kernel': 'linear'}, Accuracy: 0.8667\n",
            "Parameters: {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}, Accuracy: 0.8333\n",
            "Parameters: {'C': 1, 'gamma': 'auto', 'kernel': 'poly'}, Accuracy: 0.7667\n",
            "Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}, Accuracy: 0.8667\n",
            "Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}, Accuracy: 0.8333\n",
            "Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}, Accuracy: 0.8333\n",
            "Parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'linear'}, Accuracy: 0.8667\n",
            "Parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}, Accuracy: 0.8333\n",
            "Parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'poly'}, Accuracy: 0.7667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "McFgOcFD_57A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}