{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10cb9218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training optimizer=type,loss=CrossEntropyLoss,activation=ReLU,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0659 val_loss=2.0380 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=2.0270 val_loss=2.0154 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 3, train_loss=2.0089 val_loss=2.0107 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=1.9947 val_loss=2.0027 train_f1_score=0.3550 train_accuracy=0.2393 val_f1_score=0.3084 val_accuracy=0.2089\n",
      "\n",
      "Epoch 5, train_loss=1.9692 val_loss=1.9929 train_f1_score=0.3627 train_accuracy=0.2504 val_f1_score=0.3025 val_accuracy=0.2025\n",
      "\n",
      "Epoch 6, train_loss=1.9468 val_loss=1.9962 train_f1_score=0.3637 train_accuracy=0.2631 val_f1_score=0.2527 val_accuracy=0.1772\n",
      "\n",
      "Epoch 7, train_loss=1.9340 val_loss=1.9939 train_f1_score=0.3789 train_accuracy=0.2884 val_f1_score=0.2613 val_accuracy=0.1962\n",
      "\n",
      "Epoch 8, train_loss=1.8982 val_loss=1.9896 train_f1_score=0.3998 train_accuracy=0.3138 val_f1_score=0.2681 val_accuracy=0.2025\n",
      "\n",
      "Epoch 9, train_loss=1.8671 val_loss=1.9724 train_f1_score=0.3934 train_accuracy=0.2948 val_f1_score=0.2850 val_accuracy=0.2089\n",
      "\n",
      "Epoch 10, train_loss=1.8580 val_loss=1.9718 train_f1_score=0.3898 train_accuracy=0.3249 val_f1_score=0.2649 val_accuracy=0.2025\n",
      "\n",
      "Epoch 11, train_loss=1.8175 val_loss=1.9494 train_f1_score=0.4196 train_accuracy=0.3407 val_f1_score=0.2884 val_accuracy=0.2278\n",
      "\n",
      "Epoch 12, train_loss=1.7779 val_loss=1.9369 train_f1_score=0.4407 train_accuracy=0.3962 val_f1_score=0.2541 val_accuracy=0.2152\n",
      "\n",
      "Epoch 13, train_loss=1.7471 val_loss=1.9459 train_f1_score=0.4125 train_accuracy=0.3471 val_f1_score=0.3454 val_accuracy=0.2658\n",
      "\n",
      "Epoch 14, train_loss=1.7474 val_loss=1.9261 train_f1_score=0.4500 train_accuracy=0.3756 val_f1_score=0.2953 val_accuracy=0.2405\n",
      "\n",
      "Epoch 15, train_loss=1.6956 val_loss=1.9519 train_f1_score=0.4563 train_accuracy=0.3851 val_f1_score=0.2869 val_accuracy=0.2342\n",
      "\n",
      "Epoch 16, train_loss=1.6606 val_loss=1.9367 train_f1_score=0.4806 train_accuracy=0.4374 val_f1_score=0.2955 val_accuracy=0.2532\n",
      "\n",
      "Epoch 17, train_loss=1.6391 val_loss=1.9196 train_f1_score=0.4834 train_accuracy=0.4532 val_f1_score=0.3124 val_accuracy=0.2785\n",
      "\n",
      "Epoch 18, train_loss=1.6201 val_loss=1.9420 train_f1_score=0.5176 train_accuracy=0.4628 val_f1_score=0.3130 val_accuracy=0.2595\n",
      "\n",
      "Epoch 19, train_loss=1.5544 val_loss=1.9256 train_f1_score=0.5063 train_accuracy=0.4596 val_f1_score=0.2896 val_accuracy=0.2405\n",
      "\n",
      "Epoch 20, train_loss=1.5243 val_loss=1.9079 train_f1_score=0.5205 train_accuracy=0.4881 val_f1_score=0.3340 val_accuracy=0.2975\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.5243 val_loss=1.9079 train_f1_score=0.5205 train_accuracy=0.4881 val_f1_score=0.3340 val_accuracy=0.2975\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=ReLU,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0786 val_loss=2.0842 train_f1_score=0.1941 train_accuracy=0.1094 val_f1_score=0.1722 val_accuracy=0.0949\n",
      "\n",
      "Epoch 2, train_loss=2.0783 val_loss=2.0842 train_f1_score=0.1855 train_accuracy=0.1046 val_f1_score=0.1720 val_accuracy=0.0949\n",
      "\n",
      "Epoch 3, train_loss=2.0783 val_loss=2.0841 train_f1_score=0.1855 train_accuracy=0.1046 val_f1_score=0.1719 val_accuracy=0.0949\n",
      "\n",
      "Epoch 4, train_loss=2.0782 val_loss=2.0841 train_f1_score=0.1855 train_accuracy=0.1046 val_f1_score=0.1718 val_accuracy=0.0949\n",
      "\n",
      "Epoch 5, train_loss=2.0784 val_loss=2.0840 train_f1_score=0.1855 train_accuracy=0.1046 val_f1_score=0.1718 val_accuracy=0.0949\n",
      "\n",
      "Epoch 6, train_loss=2.0784 val_loss=2.0840 train_f1_score=0.1876 train_accuracy=0.1078 val_f1_score=0.1769 val_accuracy=0.1013\n",
      "\n",
      "Epoch 7, train_loss=2.0781 val_loss=2.0840 train_f1_score=0.1866 train_accuracy=0.1062 val_f1_score=0.1718 val_accuracy=0.0949\n",
      "\n",
      "Epoch 8, train_loss=2.0782 val_loss=2.0839 train_f1_score=0.1865 train_accuracy=0.1062 val_f1_score=0.1718 val_accuracy=0.0949\n",
      "\n",
      "Epoch 9, train_loss=2.0781 val_loss=2.0839 train_f1_score=0.1894 train_accuracy=0.1078 val_f1_score=0.1718 val_accuracy=0.0949\n",
      "\n",
      "Epoch 10, train_loss=2.0781 val_loss=2.0839 train_f1_score=0.1894 train_accuracy=0.1078 val_f1_score=0.1718 val_accuracy=0.0949\n",
      "\n",
      "Epoch 11, train_loss=2.0782 val_loss=2.0838 train_f1_score=0.1893 train_accuracy=0.1078 val_f1_score=0.1718 val_accuracy=0.0949\n",
      "\n",
      "Epoch 12, train_loss=2.0781 val_loss=2.0838 train_f1_score=0.1893 train_accuracy=0.1078 val_f1_score=0.1718 val_accuracy=0.0949\n",
      "\n",
      "Epoch 13, train_loss=2.0780 val_loss=2.0838 train_f1_score=0.1893 train_accuracy=0.1078 val_f1_score=0.1718 val_accuracy=0.0949\n",
      "\n",
      "Epoch 14, train_loss=2.0780 val_loss=2.0837 train_f1_score=0.1884 train_accuracy=0.1062 val_f1_score=0.1718 val_accuracy=0.0949\n",
      "\n",
      "Epoch 15, train_loss=2.0779 val_loss=2.0837 train_f1_score=0.1884 train_accuracy=0.1062 val_f1_score=0.1718 val_accuracy=0.0949\n",
      "\n",
      "Epoch 16, train_loss=2.0780 val_loss=2.0837 train_f1_score=0.1884 train_accuracy=0.1062 val_f1_score=0.1719 val_accuracy=0.0949\n",
      "\n",
      "Epoch 17, train_loss=2.0780 val_loss=2.0836 train_f1_score=0.1884 train_accuracy=0.1062 val_f1_score=0.1719 val_accuracy=0.0949\n",
      "\n",
      "Epoch 18, train_loss=2.0780 val_loss=2.0836 train_f1_score=0.1893 train_accuracy=0.1078 val_f1_score=0.1719 val_accuracy=0.0949\n",
      "\n",
      "Epoch 19, train_loss=2.0779 val_loss=2.0836 train_f1_score=0.1893 train_accuracy=0.1078 val_f1_score=0.1719 val_accuracy=0.0949\n",
      "\n",
      "Epoch 20, train_loss=2.0778 val_loss=2.0835 train_f1_score=0.1893 train_accuracy=0.1078 val_f1_score=0.1719 val_accuracy=0.0949\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.0778 val_loss=2.0835 train_f1_score=0.1893 train_accuracy=0.1078 val_f1_score=0.1719 val_accuracy=0.0949\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=ReLU,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0454 val_loss=2.0112 train_f1_score=0.3579 train_accuracy=0.2567 val_f1_score=0.2696 val_accuracy=0.1899\n",
      "\n",
      "Epoch 2, train_loss=1.9875 val_loss=1.9773 train_f1_score=0.3835 train_accuracy=0.2821 val_f1_score=0.2773 val_accuracy=0.2089\n",
      "\n",
      "Epoch 3, train_loss=1.9493 val_loss=1.9873 train_f1_score=0.4006 train_accuracy=0.3011 val_f1_score=0.3018 val_accuracy=0.2342\n",
      "\n",
      "Epoch 4, train_loss=1.9135 val_loss=1.9583 train_f1_score=0.4006 train_accuracy=0.3043 val_f1_score=0.2709 val_accuracy=0.2089\n",
      "\n",
      "Epoch 5, train_loss=1.8852 val_loss=1.9657 train_f1_score=0.4043 train_accuracy=0.3138 val_f1_score=0.2864 val_accuracy=0.2278\n",
      "\n",
      "Epoch 6, train_loss=1.8440 val_loss=1.9748 train_f1_score=0.4202 train_accuracy=0.3439 val_f1_score=0.2652 val_accuracy=0.2215\n",
      "\n",
      "Epoch 7, train_loss=1.8401 val_loss=1.9579 train_f1_score=0.4204 train_accuracy=0.3455 val_f1_score=0.2804 val_accuracy=0.2278\n",
      "\n",
      "Epoch 8, train_loss=1.7866 val_loss=1.9226 train_f1_score=0.4364 train_accuracy=0.3582 val_f1_score=0.3389 val_accuracy=0.2785\n",
      "\n",
      "Epoch 9, train_loss=1.7872 val_loss=1.9167 train_f1_score=0.4391 train_accuracy=0.3740 val_f1_score=0.3162 val_accuracy=0.2722\n",
      "\n",
      "Epoch 10, train_loss=1.7694 val_loss=1.8837 train_f1_score=0.4605 train_accuracy=0.4231 val_f1_score=0.2742 val_accuracy=0.2658\n",
      "\n",
      "Epoch 11, train_loss=1.7311 val_loss=1.9083 train_f1_score=0.4709 train_accuracy=0.4200 val_f1_score=0.3162 val_accuracy=0.2848\n",
      "\n",
      "Epoch 12, train_loss=1.6813 val_loss=1.9082 train_f1_score=0.4929 train_accuracy=0.4532 val_f1_score=0.2858 val_accuracy=0.2595\n",
      "\n",
      "Epoch 13, train_loss=1.6462 val_loss=1.8807 train_f1_score=0.4888 train_accuracy=0.4532 val_f1_score=0.2814 val_accuracy=0.2595\n",
      "\n",
      "Epoch 14, train_loss=1.6201 val_loss=1.9104 train_f1_score=0.4695 train_accuracy=0.4120 val_f1_score=0.2904 val_accuracy=0.2405\n",
      "\n",
      "Epoch 15, train_loss=1.5768 val_loss=1.9353 train_f1_score=0.5224 train_accuracy=0.4913 val_f1_score=0.2777 val_accuracy=0.2468\n",
      "\n",
      "Epoch 16, train_loss=1.6024 val_loss=1.9075 train_f1_score=0.5651 train_accuracy=0.5293 val_f1_score=0.3178 val_accuracy=0.2911\n",
      "\n",
      "Epoch 17, train_loss=1.5296 val_loss=1.9409 train_f1_score=0.5288 train_accuracy=0.4865 val_f1_score=0.3526 val_accuracy=0.2975\n",
      "\n",
      "Epoch 18, train_loss=1.5064 val_loss=2.1696 train_f1_score=0.4528 train_accuracy=0.3788 val_f1_score=0.3667 val_accuracy=0.2785\n",
      "\n",
      "Epoch 19, train_loss=1.4398 val_loss=1.9936 train_f1_score=0.5581 train_accuracy=0.5341 val_f1_score=0.2691 val_accuracy=0.2342\n",
      "\n",
      "Epoch 20, train_loss=1.4207 val_loss=1.9114 train_f1_score=0.5914 train_accuracy=0.5737 val_f1_score=0.2899 val_accuracy=0.2658\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.4207 val_loss=1.9114 train_f1_score=0.5914 train_accuracy=0.5737 val_f1_score=0.2899 val_accuracy=0.2658\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=ReLU,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0359 val_loss=2.0192 train_f1_score=0.3372 train_accuracy=0.2266 val_f1_score=0.2920 val_accuracy=0.1899\n",
      "\n",
      "Epoch 2, train_loss=2.0087 val_loss=2.0110 train_f1_score=0.3217 train_accuracy=0.2235 val_f1_score=0.3003 val_accuracy=0.2089\n",
      "\n",
      "Epoch 3, train_loss=1.9791 val_loss=2.0139 train_f1_score=0.3545 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=1.9608 val_loss=2.0099 train_f1_score=0.3482 train_accuracy=0.2219 val_f1_score=0.3238 val_accuracy=0.1962\n",
      "\n",
      "Epoch 5, train_loss=1.9543 val_loss=1.9778 train_f1_score=0.3282 train_accuracy=0.2678 val_f1_score=0.2556 val_accuracy=0.2089\n",
      "\n",
      "Epoch 6, train_loss=1.9228 val_loss=1.9751 train_f1_score=0.3374 train_accuracy=0.2821 val_f1_score=0.2134 val_accuracy=0.1709\n",
      "\n",
      "Epoch 7, train_loss=1.9093 val_loss=1.9918 train_f1_score=0.3645 train_accuracy=0.2758 val_f1_score=0.2885 val_accuracy=0.2342\n",
      "\n",
      "Epoch 8, train_loss=1.8564 val_loss=1.9699 train_f1_score=0.3432 train_accuracy=0.2979 val_f1_score=0.2738 val_accuracy=0.2025\n",
      "\n",
      "Epoch 9, train_loss=1.8065 val_loss=1.9669 train_f1_score=0.3910 train_accuracy=0.3344 val_f1_score=0.2189 val_accuracy=0.1772\n",
      "\n",
      "Epoch 10, train_loss=1.7637 val_loss=1.9549 train_f1_score=0.4225 train_accuracy=0.3645 val_f1_score=0.2348 val_accuracy=0.1962\n",
      "\n",
      "Epoch 11, train_loss=1.7577 val_loss=2.0476 train_f1_score=0.3405 train_accuracy=0.3074 val_f1_score=0.2309 val_accuracy=0.2089\n",
      "\n",
      "Epoch 12, train_loss=1.7621 val_loss=1.9323 train_f1_score=0.4400 train_accuracy=0.3867 val_f1_score=0.2915 val_accuracy=0.2468\n",
      "\n",
      "Epoch 13, train_loss=1.6116 val_loss=2.1085 train_f1_score=0.4272 train_accuracy=0.3962 val_f1_score=0.3002 val_accuracy=0.2785\n",
      "\n",
      "Epoch 14, train_loss=1.5588 val_loss=1.9492 train_f1_score=0.4684 train_accuracy=0.4517 val_f1_score=0.3043 val_accuracy=0.2658\n",
      "\n",
      "Epoch 15, train_loss=1.5017 val_loss=2.0765 train_f1_score=0.4733 train_accuracy=0.4564 val_f1_score=0.2579 val_accuracy=0.2342\n",
      "\n",
      "Epoch 16, train_loss=1.3985 val_loss=2.2197 train_f1_score=0.5259 train_accuracy=0.4945 val_f1_score=0.2813 val_accuracy=0.2405\n",
      "\n",
      "Epoch 17, train_loss=1.3299 val_loss=2.1051 train_f1_score=0.5652 train_accuracy=0.5468 val_f1_score=0.3605 val_accuracy=0.3228\n",
      "\n",
      "Epoch 18, train_loss=1.2718 val_loss=2.1020 train_f1_score=0.5947 train_accuracy=0.5975 val_f1_score=0.2040 val_accuracy=0.2089\n",
      "\n",
      "Epoch 19, train_loss=1.0857 val_loss=2.2688 train_f1_score=0.6841 train_accuracy=0.6672 val_f1_score=0.3677 val_accuracy=0.3354\n",
      "\n",
      "Epoch 20, train_loss=0.9671 val_loss=2.0582 train_f1_score=0.7313 train_accuracy=0.7021 val_f1_score=0.3352 val_accuracy=0.3165\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=0.9671 val_loss=2.0582 train_f1_score=0.7313 train_accuracy=0.7021 val_f1_score=0.3352 val_accuracy=0.3165\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=ReLU,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0729 val_loss=2.0668 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=2.0725 val_loss=2.0663 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 3, train_loss=2.0721 val_loss=2.0659 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=2.0720 val_loss=2.0655 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 5, train_loss=2.0716 val_loss=2.0652 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 6, train_loss=2.0712 val_loss=2.0648 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 7, train_loss=2.0710 val_loss=2.0644 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 8, train_loss=2.0703 val_loss=2.0641 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 9, train_loss=2.0702 val_loss=2.0637 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 10, train_loss=2.0702 val_loss=2.0634 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 11, train_loss=2.0699 val_loss=2.0630 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 12, train_loss=2.0693 val_loss=2.0627 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 13, train_loss=2.0689 val_loss=2.0623 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 14, train_loss=2.0688 val_loss=2.0620 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 15, train_loss=2.0684 val_loss=2.0616 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 16, train_loss=2.0685 val_loss=2.0613 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 17, train_loss=2.0680 val_loss=2.0610 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 18, train_loss=2.0675 val_loss=2.0607 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 19, train_loss=2.0678 val_loss=2.0604 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 20, train_loss=2.0671 val_loss=2.0601 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.0671 val_loss=2.0601 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=ReLU,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=3.3857 val_loss=2.0242 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=2.0296 val_loss=2.0171 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 3, train_loss=2.0004 val_loss=1.9730 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=1.9643 val_loss=1.9665 train_f1_score=0.3714 train_accuracy=0.2520 val_f1_score=0.3087 val_accuracy=0.2025\n",
      "\n",
      "Epoch 5, train_loss=1.9231 val_loss=1.9284 train_f1_score=0.3520 train_accuracy=0.2235 val_f1_score=0.3242 val_accuracy=0.1962\n",
      "\n",
      "Epoch 6, train_loss=1.8750 val_loss=1.9814 train_f1_score=0.3667 train_accuracy=0.2393 val_f1_score=0.3255 val_accuracy=0.2025\n",
      "\n",
      "Epoch 7, train_loss=1.8598 val_loss=1.9110 train_f1_score=0.3761 train_accuracy=0.2599 val_f1_score=0.3736 val_accuracy=0.2658\n",
      "\n",
      "Epoch 8, train_loss=1.8505 val_loss=1.9502 train_f1_score=0.3864 train_accuracy=0.2567 val_f1_score=0.3226 val_accuracy=0.2025\n",
      "\n",
      "Epoch 9, train_loss=1.8433 val_loss=1.8846 train_f1_score=0.3640 train_accuracy=0.2662 val_f1_score=0.3249 val_accuracy=0.2342\n",
      "\n",
      "Epoch 10, train_loss=1.8697 val_loss=1.8890 train_f1_score=0.4180 train_accuracy=0.3471 val_f1_score=0.3543 val_accuracy=0.2722\n",
      "\n",
      "Epoch 11, train_loss=1.8390 val_loss=1.8856 train_f1_score=0.3923 train_accuracy=0.2932 val_f1_score=0.3133 val_accuracy=0.2342\n",
      "\n",
      "Epoch 12, train_loss=1.7906 val_loss=1.9136 train_f1_score=0.4172 train_accuracy=0.3328 val_f1_score=0.3499 val_accuracy=0.2785\n",
      "\n",
      "Epoch 13, train_loss=1.7845 val_loss=1.8602 train_f1_score=0.4494 train_accuracy=0.3534 val_f1_score=0.3675 val_accuracy=0.2848\n",
      "\n",
      "Epoch 14, train_loss=1.7687 val_loss=1.8496 train_f1_score=0.4402 train_accuracy=0.3344 val_f1_score=0.3744 val_accuracy=0.2785\n",
      "\n",
      "Epoch 15, train_loss=1.7292 val_loss=1.9056 train_f1_score=0.3902 train_accuracy=0.3011 val_f1_score=0.3598 val_accuracy=0.2785\n",
      "\n",
      "Epoch 16, train_loss=1.7246 val_loss=1.9472 train_f1_score=0.4083 train_accuracy=0.3281 val_f1_score=0.3123 val_accuracy=0.2532\n",
      "\n",
      "Epoch 17, train_loss=1.7344 val_loss=1.8880 train_f1_score=0.4699 train_accuracy=0.3677 val_f1_score=0.4008 val_accuracy=0.3038\n",
      "\n",
      "Epoch 18, train_loss=1.6909 val_loss=1.8795 train_f1_score=0.4233 train_accuracy=0.3597 val_f1_score=0.3149 val_accuracy=0.2658\n",
      "\n",
      "Epoch 19, train_loss=1.6847 val_loss=1.8931 train_f1_score=0.4210 train_accuracy=0.3455 val_f1_score=0.3935 val_accuracy=0.3101\n",
      "\n",
      "Epoch 20, train_loss=1.6525 val_loss=1.9678 train_f1_score=0.4574 train_accuracy=0.3740 val_f1_score=0.3548 val_accuracy=0.2785\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.6525 val_loss=1.9678 train_f1_score=0.4574 train_accuracy=0.3740 val_f1_score=0.3548 val_accuracy=0.2785\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=ReLU,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0629 val_loss=2.0292 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=2.0319 val_loss=2.0143 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 3, train_loss=2.0127 val_loss=2.0025 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=2.0162 val_loss=1.9869 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 5, train_loss=1.9997 val_loss=1.9741 train_f1_score=0.3507 train_accuracy=0.2235 val_f1_score=0.3251 val_accuracy=0.2025\n",
      "\n",
      "Epoch 6, train_loss=1.9742 val_loss=1.9476 train_f1_score=0.3582 train_accuracy=0.2393 val_f1_score=0.3244 val_accuracy=0.2152\n",
      "\n",
      "Epoch 7, train_loss=1.9485 val_loss=1.9349 train_f1_score=0.3826 train_accuracy=0.2742 val_f1_score=0.3277 val_accuracy=0.2278\n",
      "\n",
      "Epoch 8, train_loss=1.9372 val_loss=1.9216 train_f1_score=0.3869 train_accuracy=0.2789 val_f1_score=0.3127 val_accuracy=0.2152\n",
      "\n",
      "Epoch 9, train_loss=1.9242 val_loss=1.9106 train_f1_score=0.3902 train_accuracy=0.2932 val_f1_score=0.2834 val_accuracy=0.2089\n",
      "\n",
      "Epoch 10, train_loss=1.8944 val_loss=1.8968 train_f1_score=0.4003 train_accuracy=0.2932 val_f1_score=0.3204 val_accuracy=0.2278\n",
      "\n",
      "Epoch 11, train_loss=1.8719 val_loss=1.8943 train_f1_score=0.4216 train_accuracy=0.3233 val_f1_score=0.2890 val_accuracy=0.2215\n",
      "\n",
      "Epoch 12, train_loss=1.8655 val_loss=1.8980 train_f1_score=0.4199 train_accuracy=0.3170 val_f1_score=0.3067 val_accuracy=0.2278\n",
      "\n",
      "Epoch 13, train_loss=1.8481 val_loss=1.8950 train_f1_score=0.4049 train_accuracy=0.3122 val_f1_score=0.3030 val_accuracy=0.2342\n",
      "\n",
      "Epoch 14, train_loss=1.8344 val_loss=1.8812 train_f1_score=0.4047 train_accuracy=0.3154 val_f1_score=0.2945 val_accuracy=0.2278\n",
      "\n",
      "Epoch 15, train_loss=1.8215 val_loss=1.8792 train_f1_score=0.4216 train_accuracy=0.3233 val_f1_score=0.3490 val_accuracy=0.2595\n",
      "\n",
      "Epoch 16, train_loss=1.7856 val_loss=1.8818 train_f1_score=0.4264 train_accuracy=0.3328 val_f1_score=0.3098 val_accuracy=0.2342\n",
      "\n",
      "Epoch 17, train_loss=1.8033 val_loss=1.8786 train_f1_score=0.4387 train_accuracy=0.3629 val_f1_score=0.2978 val_accuracy=0.2342\n",
      "\n",
      "Epoch 18, train_loss=1.7744 val_loss=1.8983 train_f1_score=0.4458 train_accuracy=0.3439 val_f1_score=0.3020 val_accuracy=0.2215\n",
      "\n",
      "Epoch 19, train_loss=1.7751 val_loss=1.8735 train_f1_score=0.4320 train_accuracy=0.3661 val_f1_score=0.2700 val_accuracy=0.2152\n",
      "\n",
      "Epoch 20, train_loss=1.7553 val_loss=1.9041 train_f1_score=0.4551 train_accuracy=0.3597 val_f1_score=0.2911 val_accuracy=0.2215\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.7553 val_loss=1.9041 train_f1_score=0.4551 train_accuracy=0.3597 val_f1_score=0.2911 val_accuracy=0.2215\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=ReLU,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0761 val_loss=2.0722 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=2.0764 val_loss=2.0721 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 3, train_loss=2.0758 val_loss=2.0720 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=2.0757 val_loss=2.0720 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 5, train_loss=2.0761 val_loss=2.0719 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 6, train_loss=2.0767 val_loss=2.0719 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 7, train_loss=2.0757 val_loss=2.0718 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 8, train_loss=2.0763 val_loss=2.0718 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 9, train_loss=2.0755 val_loss=2.0718 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 10, train_loss=2.0758 val_loss=2.0717 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 11, train_loss=2.0752 val_loss=2.0717 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 12, train_loss=2.0763 val_loss=2.0717 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 13, train_loss=2.0749 val_loss=2.0716 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 14, train_loss=2.0755 val_loss=2.0716 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 15, train_loss=2.0760 val_loss=2.0716 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 16, train_loss=2.0755 val_loss=2.0715 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 17, train_loss=2.0758 val_loss=2.0715 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 18, train_loss=2.0751 val_loss=2.0714 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 19, train_loss=2.0749 val_loss=2.0714 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 20, train_loss=2.0754 val_loss=2.0714 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.0754 val_loss=2.0714 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=ReLU,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0635 val_loss=2.0101 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=1.9674 val_loss=1.9334 train_f1_score=0.3415 train_accuracy=0.2219 val_f1_score=0.3370 val_accuracy=0.2089\n",
      "\n",
      "Epoch 3, train_loss=1.9151 val_loss=1.8855 train_f1_score=0.3599 train_accuracy=0.2710 val_f1_score=0.3600 val_accuracy=0.2658\n",
      "\n",
      "Epoch 4, train_loss=1.8802 val_loss=1.8542 train_f1_score=0.4385 train_accuracy=0.3550 val_f1_score=0.3936 val_accuracy=0.2975\n",
      "\n",
      "Epoch 5, train_loss=1.8327 val_loss=1.8424 train_f1_score=0.4052 train_accuracy=0.3423 val_f1_score=0.3532 val_accuracy=0.2975\n",
      "\n",
      "Epoch 6, train_loss=1.8214 val_loss=1.8489 train_f1_score=0.4127 train_accuracy=0.3645 val_f1_score=0.3339 val_accuracy=0.2848\n",
      "\n",
      "Epoch 7, train_loss=1.8087 val_loss=1.8186 train_f1_score=0.4228 train_accuracy=0.3629 val_f1_score=0.3294 val_accuracy=0.2658\n",
      "\n",
      "Epoch 8, train_loss=1.7821 val_loss=1.8103 train_f1_score=0.4365 train_accuracy=0.3740 val_f1_score=0.3253 val_accuracy=0.2658\n",
      "\n",
      "Epoch 9, train_loss=1.7820 val_loss=1.8000 train_f1_score=0.4423 train_accuracy=0.4010 val_f1_score=0.3410 val_accuracy=0.2911\n",
      "\n",
      "Epoch 10, train_loss=1.7498 val_loss=1.8062 train_f1_score=0.4400 train_accuracy=0.3899 val_f1_score=0.3706 val_accuracy=0.3165\n",
      "\n",
      "Epoch 11, train_loss=1.7420 val_loss=1.7902 train_f1_score=0.4307 train_accuracy=0.4025 val_f1_score=0.3210 val_accuracy=0.2785\n",
      "\n",
      "Epoch 12, train_loss=1.7190 val_loss=1.8130 train_f1_score=0.4428 train_accuracy=0.3994 val_f1_score=0.3446 val_accuracy=0.2911\n",
      "\n",
      "Epoch 13, train_loss=1.6848 val_loss=1.8059 train_f1_score=0.4588 train_accuracy=0.4041 val_f1_score=0.3606 val_accuracy=0.2911\n",
      "\n",
      "Epoch 14, train_loss=1.6939 val_loss=1.7976 train_f1_score=0.4756 train_accuracy=0.4089 val_f1_score=0.3600 val_accuracy=0.2848\n",
      "\n",
      "Epoch 15, train_loss=1.6358 val_loss=1.8621 train_f1_score=0.4678 train_accuracy=0.4184 val_f1_score=0.3890 val_accuracy=0.3101\n",
      "\n",
      "Epoch 16, train_loss=1.6775 val_loss=1.8090 train_f1_score=0.4728 train_accuracy=0.4612 val_f1_score=0.3103 val_accuracy=0.2785\n",
      "\n",
      "Epoch 17, train_loss=1.6012 val_loss=1.7959 train_f1_score=0.4901 train_accuracy=0.4406 val_f1_score=0.3541 val_accuracy=0.2911\n",
      "\n",
      "Epoch 18, train_loss=1.6131 val_loss=1.7856 train_f1_score=0.5045 train_accuracy=0.4723 val_f1_score=0.3575 val_accuracy=0.2975\n",
      "\n",
      "Epoch 19, train_loss=1.5879 val_loss=1.7967 train_f1_score=0.5170 train_accuracy=0.4849 val_f1_score=0.3736 val_accuracy=0.3101\n",
      "\n",
      "Epoch 20, train_loss=1.5877 val_loss=1.7798 train_f1_score=0.5424 train_accuracy=0.5135 val_f1_score=0.3916 val_accuracy=0.3481\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.5877 val_loss=1.7798 train_f1_score=0.5424 train_accuracy=0.5135 val_f1_score=0.3916 val_accuracy=0.3481\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=ReLU,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0589 val_loss=2.0263 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=1.9841 val_loss=1.9558 train_f1_score=0.3536 train_accuracy=0.2567 val_f1_score=0.3818 val_accuracy=0.2975\n",
      "\n",
      "Epoch 3, train_loss=1.9372 val_loss=1.8635 train_f1_score=0.4108 train_accuracy=0.3027 val_f1_score=0.3887 val_accuracy=0.2785\n",
      "\n",
      "Epoch 4, train_loss=1.9104 val_loss=1.8315 train_f1_score=0.4042 train_accuracy=0.2932 val_f1_score=0.4029 val_accuracy=0.2911\n",
      "\n",
      "Epoch 5, train_loss=1.8831 val_loss=1.8658 train_f1_score=0.3963 train_accuracy=0.3170 val_f1_score=0.3517 val_accuracy=0.2722\n",
      "\n",
      "Epoch 6, train_loss=1.8376 val_loss=1.8265 train_f1_score=0.4282 train_accuracy=0.3312 val_f1_score=0.3279 val_accuracy=0.2532\n",
      "\n",
      "Epoch 7, train_loss=1.8095 val_loss=1.8034 train_f1_score=0.4363 train_accuracy=0.3344 val_f1_score=0.4184 val_accuracy=0.3101\n",
      "\n",
      "Epoch 8, train_loss=1.7924 val_loss=1.8430 train_f1_score=0.4327 train_accuracy=0.3597 val_f1_score=0.3727 val_accuracy=0.2975\n",
      "\n",
      "Epoch 9, train_loss=1.7756 val_loss=1.7886 train_f1_score=0.4320 train_accuracy=0.3407 val_f1_score=0.3990 val_accuracy=0.3038\n",
      "\n",
      "Epoch 10, train_loss=1.7695 val_loss=1.8164 train_f1_score=0.4443 train_accuracy=0.3613 val_f1_score=0.3800 val_accuracy=0.2911\n",
      "\n",
      "Epoch 11, train_loss=1.7366 val_loss=1.7994 train_f1_score=0.4676 train_accuracy=0.3930 val_f1_score=0.3836 val_accuracy=0.3101\n",
      "\n",
      "Epoch 12, train_loss=1.6842 val_loss=1.7974 train_f1_score=0.4982 train_accuracy=0.4485 val_f1_score=0.3474 val_accuracy=0.3101\n",
      "\n",
      "Epoch 13, train_loss=1.6133 val_loss=1.7771 train_f1_score=0.4826 train_accuracy=0.4326 val_f1_score=0.3504 val_accuracy=0.3101\n",
      "\n",
      "Epoch 14, train_loss=1.5375 val_loss=1.8293 train_f1_score=0.5221 train_accuracy=0.4976 val_f1_score=0.3611 val_accuracy=0.3291\n",
      "\n",
      "Epoch 15, train_loss=1.4679 val_loss=1.8847 train_f1_score=0.5682 train_accuracy=0.5166 val_f1_score=0.3952 val_accuracy=0.3291\n",
      "\n",
      "Epoch 16, train_loss=1.3226 val_loss=1.9313 train_f1_score=0.5921 train_accuracy=0.5610 val_f1_score=0.4170 val_accuracy=0.3734\n",
      "\n",
      "Epoch 17, train_loss=1.3252 val_loss=1.8426 train_f1_score=0.6714 train_accuracy=0.6371 val_f1_score=0.3976 val_accuracy=0.3608\n",
      "\n",
      "Epoch 18, train_loss=1.1470 val_loss=1.9788 train_f1_score=0.7152 train_accuracy=0.7116 val_f1_score=0.3444 val_accuracy=0.3291\n",
      "\n",
      "Epoch 19, train_loss=0.9429 val_loss=2.1108 train_f1_score=0.7674 train_accuracy=0.7623 val_f1_score=0.3876 val_accuracy=0.3608\n",
      "\n",
      "Epoch 20, train_loss=1.0029 val_loss=1.9095 train_f1_score=0.8145 train_accuracy=0.8130 val_f1_score=0.3886 val_accuracy=0.3861\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.0029 val_loss=1.9095 train_f1_score=0.8145 train_accuracy=0.8130 val_f1_score=0.3886 val_accuracy=0.3861\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=ReLU,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0625 val_loss=2.0519 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=2.0622 val_loss=2.0516 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 3, train_loss=2.0619 val_loss=2.0514 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=2.0619 val_loss=2.0511 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 5, train_loss=2.0622 val_loss=2.0508 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 6, train_loss=2.0615 val_loss=2.0506 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 7, train_loss=2.0612 val_loss=2.0503 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 8, train_loss=2.0612 val_loss=2.0501 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 9, train_loss=2.0611 val_loss=2.0498 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 10, train_loss=2.0604 val_loss=2.0496 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 11, train_loss=2.0607 val_loss=2.0493 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 12, train_loss=2.0597 val_loss=2.0491 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 13, train_loss=2.0607 val_loss=2.0488 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 14, train_loss=2.0606 val_loss=2.0486 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 15, train_loss=2.0590 val_loss=2.0483 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 16, train_loss=2.0591 val_loss=2.0481 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 17, train_loss=2.0581 val_loss=2.0478 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 18, train_loss=2.0594 val_loss=2.0476 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 19, train_loss=2.0588 val_loss=2.0474 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 20, train_loss=2.0582 val_loss=2.0471 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.0582 val_loss=2.0471 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=ReLU,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=3.2660 val_loss=2.0538 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=2.0310 val_loss=2.0557 train_f1_score=0.3458 train_accuracy=0.2520 val_f1_score=0.3088 val_accuracy=0.2152\n",
      "\n",
      "Epoch 3, train_loss=2.0082 val_loss=2.0008 train_f1_score=0.3479 train_accuracy=0.2266 val_f1_score=0.3125 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=1.9886 val_loss=2.0062 train_f1_score=0.3428 train_accuracy=0.2393 val_f1_score=0.3102 val_accuracy=0.2152\n",
      "\n",
      "Epoch 5, train_loss=1.9792 val_loss=1.9725 train_f1_score=0.3565 train_accuracy=0.2377 val_f1_score=0.3244 val_accuracy=0.2152\n",
      "\n",
      "Epoch 6, train_loss=1.9528 val_loss=1.9444 train_f1_score=0.3658 train_accuracy=0.2488 val_f1_score=0.3299 val_accuracy=0.2215\n",
      "\n",
      "Epoch 7, train_loss=1.9190 val_loss=1.9672 train_f1_score=0.3484 train_accuracy=0.2789 val_f1_score=0.3347 val_accuracy=0.2658\n",
      "\n",
      "Epoch 8, train_loss=1.9190 val_loss=1.9834 train_f1_score=0.3575 train_accuracy=0.2868 val_f1_score=0.2505 val_accuracy=0.2025\n",
      "\n",
      "Epoch 9, train_loss=1.9101 val_loss=2.0136 train_f1_score=0.2770 train_accuracy=0.2203 val_f1_score=0.2313 val_accuracy=0.1709\n",
      "\n",
      "Epoch 10, train_loss=1.8984 val_loss=1.9011 train_f1_score=0.3934 train_accuracy=0.3170 val_f1_score=0.3240 val_accuracy=0.2532\n",
      "\n",
      "Epoch 11, train_loss=1.8449 val_loss=1.9356 train_f1_score=0.3638 train_accuracy=0.2615 val_f1_score=0.3428 val_accuracy=0.2532\n",
      "\n",
      "Epoch 12, train_loss=1.8704 val_loss=1.9468 train_f1_score=0.3896 train_accuracy=0.3154 val_f1_score=0.2662 val_accuracy=0.2089\n",
      "\n",
      "Epoch 13, train_loss=1.8473 val_loss=1.9090 train_f1_score=0.3931 train_accuracy=0.3154 val_f1_score=0.3198 val_accuracy=0.2468\n",
      "\n",
      "Epoch 14, train_loss=1.8124 val_loss=2.0152 train_f1_score=0.3458 train_accuracy=0.2884 val_f1_score=0.2195 val_accuracy=0.1962\n",
      "\n",
      "Epoch 15, train_loss=1.8242 val_loss=1.9532 train_f1_score=0.4190 train_accuracy=0.3376 val_f1_score=0.2911 val_accuracy=0.2342\n",
      "\n",
      "Epoch 16, train_loss=1.7906 val_loss=1.9515 train_f1_score=0.4257 train_accuracy=0.3391 val_f1_score=0.3163 val_accuracy=0.2405\n",
      "\n",
      "Epoch 17, train_loss=1.8197 val_loss=1.9443 train_f1_score=0.4224 train_accuracy=0.3265 val_f1_score=0.3079 val_accuracy=0.2278\n",
      "\n",
      "Epoch 18, train_loss=1.7948 val_loss=1.9850 train_f1_score=0.4039 train_accuracy=0.3439 val_f1_score=0.2179 val_accuracy=0.1772\n",
      "\n",
      "Epoch 19, train_loss=1.7630 val_loss=2.0574 train_f1_score=0.4183 train_accuracy=0.3249 val_f1_score=0.3131 val_accuracy=0.2278\n",
      "\n",
      "Epoch 20, train_loss=1.7509 val_loss=2.0101 train_f1_score=0.3774 train_accuracy=0.3185 val_f1_score=0.2199 val_accuracy=0.1899\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.7509 val_loss=2.0101 train_f1_score=0.3774 train_accuracy=0.3185 val_f1_score=0.2199 val_accuracy=0.1899\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=Sigmoid,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.1299 val_loss=2.1269 train_f1_score=0.1868 train_accuracy=0.1030 val_f1_score=0.1190 val_accuracy=0.0633\n",
      "\n",
      "Epoch 2, train_loss=2.1044 val_loss=2.1016 train_f1_score=0.1868 train_accuracy=0.1030 val_f1_score=0.1190 val_accuracy=0.0633\n",
      "\n",
      "Epoch 3, train_loss=2.0854 val_loss=2.0824 train_f1_score=0.3551 train_accuracy=0.2219 val_f1_score=0.3365 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=2.0697 val_loss=2.0664 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 5, train_loss=2.0568 val_loss=2.0532 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 6, train_loss=2.0467 val_loss=2.0409 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 7, train_loss=2.0381 val_loss=2.0322 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 8, train_loss=2.0308 val_loss=2.0247 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 9, train_loss=2.0251 val_loss=2.0189 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 10, train_loss=2.0207 val_loss=2.0140 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 11, train_loss=2.0174 val_loss=2.0105 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 12, train_loss=2.0144 val_loss=2.0064 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 13, train_loss=2.0125 val_loss=2.0041 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 14, train_loss=2.0084 val_loss=2.0015 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 15, train_loss=2.0067 val_loss=1.9996 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 16, train_loss=2.0061 val_loss=1.9976 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 17, train_loss=2.0009 val_loss=1.9965 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 18, train_loss=1.9986 val_loss=1.9942 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 19, train_loss=1.9961 val_loss=1.9920 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 20, train_loss=1.9903 val_loss=1.9906 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.9903 val_loss=1.9906 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=Sigmoid,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.1509 val_loss=2.1509 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 2, train_loss=2.1503 val_loss=2.1504 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 3, train_loss=2.1507 val_loss=2.1498 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 4, train_loss=2.1504 val_loss=2.1492 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 5, train_loss=2.1501 val_loss=2.1486 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 6, train_loss=2.1484 val_loss=2.1480 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 7, train_loss=2.1481 val_loss=2.1475 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 8, train_loss=2.1467 val_loss=2.1469 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 9, train_loss=2.1469 val_loss=2.1463 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 10, train_loss=2.1450 val_loss=2.1458 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 11, train_loss=2.1466 val_loss=2.1452 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 12, train_loss=2.1459 val_loss=2.1446 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 13, train_loss=2.1450 val_loss=2.1441 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 14, train_loss=2.1438 val_loss=2.1435 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 15, train_loss=2.1435 val_loss=2.1429 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 16, train_loss=2.1433 val_loss=2.1424 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 17, train_loss=2.1432 val_loss=2.1418 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 18, train_loss=2.1422 val_loss=2.1413 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 19, train_loss=2.1406 val_loss=2.1407 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 20, train_loss=2.1424 val_loss=2.1402 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.1424 val_loss=2.1402 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=Sigmoid,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0560 val_loss=2.0208 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=2.0325 val_loss=2.0110 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 3, train_loss=2.0257 val_loss=2.0066 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=2.0204 val_loss=2.0037 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 5, train_loss=2.0158 val_loss=2.0003 train_f1_score=0.3520 train_accuracy=0.2314 val_f1_score=0.3280 val_accuracy=0.2089\n",
      "\n",
      "Epoch 6, train_loss=2.0090 val_loss=1.9945 train_f1_score=0.3551 train_accuracy=0.2282 val_f1_score=0.3076 val_accuracy=0.1962\n",
      "\n",
      "Epoch 7, train_loss=2.0026 val_loss=1.9882 train_f1_score=0.3670 train_accuracy=0.2441 val_f1_score=0.3373 val_accuracy=0.2278\n",
      "\n",
      "Epoch 8, train_loss=1.9993 val_loss=1.9853 train_f1_score=0.3870 train_accuracy=0.2662 val_f1_score=0.3330 val_accuracy=0.2278\n",
      "\n",
      "Epoch 9, train_loss=1.9893 val_loss=1.9810 train_f1_score=0.4027 train_accuracy=0.2805 val_f1_score=0.3549 val_accuracy=0.2468\n",
      "\n",
      "Epoch 10, train_loss=1.9862 val_loss=1.9795 train_f1_score=0.3557 train_accuracy=0.2345 val_f1_score=0.3182 val_accuracy=0.2089\n",
      "\n",
      "Epoch 11, train_loss=1.9812 val_loss=1.9734 train_f1_score=0.3938 train_accuracy=0.2710 val_f1_score=0.3419 val_accuracy=0.2342\n",
      "\n",
      "Epoch 12, train_loss=1.9734 val_loss=1.9683 train_f1_score=0.4134 train_accuracy=0.2900 val_f1_score=0.3975 val_accuracy=0.2785\n",
      "\n",
      "Epoch 13, train_loss=1.9680 val_loss=1.9657 train_f1_score=0.4162 train_accuracy=0.2900 val_f1_score=0.3715 val_accuracy=0.2595\n",
      "\n",
      "Epoch 14, train_loss=1.9634 val_loss=1.9625 train_f1_score=0.4094 train_accuracy=0.2837 val_f1_score=0.3661 val_accuracy=0.2532\n",
      "\n",
      "Epoch 15, train_loss=1.9570 val_loss=1.9590 train_f1_score=0.4307 train_accuracy=0.3059 val_f1_score=0.3863 val_accuracy=0.2722\n",
      "\n",
      "Epoch 16, train_loss=1.9542 val_loss=1.9569 train_f1_score=0.4285 train_accuracy=0.3090 val_f1_score=0.4033 val_accuracy=0.2848\n",
      "\n",
      "Epoch 17, train_loss=1.9444 val_loss=1.9526 train_f1_score=0.4348 train_accuracy=0.3074 val_f1_score=0.3777 val_accuracy=0.2658\n",
      "\n",
      "Epoch 18, train_loss=1.9428 val_loss=1.9514 train_f1_score=0.4187 train_accuracy=0.2932 val_f1_score=0.3612 val_accuracy=0.2532\n",
      "\n",
      "Epoch 19, train_loss=1.9337 val_loss=1.9471 train_f1_score=0.4144 train_accuracy=0.3027 val_f1_score=0.3843 val_accuracy=0.2722\n",
      "\n",
      "Epoch 20, train_loss=1.9268 val_loss=1.9455 train_f1_score=0.4407 train_accuracy=0.3185 val_f1_score=0.4020 val_accuracy=0.2848\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.9268 val_loss=1.9455 train_f1_score=0.4407 train_accuracy=0.3185 val_f1_score=0.4020 val_accuracy=0.2848\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=Sigmoid,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0543 val_loss=2.0004 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=2.0280 val_loss=2.0021 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 3, train_loss=2.0231 val_loss=2.0008 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=2.0224 val_loss=2.0042 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 5, train_loss=2.0191 val_loss=2.0035 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 6, train_loss=2.0187 val_loss=2.0001 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 7, train_loss=2.0087 val_loss=1.9985 train_f1_score=0.3328 train_accuracy=0.2203 val_f1_score=0.2766 val_accuracy=0.1899\n",
      "\n",
      "Epoch 8, train_loss=1.9979 val_loss=1.9975 train_f1_score=0.3328 train_accuracy=0.2235 val_f1_score=0.2668 val_accuracy=0.1835\n",
      "\n",
      "Epoch 9, train_loss=1.9836 val_loss=1.9968 train_f1_score=0.3407 train_accuracy=0.2330 val_f1_score=0.2731 val_accuracy=0.1899\n",
      "\n",
      "Epoch 10, train_loss=1.9603 val_loss=1.9919 train_f1_score=0.3706 train_accuracy=0.2615 val_f1_score=0.2676 val_accuracy=0.1899\n",
      "\n",
      "Epoch 11, train_loss=1.9460 val_loss=2.0052 train_f1_score=0.3620 train_accuracy=0.2520 val_f1_score=0.2774 val_accuracy=0.1962\n",
      "\n",
      "Epoch 12, train_loss=1.9315 val_loss=2.0243 train_f1_score=0.3701 train_accuracy=0.2583 val_f1_score=0.2694 val_accuracy=0.1899\n",
      "\n",
      "Epoch 13, train_loss=1.9355 val_loss=2.0227 train_f1_score=0.3586 train_accuracy=0.2520 val_f1_score=0.2601 val_accuracy=0.1835\n",
      "\n",
      "Epoch 14, train_loss=1.9233 val_loss=2.0163 train_f1_score=0.4097 train_accuracy=0.2979 val_f1_score=0.2959 val_accuracy=0.2089\n",
      "\n",
      "Epoch 15, train_loss=1.9117 val_loss=2.0201 train_f1_score=0.4090 train_accuracy=0.2948 val_f1_score=0.3019 val_accuracy=0.2152\n",
      "\n",
      "Epoch 16, train_loss=1.9027 val_loss=2.0060 train_f1_score=0.3907 train_accuracy=0.2773 val_f1_score=0.2585 val_accuracy=0.1835\n",
      "\n",
      "Epoch 17, train_loss=1.9331 val_loss=2.0057 train_f1_score=0.3777 train_accuracy=0.2678 val_f1_score=0.2594 val_accuracy=0.1835\n",
      "\n",
      "Epoch 18, train_loss=1.8984 val_loss=2.0172 train_f1_score=0.4165 train_accuracy=0.3011 val_f1_score=0.2944 val_accuracy=0.2089\n",
      "\n",
      "Epoch 19, train_loss=1.8838 val_loss=2.0044 train_f1_score=0.3774 train_accuracy=0.2710 val_f1_score=0.2955 val_accuracy=0.2089\n",
      "\n",
      "Epoch 20, train_loss=1.8815 val_loss=2.0359 train_f1_score=0.4142 train_accuracy=0.3043 val_f1_score=0.3077 val_accuracy=0.2152\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.8815 val_loss=2.0359 train_f1_score=0.4142 train_accuracy=0.3043 val_f1_score=0.3077 val_accuracy=0.2152\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=Sigmoid,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0951 val_loss=2.1295 train_f1_score=0.1868 train_accuracy=0.1030 val_f1_score=0.1190 val_accuracy=0.0633\n",
      "\n",
      "Epoch 2, train_loss=2.0913 val_loss=2.1243 train_f1_score=0.1868 train_accuracy=0.1030 val_f1_score=0.1190 val_accuracy=0.0633\n",
      "\n",
      "Epoch 3, train_loss=2.0878 val_loss=2.1192 train_f1_score=0.1868 train_accuracy=0.1030 val_f1_score=0.1190 val_accuracy=0.0633\n",
      "\n",
      "Epoch 4, train_loss=2.0839 val_loss=2.1145 train_f1_score=0.1868 train_accuracy=0.1030 val_f1_score=0.1190 val_accuracy=0.0633\n",
      "\n",
      "Epoch 5, train_loss=2.0802 val_loss=2.1100 train_f1_score=0.1868 train_accuracy=0.1030 val_f1_score=0.1190 val_accuracy=0.0633\n",
      "\n",
      "Epoch 6, train_loss=2.0777 val_loss=2.1057 train_f1_score=0.1868 train_accuracy=0.1030 val_f1_score=0.1190 val_accuracy=0.0633\n",
      "\n",
      "Epoch 7, train_loss=2.0745 val_loss=2.1016 train_f1_score=0.1868 train_accuracy=0.1030 val_f1_score=0.1190 val_accuracy=0.0633\n",
      "\n",
      "Epoch 8, train_loss=2.0713 val_loss=2.0977 train_f1_score=0.1868 train_accuracy=0.1030 val_f1_score=0.1190 val_accuracy=0.0633\n",
      "\n",
      "Epoch 9, train_loss=2.0688 val_loss=2.0940 train_f1_score=0.1868 train_accuracy=0.1030 val_f1_score=0.1190 val_accuracy=0.0633\n",
      "\n",
      "Epoch 10, train_loss=2.0662 val_loss=2.0904 train_f1_score=0.1868 train_accuracy=0.1030 val_f1_score=0.1190 val_accuracy=0.0633\n",
      "\n",
      "Epoch 11, train_loss=2.0641 val_loss=2.0871 train_f1_score=0.1868 train_accuracy=0.1030 val_f1_score=0.1190 val_accuracy=0.0633\n",
      "\n",
      "Epoch 12, train_loss=2.0615 val_loss=2.0839 train_f1_score=0.1868 train_accuracy=0.1030 val_f1_score=0.1190 val_accuracy=0.0633\n",
      "\n",
      "Epoch 13, train_loss=2.0594 val_loss=2.0807 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 14, train_loss=2.0567 val_loss=2.0778 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 15, train_loss=2.0552 val_loss=2.0750 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 16, train_loss=2.0534 val_loss=2.0723 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 17, train_loss=2.0531 val_loss=2.0698 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 18, train_loss=2.0502 val_loss=2.0673 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 19, train_loss=2.0488 val_loss=2.0650 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 20, train_loss=2.0468 val_loss=2.0628 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.0468 val_loss=2.0628 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=Sigmoid,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0578 val_loss=2.0101 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=2.0372 val_loss=2.0091 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 3, train_loss=2.0313 val_loss=2.0046 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=2.0114 val_loss=2.0195 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 5, train_loss=1.9822 val_loss=1.9289 train_f1_score=0.3914 train_accuracy=0.2837 val_f1_score=0.3639 val_accuracy=0.2595\n",
      "\n",
      "Epoch 6, train_loss=1.9429 val_loss=1.8931 train_f1_score=0.4018 train_accuracy=0.2948 val_f1_score=0.3777 val_accuracy=0.2722\n",
      "\n",
      "Epoch 7, train_loss=1.9119 val_loss=1.8625 train_f1_score=0.4075 train_accuracy=0.2979 val_f1_score=0.3785 val_accuracy=0.2722\n",
      "\n",
      "Epoch 8, train_loss=1.8787 val_loss=1.8578 train_f1_score=0.4120 train_accuracy=0.3059 val_f1_score=0.3826 val_accuracy=0.2785\n",
      "\n",
      "Epoch 9, train_loss=1.8656 val_loss=1.8434 train_f1_score=0.4168 train_accuracy=0.3074 val_f1_score=0.3949 val_accuracy=0.2848\n",
      "\n",
      "Epoch 10, train_loss=1.8647 val_loss=1.8424 train_f1_score=0.4259 train_accuracy=0.3074 val_f1_score=0.3936 val_accuracy=0.2785\n",
      "\n",
      "Epoch 11, train_loss=1.8667 val_loss=1.9563 train_f1_score=0.3779 train_accuracy=0.2552 val_f1_score=0.3443 val_accuracy=0.2278\n",
      "\n",
      "Epoch 12, train_loss=1.8787 val_loss=1.8355 train_f1_score=0.4303 train_accuracy=0.3090 val_f1_score=0.3936 val_accuracy=0.2785\n",
      "\n",
      "Epoch 13, train_loss=1.8273 val_loss=1.8354 train_f1_score=0.4422 train_accuracy=0.3217 val_f1_score=0.3978 val_accuracy=0.2848\n",
      "\n",
      "Epoch 14, train_loss=1.8185 val_loss=1.8268 train_f1_score=0.4365 train_accuracy=0.3170 val_f1_score=0.3891 val_accuracy=0.2785\n",
      "\n",
      "Epoch 15, train_loss=1.8184 val_loss=1.8405 train_f1_score=0.4277 train_accuracy=0.3154 val_f1_score=0.3777 val_accuracy=0.2722\n",
      "\n",
      "Epoch 16, train_loss=1.7979 val_loss=2.1068 train_f1_score=0.3541 train_accuracy=0.2203 val_f1_score=0.3367 val_accuracy=0.2089\n",
      "\n",
      "Epoch 17, train_loss=1.8950 val_loss=1.8267 train_f1_score=0.4329 train_accuracy=0.3201 val_f1_score=0.3925 val_accuracy=0.2848\n",
      "\n",
      "Epoch 18, train_loss=1.8003 val_loss=1.8589 train_f1_score=0.4281 train_accuracy=0.3185 val_f1_score=0.3724 val_accuracy=0.2722\n",
      "\n",
      "Epoch 19, train_loss=1.7989 val_loss=1.8350 train_f1_score=0.4447 train_accuracy=0.3249 val_f1_score=0.3811 val_accuracy=0.2722\n",
      "\n",
      "Epoch 20, train_loss=1.7947 val_loss=1.8255 train_f1_score=0.4368 train_accuracy=0.3170 val_f1_score=0.3998 val_accuracy=0.2848\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.7947 val_loss=1.8255 train_f1_score=0.4368 train_accuracy=0.3170 val_f1_score=0.3998 val_accuracy=0.2848\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=Sigmoid,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.1368 val_loss=2.0856 train_f1_score=0.1737 train_accuracy=0.0951 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 2, train_loss=2.1133 val_loss=2.0643 train_f1_score=0.1737 train_accuracy=0.0951 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 3, train_loss=2.0915 val_loss=2.0489 train_f1_score=0.1737 train_accuracy=0.0951 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 4, train_loss=2.0846 val_loss=2.0373 train_f1_score=0.1737 train_accuracy=0.0951 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 5, train_loss=2.0613 val_loss=2.0285 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 6, train_loss=2.0638 val_loss=2.0205 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 7, train_loss=2.0610 val_loss=2.0150 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 8, train_loss=2.0440 val_loss=2.0103 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 9, train_loss=2.0345 val_loss=2.0071 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 10, train_loss=2.0326 val_loss=2.0043 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 11, train_loss=2.0315 val_loss=2.0025 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 12, train_loss=2.0460 val_loss=2.0008 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 13, train_loss=2.0257 val_loss=1.9993 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 14, train_loss=2.0267 val_loss=1.9996 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 15, train_loss=2.0238 val_loss=1.9991 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 16, train_loss=2.0258 val_loss=1.9984 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 17, train_loss=2.0195 val_loss=1.9984 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 18, train_loss=2.0135 val_loss=1.9975 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 19, train_loss=2.0193 val_loss=1.9977 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 20, train_loss=2.0040 val_loss=1.9968 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.0040 val_loss=1.9968 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=Sigmoid,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.2536 val_loss=2.2511 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 2, train_loss=2.2587 val_loss=2.2501 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 3, train_loss=2.2605 val_loss=2.2492 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 4, train_loss=2.2579 val_loss=2.2482 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 5, train_loss=2.2568 val_loss=2.2473 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 6, train_loss=2.2549 val_loss=2.2463 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 7, train_loss=2.2452 val_loss=2.2454 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 8, train_loss=2.2610 val_loss=2.2444 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 9, train_loss=2.2451 val_loss=2.2435 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 10, train_loss=2.2481 val_loss=2.2426 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 11, train_loss=2.2471 val_loss=2.2416 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 12, train_loss=2.2478 val_loss=2.2407 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 13, train_loss=2.2549 val_loss=2.2398 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 14, train_loss=2.2450 val_loss=2.2389 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 15, train_loss=2.2506 val_loss=2.2380 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 16, train_loss=2.2466 val_loss=2.2370 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 17, train_loss=2.2430 val_loss=2.2361 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 18, train_loss=2.2392 val_loss=2.2352 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 19, train_loss=2.2371 val_loss=2.2343 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "Epoch 20, train_loss=2.2395 val_loss=2.2334 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.2395 val_loss=2.2334 train_f1_score=0.1684 train_accuracy=0.0919 val_f1_score=0.2045 val_accuracy=0.1139\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=Sigmoid,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.1138 val_loss=2.0628 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=2.0756 val_loss=2.0401 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 3, train_loss=2.0561 val_loss=2.0282 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=2.0463 val_loss=2.0207 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 5, train_loss=2.0400 val_loss=2.0148 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 6, train_loss=2.0350 val_loss=2.0112 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 7, train_loss=2.0388 val_loss=2.0060 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 8, train_loss=2.0244 val_loss=2.0005 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 9, train_loss=2.0221 val_loss=1.9948 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 10, train_loss=2.0157 val_loss=1.9886 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 11, train_loss=2.0102 val_loss=1.9841 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 12, train_loss=2.0044 val_loss=1.9800 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 13, train_loss=2.0036 val_loss=1.9754 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 14, train_loss=1.9933 val_loss=1.9680 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 15, train_loss=1.9826 val_loss=1.9656 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 16, train_loss=1.9805 val_loss=1.9572 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 17, train_loss=1.9708 val_loss=1.9545 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 18, train_loss=1.9632 val_loss=1.9474 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 19, train_loss=1.9612 val_loss=1.9402 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 20, train_loss=1.9606 val_loss=1.9355 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.9606 val_loss=1.9355 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=Sigmoid,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0624 val_loss=1.9976 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=2.0318 val_loss=1.9997 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 3, train_loss=2.0251 val_loss=2.0012 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=2.0092 val_loss=2.0016 train_f1_score=0.3622 train_accuracy=0.2583 val_f1_score=0.2339 val_accuracy=0.1646\n",
      "\n",
      "Epoch 5, train_loss=2.0021 val_loss=2.0005 train_f1_score=0.3696 train_accuracy=0.2647 val_f1_score=0.2631 val_accuracy=0.1835\n",
      "\n",
      "Epoch 6, train_loss=2.0013 val_loss=1.9973 train_f1_score=0.3572 train_accuracy=0.2520 val_f1_score=0.2431 val_accuracy=0.1709\n",
      "\n",
      "Epoch 7, train_loss=1.9908 val_loss=2.0035 train_f1_score=0.3581 train_accuracy=0.2583 val_f1_score=0.2838 val_accuracy=0.1962\n",
      "\n",
      "Epoch 8, train_loss=1.9735 val_loss=2.0104 train_f1_score=0.3661 train_accuracy=0.2631 val_f1_score=0.2629 val_accuracy=0.1835\n",
      "\n",
      "Epoch 9, train_loss=1.9739 val_loss=2.0110 train_f1_score=0.3656 train_accuracy=0.2615 val_f1_score=0.2347 val_accuracy=0.1646\n",
      "\n",
      "Epoch 10, train_loss=1.9642 val_loss=2.0099 train_f1_score=0.3658 train_accuracy=0.2615 val_f1_score=0.2338 val_accuracy=0.1646\n",
      "\n",
      "Epoch 11, train_loss=1.9590 val_loss=2.0102 train_f1_score=0.3736 train_accuracy=0.2726 val_f1_score=0.2845 val_accuracy=0.1962\n",
      "\n",
      "Epoch 12, train_loss=1.9535 val_loss=1.9958 train_f1_score=0.3619 train_accuracy=0.2567 val_f1_score=0.2694 val_accuracy=0.1899\n",
      "\n",
      "Epoch 13, train_loss=1.9308 val_loss=2.0175 train_f1_score=0.3888 train_accuracy=0.2853 val_f1_score=0.2894 val_accuracy=0.1962\n",
      "\n",
      "Epoch 14, train_loss=1.9360 val_loss=2.0084 train_f1_score=0.3866 train_accuracy=0.2789 val_f1_score=0.2799 val_accuracy=0.1962\n",
      "\n",
      "Epoch 15, train_loss=1.9230 val_loss=2.0224 train_f1_score=0.3850 train_accuracy=0.2773 val_f1_score=0.2802 val_accuracy=0.1962\n",
      "\n",
      "Epoch 16, train_loss=1.9167 val_loss=2.0203 train_f1_score=0.4003 train_accuracy=0.2900 val_f1_score=0.2987 val_accuracy=0.2089\n",
      "\n",
      "Epoch 17, train_loss=1.8980 val_loss=2.0063 train_f1_score=0.4055 train_accuracy=0.2932 val_f1_score=0.3327 val_accuracy=0.2342\n",
      "\n",
      "Epoch 18, train_loss=1.8873 val_loss=2.0157 train_f1_score=0.4169 train_accuracy=0.3059 val_f1_score=0.3020 val_accuracy=0.2089\n",
      "\n",
      "Epoch 19, train_loss=1.8919 val_loss=2.0296 train_f1_score=0.4032 train_accuracy=0.2916 val_f1_score=0.3148 val_accuracy=0.2215\n",
      "\n",
      "Epoch 20, train_loss=1.8667 val_loss=2.0185 train_f1_score=0.4203 train_accuracy=0.3122 val_f1_score=0.2901 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.8667 val_loss=2.0185 train_f1_score=0.4203 train_accuracy=0.3122 val_f1_score=0.2901 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=Sigmoid,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.1380 val_loss=2.1319 train_f1_score=0.1997 train_accuracy=0.1109 val_f1_score=0.1839 val_accuracy=0.1013\n",
      "\n",
      "Epoch 2, train_loss=2.1349 val_loss=2.1267 train_f1_score=0.1997 train_accuracy=0.1109 val_f1_score=0.1839 val_accuracy=0.1013\n",
      "\n",
      "Epoch 3, train_loss=2.1174 val_loss=2.1218 train_f1_score=0.1997 train_accuracy=0.1109 val_f1_score=0.1839 val_accuracy=0.1013\n",
      "\n",
      "Epoch 4, train_loss=2.1190 val_loss=2.1171 train_f1_score=0.1997 train_accuracy=0.1109 val_f1_score=0.1839 val_accuracy=0.1013\n",
      "\n",
      "Epoch 5, train_loss=2.1177 val_loss=2.1126 train_f1_score=0.1997 train_accuracy=0.1109 val_f1_score=0.1839 val_accuracy=0.1013\n",
      "\n",
      "Epoch 6, train_loss=2.1112 val_loss=2.1082 train_f1_score=0.1997 train_accuracy=0.1109 val_f1_score=0.1839 val_accuracy=0.1013\n",
      "\n",
      "Epoch 7, train_loss=2.1051 val_loss=2.1040 train_f1_score=0.1997 train_accuracy=0.1109 val_f1_score=0.1839 val_accuracy=0.1013\n",
      "\n",
      "Epoch 8, train_loss=2.1044 val_loss=2.0999 train_f1_score=0.1997 train_accuracy=0.1109 val_f1_score=0.1839 val_accuracy=0.1013\n",
      "\n",
      "Epoch 9, train_loss=2.1072 val_loss=2.0960 train_f1_score=0.1997 train_accuracy=0.1109 val_f1_score=0.1839 val_accuracy=0.1013\n",
      "\n",
      "Epoch 10, train_loss=2.0976 val_loss=2.0922 train_f1_score=0.1997 train_accuracy=0.1109 val_f1_score=0.1839 val_accuracy=0.1013\n",
      "\n",
      "Epoch 11, train_loss=2.0967 val_loss=2.0886 train_f1_score=0.1997 train_accuracy=0.1109 val_f1_score=0.1839 val_accuracy=0.1013\n",
      "\n",
      "Epoch 12, train_loss=2.0908 val_loss=2.0850 train_f1_score=0.1997 train_accuracy=0.1109 val_f1_score=0.1839 val_accuracy=0.1013\n",
      "\n",
      "Epoch 13, train_loss=2.0892 val_loss=2.0815 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 14, train_loss=2.0906 val_loss=2.0782 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 15, train_loss=2.0798 val_loss=2.0750 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 16, train_loss=2.0754 val_loss=2.0719 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 17, train_loss=2.0775 val_loss=2.0690 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 18, train_loss=2.0753 val_loss=2.0662 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 19, train_loss=2.0665 val_loss=2.0634 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 20, train_loss=2.0712 val_loss=2.0608 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.0712 val_loss=2.0608 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=type,loss=CrossEntropyLoss,activation=Sigmoid,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0566 val_loss=2.0114 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 2, train_loss=2.0406 val_loss=2.0000 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 3, train_loss=2.0343 val_loss=2.0112 train_f1_score=0.3439 train_accuracy=0.2203 val_f1_score=0.3331 val_accuracy=0.2025\n",
      "\n",
      "Epoch 4, train_loss=2.0270 val_loss=2.0086 train_f1_score=0.3196 train_accuracy=0.1902 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 5, train_loss=2.0276 val_loss=2.0029 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 6, train_loss=2.0296 val_loss=2.0052 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 7, train_loss=2.0376 val_loss=2.0028 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 8, train_loss=2.0235 val_loss=2.0011 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 9, train_loss=2.0393 val_loss=2.0030 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 10, train_loss=2.0330 val_loss=2.0039 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 11, train_loss=2.0252 val_loss=2.0035 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 12, train_loss=2.0249 val_loss=2.0083 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 13, train_loss=2.0292 val_loss=2.0024 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 14, train_loss=2.0322 val_loss=2.0058 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 15, train_loss=2.0284 val_loss=1.9987 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 16, train_loss=2.0303 val_loss=1.9990 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 17, train_loss=2.0269 val_loss=2.0018 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 18, train_loss=2.0291 val_loss=2.0033 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 19, train_loss=2.0307 val_loss=2.0036 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "Epoch 20, train_loss=2.0265 val_loss=2.0026 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.0265 val_loss=2.0026 train_f1_score=0.3546 train_accuracy=0.2155 val_f1_score=0.3368 val_accuracy=0.2025\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=Adam,loss=CrossEntropyLoss,activation=Tanh,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0281 val_loss=2.0506 train_f1_score=0.3802 train_accuracy=0.2504 val_f1_score=0.2689 val_accuracy=0.1709\n",
      "\n",
      "Epoch 2, train_loss=1.9653 val_loss=2.0340 train_f1_score=0.3465 train_accuracy=0.2393 val_f1_score=0.2380 val_accuracy=0.1519\n",
      "\n",
      "Epoch 3, train_loss=1.9097 val_loss=1.9674 train_f1_score=0.3832 train_accuracy=0.2932 val_f1_score=0.3021 val_accuracy=0.2152\n",
      "\n",
      "Epoch 4, train_loss=1.8612 val_loss=1.9411 train_f1_score=0.3801 train_accuracy=0.3090 val_f1_score=0.2579 val_accuracy=0.1962\n",
      "\n",
      "Epoch 5, train_loss=1.8468 val_loss=1.9719 train_f1_score=0.3914 train_accuracy=0.3265 val_f1_score=0.2648 val_accuracy=0.2089\n",
      "\n",
      "Epoch 6, train_loss=1.8058 val_loss=1.9555 train_f1_score=0.4003 train_accuracy=0.3455 val_f1_score=0.2630 val_accuracy=0.2152\n",
      "\n",
      "Epoch 7, train_loss=1.7653 val_loss=1.9388 train_f1_score=0.4643 train_accuracy=0.4057 val_f1_score=0.1915 val_accuracy=0.1646\n",
      "\n",
      "Epoch 8, train_loss=1.7218 val_loss=1.9123 train_f1_score=0.4508 train_accuracy=0.4073 val_f1_score=0.2664 val_accuracy=0.2215\n",
      "\n",
      "Epoch 9, train_loss=1.6664 val_loss=1.9576 train_f1_score=0.4852 train_accuracy=0.4216 val_f1_score=0.3092 val_accuracy=0.2405\n",
      "\n",
      "Epoch 10, train_loss=1.5902 val_loss=1.9511 train_f1_score=0.5344 train_accuracy=0.5008 val_f1_score=0.3037 val_accuracy=0.2595\n",
      "\n",
      "Epoch 11, train_loss=1.5057 val_loss=2.0151 train_f1_score=0.5516 train_accuracy=0.5166 val_f1_score=0.2678 val_accuracy=0.2089\n",
      "\n",
      "Epoch 12, train_loss=1.4295 val_loss=1.9451 train_f1_score=0.6799 train_accuracy=0.6482 val_f1_score=0.3127 val_accuracy=0.2658\n",
      "\n",
      "Epoch 13, train_loss=1.2481 val_loss=1.9958 train_f1_score=0.7263 train_accuracy=0.7005 val_f1_score=0.2940 val_accuracy=0.2532\n",
      "\n",
      "Epoch 14, train_loss=1.0423 val_loss=2.1154 train_f1_score=0.7208 train_accuracy=0.7084 val_f1_score=0.3122 val_accuracy=0.2595\n",
      "\n",
      "Epoch 15, train_loss=0.8973 val_loss=2.0711 train_f1_score=0.8394 train_accuracy=0.8288 val_f1_score=0.3383 val_accuracy=0.3101\n",
      "\n",
      "Epoch 16, train_loss=0.7787 val_loss=2.1108 train_f1_score=0.8735 train_accuracy=0.8700 val_f1_score=0.2988 val_accuracy=0.2848\n",
      "\n",
      "Epoch 17, train_loss=0.5687 val_loss=2.2367 train_f1_score=0.9134 train_accuracy=0.9144 val_f1_score=0.3320 val_accuracy=0.3101\n",
      "\n",
      "Epoch 18, train_loss=0.4521 val_loss=2.4960 train_f1_score=0.9195 train_accuracy=0.9192 val_f1_score=0.2628 val_accuracy=0.2342\n",
      "\n",
      "Epoch 19, train_loss=0.3524 val_loss=2.5025 train_f1_score=0.9380 train_accuracy=0.9382 val_f1_score=0.2939 val_accuracy=0.2975\n",
      "\n",
      "Epoch 20, train_loss=0.2897 val_loss=2.4998 train_f1_score=0.9587 train_accuracy=0.9588 val_f1_score=0.2823 val_accuracy=0.2785\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=0.2897,val_loss=2.4998,train_f1_score=0.9587,train_accuracy=0.9588,val_f1_score=0.2823,val_accuracy=0.2785\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=SGD,loss=CrossEntropyLoss,activation=Tanh,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0952 val_loss=2.0921 train_f1_score=0.1894 train_accuracy=0.1046 val_f1_score=0.2147 val_accuracy=0.1203\n",
      "\n",
      "Epoch 2, train_loss=2.0937 val_loss=2.0912 train_f1_score=0.1894 train_accuracy=0.1046 val_f1_score=0.2147 val_accuracy=0.1203\n",
      "\n",
      "Epoch 3, train_loss=2.0918 val_loss=2.0903 train_f1_score=0.1894 train_accuracy=0.1046 val_f1_score=0.2147 val_accuracy=0.1203\n",
      "\n",
      "Epoch 4, train_loss=2.0907 val_loss=2.0893 train_f1_score=0.1894 train_accuracy=0.1046 val_f1_score=0.2147 val_accuracy=0.1203\n",
      "\n",
      "Epoch 5, train_loss=2.0894 val_loss=2.0884 train_f1_score=0.1894 train_accuracy=0.1046 val_f1_score=0.2147 val_accuracy=0.1203\n",
      "\n",
      "Epoch 6, train_loss=2.0880 val_loss=2.0875 train_f1_score=0.1894 train_accuracy=0.1046 val_f1_score=0.2147 val_accuracy=0.1203\n",
      "\n",
      "Epoch 7, train_loss=2.0866 val_loss=2.0867 train_f1_score=0.1894 train_accuracy=0.1046 val_f1_score=0.2147 val_accuracy=0.1203\n",
      "\n",
      "Epoch 8, train_loss=2.0852 val_loss=2.0858 train_f1_score=0.1894 train_accuracy=0.1046 val_f1_score=0.2147 val_accuracy=0.1203\n",
      "\n",
      "Epoch 9, train_loss=2.0840 val_loss=2.0850 train_f1_score=0.1894 train_accuracy=0.1046 val_f1_score=0.2147 val_accuracy=0.1203\n",
      "\n",
      "Epoch 10, train_loss=2.0828 val_loss=2.0842 train_f1_score=0.1894 train_accuracy=0.1046 val_f1_score=0.2147 val_accuracy=0.1203\n",
      "\n",
      "Epoch 11, train_loss=2.0814 val_loss=2.0834 train_f1_score=0.1894 train_accuracy=0.1046 val_f1_score=0.2147 val_accuracy=0.1203\n",
      "\n",
      "Epoch 12, train_loss=2.0800 val_loss=2.0826 train_f1_score=0.1865 train_accuracy=0.1030 val_f1_score=0.2147 val_accuracy=0.1203\n",
      "\n",
      "Epoch 13, train_loss=2.0788 val_loss=2.0818 train_f1_score=0.1866 train_accuracy=0.1062 val_f1_score=0.2147 val_accuracy=0.1203\n",
      "\n",
      "Epoch 14, train_loss=2.0778 val_loss=2.0810 train_f1_score=0.1870 train_accuracy=0.1078 val_f1_score=0.2145 val_accuracy=0.1203\n",
      "\n",
      "Epoch 15, train_loss=2.0766 val_loss=2.0803 train_f1_score=0.1833 train_accuracy=0.1094 val_f1_score=0.2048 val_accuracy=0.1203\n",
      "\n",
      "Epoch 16, train_loss=2.0752 val_loss=2.0795 train_f1_score=0.1892 train_accuracy=0.1204 val_f1_score=0.2106 val_accuracy=0.1266\n",
      "\n",
      "Epoch 17, train_loss=2.0741 val_loss=2.0788 train_f1_score=0.1965 train_accuracy=0.1300 val_f1_score=0.2035 val_accuracy=0.1266\n",
      "\n",
      "Epoch 18, train_loss=2.0726 val_loss=2.0781 train_f1_score=0.1891 train_accuracy=0.1284 val_f1_score=0.1810 val_accuracy=0.1139\n",
      "\n",
      "Epoch 19, train_loss=2.0715 val_loss=2.0773 train_f1_score=0.1963 train_accuracy=0.1347 val_f1_score=0.1858 val_accuracy=0.1203\n",
      "\n",
      "Epoch 20, train_loss=2.0704 val_loss=2.0766 train_f1_score=0.2356 train_accuracy=0.1585 val_f1_score=0.2083 val_accuracy=0.1329\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.0704,val_loss=2.0766,train_f1_score=0.2356,train_accuracy=0.1585,val_f1_score=0.2083,val_accuracy=0.1329\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=RMSprop,loss=CrossEntropyLoss,activation=Tanh,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.1108 val_loss=2.1189 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 2, train_loss=2.0436 val_loss=2.1054 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 3, train_loss=2.0365 val_loss=2.0714 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 4, train_loss=2.0407 val_loss=2.0653 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 5, train_loss=2.0444 val_loss=2.1555 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 6, train_loss=2.0247 val_loss=2.0443 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 7, train_loss=1.9704 val_loss=2.0332 train_f1_score=0.3718 train_accuracy=0.2425 val_f1_score=0.3304 val_accuracy=0.2089\n",
      "\n",
      "Epoch 8, train_loss=1.9326 val_loss=1.9538 train_f1_score=0.3986 train_accuracy=0.3122 val_f1_score=0.3446 val_accuracy=0.2595\n",
      "\n",
      "Epoch 9, train_loss=1.9132 val_loss=1.9761 train_f1_score=0.3396 train_accuracy=0.2583 val_f1_score=0.2808 val_accuracy=0.1962\n",
      "\n",
      "Epoch 10, train_loss=1.8451 val_loss=1.9512 train_f1_score=0.4333 train_accuracy=0.3217 val_f1_score=0.3377 val_accuracy=0.2468\n",
      "\n",
      "Epoch 11, train_loss=1.8219 val_loss=1.9641 train_f1_score=0.4218 train_accuracy=0.3185 val_f1_score=0.3513 val_accuracy=0.2532\n",
      "\n",
      "Epoch 12, train_loss=1.8182 val_loss=1.9529 train_f1_score=0.4129 train_accuracy=0.3661 val_f1_score=0.2663 val_accuracy=0.2152\n",
      "\n",
      "Epoch 13, train_loss=1.7512 val_loss=2.0209 train_f1_score=0.4534 train_accuracy=0.4041 val_f1_score=0.3009 val_accuracy=0.2405\n",
      "\n",
      "Epoch 14, train_loss=1.7358 val_loss=1.9829 train_f1_score=0.4801 train_accuracy=0.4485 val_f1_score=0.2965 val_accuracy=0.2532\n",
      "\n",
      "Epoch 15, train_loss=1.6637 val_loss=2.0101 train_f1_score=0.5023 train_accuracy=0.4881 val_f1_score=0.2839 val_accuracy=0.2532\n",
      "\n",
      "Epoch 16, train_loss=1.6352 val_loss=2.0707 train_f1_score=0.5107 train_accuracy=0.4913 val_f1_score=0.2844 val_accuracy=0.2405\n",
      "\n",
      "Epoch 17, train_loss=1.5695 val_loss=2.0371 train_f1_score=0.4971 train_accuracy=0.4564 val_f1_score=0.3165 val_accuracy=0.2532\n",
      "\n",
      "Epoch 18, train_loss=1.4866 val_loss=2.0797 train_f1_score=0.5619 train_accuracy=0.5452 val_f1_score=0.2694 val_accuracy=0.2215\n",
      "\n",
      "Epoch 19, train_loss=1.4926 val_loss=2.0727 train_f1_score=0.5576 train_accuracy=0.5246 val_f1_score=0.3097 val_accuracy=0.2468\n",
      "\n",
      "Epoch 20, train_loss=1.4096 val_loss=2.1570 train_f1_score=0.5643 train_accuracy=0.5388 val_f1_score=0.2734 val_accuracy=0.2405\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.4096,val_loss=2.1570,train_f1_score=0.5643,train_accuracy=0.5388,val_f1_score=0.2734,val_accuracy=0.2405\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=Adam,loss=CrossEntropyLoss,activation=Tanh,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0155 val_loss=2.0648 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 2, train_loss=1.9792 val_loss=2.0314 train_f1_score=0.3899 train_accuracy=0.2900 val_f1_score=0.3336 val_accuracy=0.2342\n",
      "\n",
      "Epoch 3, train_loss=1.9284 val_loss=1.9892 train_f1_score=0.4123 train_accuracy=0.3185 val_f1_score=0.3884 val_accuracy=0.2848\n",
      "\n",
      "Epoch 4, train_loss=1.8667 val_loss=1.9354 train_f1_score=0.4200 train_accuracy=0.3265 val_f1_score=0.3804 val_accuracy=0.2722\n",
      "\n",
      "Epoch 5, train_loss=1.8165 val_loss=1.9102 train_f1_score=0.4166 train_accuracy=0.3550 val_f1_score=0.3181 val_accuracy=0.2405\n",
      "\n",
      "Epoch 6, train_loss=1.7574 val_loss=1.8686 train_f1_score=0.4476 train_accuracy=0.4168 val_f1_score=0.3533 val_accuracy=0.2975\n",
      "\n",
      "Epoch 7, train_loss=1.7019 val_loss=1.8686 train_f1_score=0.4848 train_accuracy=0.4580 val_f1_score=0.3199 val_accuracy=0.2722\n",
      "\n",
      "Epoch 8, train_loss=1.6400 val_loss=1.8795 train_f1_score=0.4748 train_accuracy=0.4390 val_f1_score=0.3267 val_accuracy=0.2595\n",
      "\n",
      "Epoch 9, train_loss=1.5865 val_loss=1.8760 train_f1_score=0.5058 train_accuracy=0.4786 val_f1_score=0.3078 val_accuracy=0.2595\n",
      "\n",
      "Epoch 10, train_loss=1.5237 val_loss=1.8392 train_f1_score=0.5507 train_accuracy=0.5325 val_f1_score=0.3002 val_accuracy=0.2532\n",
      "\n",
      "Epoch 11, train_loss=1.4629 val_loss=1.8691 train_f1_score=0.5734 train_accuracy=0.5578 val_f1_score=0.3311 val_accuracy=0.2848\n",
      "\n",
      "Epoch 12, train_loss=1.4237 val_loss=1.8500 train_f1_score=0.6309 train_accuracy=0.6101 val_f1_score=0.3347 val_accuracy=0.2848\n",
      "\n",
      "Epoch 13, train_loss=1.3397 val_loss=1.8287 train_f1_score=0.6999 train_accuracy=0.6926 val_f1_score=0.2946 val_accuracy=0.2658\n",
      "\n",
      "Epoch 14, train_loss=1.2688 val_loss=1.8288 train_f1_score=0.7046 train_accuracy=0.6989 val_f1_score=0.3298 val_accuracy=0.2848\n",
      "\n",
      "Epoch 15, train_loss=1.2066 val_loss=1.8995 train_f1_score=0.7201 train_accuracy=0.7084 val_f1_score=0.2980 val_accuracy=0.2595\n",
      "\n",
      "Epoch 16, train_loss=1.1689 val_loss=1.8275 train_f1_score=0.7751 train_accuracy=0.7702 val_f1_score=0.3095 val_accuracy=0.2848\n",
      "\n",
      "Epoch 17, train_loss=1.0785 val_loss=1.8600 train_f1_score=0.8045 train_accuracy=0.8003 val_f1_score=0.3226 val_accuracy=0.2785\n",
      "\n",
      "Epoch 18, train_loss=1.0041 val_loss=1.8856 train_f1_score=0.8096 train_accuracy=0.8051 val_f1_score=0.2882 val_accuracy=0.2532\n",
      "\n",
      "Epoch 19, train_loss=0.9563 val_loss=1.8743 train_f1_score=0.8406 train_accuracy=0.8415 val_f1_score=0.3131 val_accuracy=0.2911\n",
      "\n",
      "Epoch 20, train_loss=0.9018 val_loss=1.8944 train_f1_score=0.8653 train_accuracy=0.8653 val_f1_score=0.2886 val_accuracy=0.2658\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=0.9018,val_loss=1.8944,train_f1_score=0.8653,train_accuracy=0.8653,val_f1_score=0.2886,val_accuracy=0.2658\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=SGD,loss=CrossEntropyLoss,activation=Tanh,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0864 val_loss=2.0942 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 2, train_loss=2.0863 val_loss=2.0941 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 3, train_loss=2.0860 val_loss=2.0940 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 4, train_loss=2.0857 val_loss=2.0939 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 5, train_loss=2.0859 val_loss=2.0938 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 6, train_loss=2.0853 val_loss=2.0936 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 7, train_loss=2.0850 val_loss=2.0935 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 8, train_loss=2.0850 val_loss=2.0934 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 9, train_loss=2.0847 val_loss=2.0933 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 10, train_loss=2.0845 val_loss=2.0931 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 11, train_loss=2.0842 val_loss=2.0930 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 12, train_loss=2.0839 val_loss=2.0929 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 13, train_loss=2.0841 val_loss=2.0928 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 14, train_loss=2.0837 val_loss=2.0926 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 15, train_loss=2.0835 val_loss=2.0925 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 16, train_loss=2.0833 val_loss=2.0924 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 17, train_loss=2.0834 val_loss=2.0923 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 18, train_loss=2.0828 val_loss=2.0921 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 19, train_loss=2.0827 val_loss=2.0920 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "Epoch 20, train_loss=2.0826 val_loss=2.0919 train_f1_score=0.2125 train_accuracy=0.1189 val_f1_score=0.1302 val_accuracy=0.0696\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.0826,val_loss=2.0919,train_f1_score=0.2125,train_accuracy=0.1189,val_f1_score=0.1302,val_accuracy=0.0696\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=RMSprop,loss=CrossEntropyLoss,activation=Tanh,dropout=0.0\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0351 val_loss=2.0669 train_f1_score=0.3661 train_accuracy=0.2314 val_f1_score=0.2908 val_accuracy=0.1709\n",
      "\n",
      "Epoch 2, train_loss=1.9666 val_loss=2.0260 train_f1_score=0.3949 train_accuracy=0.2900 val_f1_score=0.3214 val_accuracy=0.2278\n",
      "\n",
      "Epoch 3, train_loss=1.8951 val_loss=1.9912 train_f1_score=0.4318 train_accuracy=0.3677 val_f1_score=0.3151 val_accuracy=0.2278\n",
      "\n",
      "Epoch 4, train_loss=1.8287 val_loss=1.9786 train_f1_score=0.4616 train_accuracy=0.4136 val_f1_score=0.3221 val_accuracy=0.2468\n",
      "\n",
      "Epoch 5, train_loss=1.7297 val_loss=1.9573 train_f1_score=0.4936 train_accuracy=0.4437 val_f1_score=0.3342 val_accuracy=0.2595\n",
      "\n",
      "Epoch 6, train_loss=1.6793 val_loss=1.8953 train_f1_score=0.5110 train_accuracy=0.4865 val_f1_score=0.3560 val_accuracy=0.2975\n",
      "\n",
      "Epoch 7, train_loss=1.6058 val_loss=1.9610 train_f1_score=0.5665 train_accuracy=0.5341 val_f1_score=0.3210 val_accuracy=0.2532\n",
      "\n",
      "Epoch 8, train_loss=1.5452 val_loss=1.8921 train_f1_score=0.6097 train_accuracy=0.5864 val_f1_score=0.3246 val_accuracy=0.2785\n",
      "\n",
      "Epoch 9, train_loss=1.4777 val_loss=1.8711 train_f1_score=0.6203 train_accuracy=0.5959 val_f1_score=0.3233 val_accuracy=0.2785\n",
      "\n",
      "Epoch 10, train_loss=1.3941 val_loss=1.9050 train_f1_score=0.6381 train_accuracy=0.6165 val_f1_score=0.3363 val_accuracy=0.2848\n",
      "\n",
      "Epoch 11, train_loss=1.3110 val_loss=1.9414 train_f1_score=0.6478 train_accuracy=0.6307 val_f1_score=0.3030 val_accuracy=0.2595\n",
      "\n",
      "Epoch 12, train_loss=1.2453 val_loss=1.8729 train_f1_score=0.7425 train_accuracy=0.7353 val_f1_score=0.3379 val_accuracy=0.3165\n",
      "\n",
      "Epoch 13, train_loss=1.1873 val_loss=1.8808 train_f1_score=0.7295 train_accuracy=0.7195 val_f1_score=0.3774 val_accuracy=0.3165\n",
      "\n",
      "Epoch 14, train_loss=1.1376 val_loss=1.8932 train_f1_score=0.7131 train_accuracy=0.7116 val_f1_score=0.4169 val_accuracy=0.3608\n",
      "\n",
      "Epoch 15, train_loss=1.0492 val_loss=1.8850 train_f1_score=0.8104 train_accuracy=0.8035 val_f1_score=0.3774 val_accuracy=0.3354\n",
      "\n",
      "Epoch 16, train_loss=0.9818 val_loss=1.8704 train_f1_score=0.7967 train_accuracy=0.7987 val_f1_score=0.2836 val_accuracy=0.2658\n",
      "\n",
      "Epoch 17, train_loss=0.9023 val_loss=1.8359 train_f1_score=0.8390 train_accuracy=0.8352 val_f1_score=0.4167 val_accuracy=0.3861\n",
      "\n",
      "Epoch 18, train_loss=0.8939 val_loss=1.8993 train_f1_score=0.8142 train_accuracy=0.8130 val_f1_score=0.3491 val_accuracy=0.3101\n",
      "\n",
      "Epoch 19, train_loss=0.7930 val_loss=1.8899 train_f1_score=0.8652 train_accuracy=0.8669 val_f1_score=0.3888 val_accuracy=0.3544\n",
      "\n",
      "Epoch 20, train_loss=0.7480 val_loss=1.9144 train_f1_score=0.8894 train_accuracy=0.8891 val_f1_score=0.3100 val_accuracy=0.2975\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=0.7480,val_loss=1.9144,train_f1_score=0.8894,train_accuracy=0.8891,val_f1_score=0.3100,val_accuracy=0.2975\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=Adam,loss=CrossEntropyLoss,activation=Tanh,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0623 val_loss=2.0758 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 2, train_loss=2.0253 val_loss=2.0844 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 3, train_loss=1.9994 val_loss=2.0756 train_f1_score=0.3493 train_accuracy=0.2361 val_f1_score=0.2579 val_accuracy=0.1646\n",
      "\n",
      "Epoch 4, train_loss=1.9790 val_loss=2.0336 train_f1_score=0.3989 train_accuracy=0.3059 val_f1_score=0.2791 val_accuracy=0.2089\n",
      "\n",
      "Epoch 5, train_loss=1.9430 val_loss=2.0024 train_f1_score=0.3856 train_accuracy=0.2868 val_f1_score=0.3273 val_accuracy=0.2342\n",
      "\n",
      "Epoch 6, train_loss=1.8898 val_loss=2.0540 train_f1_score=0.3917 train_accuracy=0.2742 val_f1_score=0.2646 val_accuracy=0.1772\n",
      "\n",
      "Epoch 7, train_loss=1.8396 val_loss=2.0020 train_f1_score=0.4307 train_accuracy=0.3249 val_f1_score=0.2965 val_accuracy=0.2152\n",
      "\n",
      "Epoch 8, train_loss=1.7855 val_loss=1.9199 train_f1_score=0.4566 train_accuracy=0.4025 val_f1_score=0.2706 val_accuracy=0.2278\n",
      "\n",
      "Epoch 9, train_loss=1.7044 val_loss=1.9324 train_f1_score=0.4866 train_accuracy=0.4216 val_f1_score=0.3069 val_accuracy=0.2468\n",
      "\n",
      "Epoch 10, train_loss=1.6298 val_loss=1.9079 train_f1_score=0.5469 train_accuracy=0.5071 val_f1_score=0.3203 val_accuracy=0.2722\n",
      "\n",
      "Epoch 11, train_loss=1.5015 val_loss=1.9315 train_f1_score=0.5799 train_accuracy=0.5277 val_f1_score=0.3292 val_accuracy=0.2595\n",
      "\n",
      "Epoch 12, train_loss=1.3900 val_loss=1.8754 train_f1_score=0.6458 train_accuracy=0.6276 val_f1_score=0.3584 val_accuracy=0.3228\n",
      "\n",
      "Epoch 13, train_loss=1.2766 val_loss=1.9594 train_f1_score=0.6903 train_accuracy=0.6624 val_f1_score=0.3086 val_accuracy=0.2658\n",
      "\n",
      "Epoch 14, train_loss=1.1256 val_loss=1.9560 train_f1_score=0.7441 train_accuracy=0.7338 val_f1_score=0.3068 val_accuracy=0.2722\n",
      "\n",
      "Epoch 15, train_loss=0.9581 val_loss=2.0878 train_f1_score=0.8196 train_accuracy=0.8130 val_f1_score=0.2484 val_accuracy=0.2215\n",
      "\n",
      "Epoch 16, train_loss=0.8265 val_loss=2.1921 train_f1_score=0.8558 train_accuracy=0.8526 val_f1_score=0.2737 val_accuracy=0.2595\n",
      "\n",
      "Epoch 17, train_loss=0.6471 val_loss=2.2026 train_f1_score=0.8883 train_accuracy=0.8875 val_f1_score=0.2978 val_accuracy=0.2848\n",
      "\n",
      "Epoch 18, train_loss=0.5522 val_loss=2.2367 train_f1_score=0.9350 train_accuracy=0.9350 val_f1_score=0.3034 val_accuracy=0.2975\n",
      "\n",
      "Epoch 19, train_loss=0.4678 val_loss=2.2819 train_f1_score=0.9377 train_accuracy=0.9366 val_f1_score=0.2850 val_accuracy=0.2658\n",
      "\n",
      "Epoch 20, train_loss=0.4149 val_loss=2.4174 train_f1_score=0.9365 train_accuracy=0.9366 val_f1_score=0.2937 val_accuracy=0.2785\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=0.4149,val_loss=2.4174,train_f1_score=0.9365,train_accuracy=0.9366,val_f1_score=0.2937,val_accuracy=0.2785\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=SGD,loss=CrossEntropyLoss,activation=Tanh,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0823 val_loss=2.0861 train_f1_score=0.2981 train_accuracy=0.1823 val_f1_score=0.3411 val_accuracy=0.2215\n",
      "\n",
      "Epoch 2, train_loss=2.0778 val_loss=2.0845 train_f1_score=0.3173 train_accuracy=0.1886 val_f1_score=0.3452 val_accuracy=0.2089\n",
      "\n",
      "Epoch 3, train_loss=2.0758 val_loss=2.0828 train_f1_score=0.3173 train_accuracy=0.1886 val_f1_score=0.3452 val_accuracy=0.2089\n",
      "\n",
      "Epoch 4, train_loss=2.0738 val_loss=2.0810 train_f1_score=0.3173 train_accuracy=0.1886 val_f1_score=0.3452 val_accuracy=0.2089\n",
      "\n",
      "Epoch 5, train_loss=2.0708 val_loss=2.0794 train_f1_score=0.3173 train_accuracy=0.1886 val_f1_score=0.3455 val_accuracy=0.2089\n",
      "\n",
      "Epoch 6, train_loss=2.0663 val_loss=2.0778 train_f1_score=0.3173 train_accuracy=0.1886 val_f1_score=0.3455 val_accuracy=0.2089\n",
      "\n",
      "Epoch 7, train_loss=2.0649 val_loss=2.0764 train_f1_score=0.3172 train_accuracy=0.1886 val_f1_score=0.3455 val_accuracy=0.2089\n",
      "\n",
      "Epoch 8, train_loss=2.0619 val_loss=2.0751 train_f1_score=0.3170 train_accuracy=0.1902 val_f1_score=0.3455 val_accuracy=0.2089\n",
      "\n",
      "Epoch 9, train_loss=2.0610 val_loss=2.0736 train_f1_score=0.3118 train_accuracy=0.1902 val_f1_score=0.3448 val_accuracy=0.2089\n",
      "\n",
      "Epoch 10, train_loss=2.0579 val_loss=2.0722 train_f1_score=0.3097 train_accuracy=0.1918 val_f1_score=0.3448 val_accuracy=0.2089\n",
      "\n",
      "Epoch 11, train_loss=2.0538 val_loss=2.0708 train_f1_score=0.3045 train_accuracy=0.1949 val_f1_score=0.3352 val_accuracy=0.2089\n",
      "\n",
      "Epoch 12, train_loss=2.0501 val_loss=2.0695 train_f1_score=0.3073 train_accuracy=0.2029 val_f1_score=0.3246 val_accuracy=0.2025\n",
      "\n",
      "Epoch 13, train_loss=2.0517 val_loss=2.0684 train_f1_score=0.2948 train_accuracy=0.1997 val_f1_score=0.3243 val_accuracy=0.2025\n",
      "\n",
      "Epoch 14, train_loss=2.0478 val_loss=2.0673 train_f1_score=0.2990 train_accuracy=0.2060 val_f1_score=0.3069 val_accuracy=0.1962\n",
      "\n",
      "Epoch 15, train_loss=2.0466 val_loss=2.0659 train_f1_score=0.3147 train_accuracy=0.2235 val_f1_score=0.2682 val_accuracy=0.1772\n",
      "\n",
      "Epoch 16, train_loss=2.0423 val_loss=2.0648 train_f1_score=0.3257 train_accuracy=0.2330 val_f1_score=0.2788 val_accuracy=0.1899\n",
      "\n",
      "Epoch 17, train_loss=2.0421 val_loss=2.0638 train_f1_score=0.3458 train_accuracy=0.2472 val_f1_score=0.3037 val_accuracy=0.2089\n",
      "\n",
      "Epoch 18, train_loss=2.0399 val_loss=2.0628 train_f1_score=0.3461 train_accuracy=0.2472 val_f1_score=0.3119 val_accuracy=0.2152\n",
      "\n",
      "Epoch 19, train_loss=2.0381 val_loss=2.0618 train_f1_score=0.3552 train_accuracy=0.2536 val_f1_score=0.3117 val_accuracy=0.2152\n",
      "\n",
      "Epoch 20, train_loss=2.0357 val_loss=2.0609 train_f1_score=0.3564 train_accuracy=0.2536 val_f1_score=0.3031 val_accuracy=0.2089\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.0357,val_loss=2.0609,train_f1_score=0.3564,train_accuracy=0.2536,val_f1_score=0.3031,val_accuracy=0.2089\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=RMSprop,loss=CrossEntropyLoss,activation=Tanh,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.1146 val_loss=2.1740 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 2, train_loss=2.0708 val_loss=2.1221 train_f1_score=0.3173 train_accuracy=0.1886 val_f1_score=0.3455 val_accuracy=0.2089\n",
      "\n",
      "Epoch 3, train_loss=2.0632 val_loss=2.0729 train_f1_score=0.3624 train_accuracy=0.2282 val_f1_score=0.2808 val_accuracy=0.1646\n",
      "\n",
      "Epoch 4, train_loss=2.0547 val_loss=2.1154 train_f1_score=0.3602 train_accuracy=0.2456 val_f1_score=0.2960 val_accuracy=0.1962\n",
      "\n",
      "Epoch 5, train_loss=2.0776 val_loss=2.0754 train_f1_score=0.3173 train_accuracy=0.1886 val_f1_score=0.3455 val_accuracy=0.2089\n",
      "\n",
      "Epoch 6, train_loss=2.0456 val_loss=2.1139 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 7, train_loss=2.0537 val_loss=2.1275 train_f1_score=0.3173 train_accuracy=0.1886 val_f1_score=0.3455 val_accuracy=0.2089\n",
      "\n",
      "Epoch 8, train_loss=2.0391 val_loss=2.1172 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 9, train_loss=2.0460 val_loss=2.1086 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 10, train_loss=2.0318 val_loss=2.0862 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 11, train_loss=2.0389 val_loss=2.0796 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 12, train_loss=2.0338 val_loss=2.0787 train_f1_score=0.3173 train_accuracy=0.1886 val_f1_score=0.3455 val_accuracy=0.2089\n",
      "\n",
      "Epoch 13, train_loss=2.0335 val_loss=2.0956 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 14, train_loss=2.0365 val_loss=2.0810 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 15, train_loss=2.0293 val_loss=2.0649 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 16, train_loss=2.0306 val_loss=2.0835 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 17, train_loss=2.0257 val_loss=2.0752 train_f1_score=0.3173 train_accuracy=0.1886 val_f1_score=0.3455 val_accuracy=0.2089\n",
      "\n",
      "Epoch 18, train_loss=2.0235 val_loss=2.0946 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 19, train_loss=2.0545 val_loss=2.0666 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "Epoch 20, train_loss=2.0322 val_loss=2.0892 train_f1_score=0.3653 train_accuracy=0.2235 val_f1_score=0.2919 val_accuracy=0.1709\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.0322,val_loss=2.0892,train_f1_score=0.3653,train_accuracy=0.2235,val_f1_score=0.2919,val_accuracy=0.1709\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=Adam,loss=CrossEntropyLoss,activation=Tanh,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0161 val_loss=2.0566 train_f1_score=0.3368 train_accuracy=0.2393 val_f1_score=0.2490 val_accuracy=0.1709\n",
      "\n",
      "Epoch 2, train_loss=1.9706 val_loss=2.0306 train_f1_score=0.3389 train_accuracy=0.2456 val_f1_score=0.2953 val_accuracy=0.2025\n",
      "\n",
      "Epoch 3, train_loss=1.9206 val_loss=1.9824 train_f1_score=0.4019 train_accuracy=0.2884 val_f1_score=0.3201 val_accuracy=0.2215\n",
      "\n",
      "Epoch 4, train_loss=1.8931 val_loss=1.9549 train_f1_score=0.4121 train_accuracy=0.3265 val_f1_score=0.3027 val_accuracy=0.2152\n",
      "\n",
      "Epoch 5, train_loss=1.8447 val_loss=1.9125 train_f1_score=0.4348 train_accuracy=0.3613 val_f1_score=0.3024 val_accuracy=0.2342\n",
      "\n",
      "Epoch 6, train_loss=1.8064 val_loss=1.8867 train_f1_score=0.4481 train_accuracy=0.4025 val_f1_score=0.3258 val_accuracy=0.2785\n",
      "\n",
      "Epoch 7, train_loss=1.7610 val_loss=1.8700 train_f1_score=0.4663 train_accuracy=0.4279 val_f1_score=0.3224 val_accuracy=0.2722\n",
      "\n",
      "Epoch 8, train_loss=1.7442 val_loss=1.8414 train_f1_score=0.4788 train_accuracy=0.4453 val_f1_score=0.3720 val_accuracy=0.3165\n",
      "\n",
      "Epoch 9, train_loss=1.6870 val_loss=1.8525 train_f1_score=0.5061 train_accuracy=0.4770 val_f1_score=0.3372 val_accuracy=0.2911\n",
      "\n",
      "Epoch 10, train_loss=1.6647 val_loss=1.8428 train_f1_score=0.4938 train_accuracy=0.4517 val_f1_score=0.3438 val_accuracy=0.2848\n",
      "\n",
      "Epoch 11, train_loss=1.6189 val_loss=1.8167 train_f1_score=0.5743 train_accuracy=0.5578 val_f1_score=0.3556 val_accuracy=0.3291\n",
      "\n",
      "Epoch 12, train_loss=1.5654 val_loss=1.8122 train_f1_score=0.5955 train_accuracy=0.5705 val_f1_score=0.3658 val_accuracy=0.3354\n",
      "\n",
      "Epoch 13, train_loss=1.5001 val_loss=1.7955 train_f1_score=0.6031 train_accuracy=0.5816 val_f1_score=0.3409 val_accuracy=0.3101\n",
      "\n",
      "Epoch 14, train_loss=1.4575 val_loss=1.8093 train_f1_score=0.6274 train_accuracy=0.6086 val_f1_score=0.3352 val_accuracy=0.3165\n",
      "\n",
      "Epoch 15, train_loss=1.4226 val_loss=1.7808 train_f1_score=0.6513 train_accuracy=0.6355 val_f1_score=0.3529 val_accuracy=0.3228\n",
      "\n",
      "Epoch 16, train_loss=1.3828 val_loss=1.8251 train_f1_score=0.6410 train_accuracy=0.6197 val_f1_score=0.3467 val_accuracy=0.2975\n",
      "\n",
      "Epoch 17, train_loss=1.3192 val_loss=1.7787 train_f1_score=0.7145 train_accuracy=0.6989 val_f1_score=0.3572 val_accuracy=0.3291\n",
      "\n",
      "Epoch 18, train_loss=1.2581 val_loss=1.7777 train_f1_score=0.7352 train_accuracy=0.7258 val_f1_score=0.3298 val_accuracy=0.3165\n",
      "\n",
      "Epoch 19, train_loss=1.2046 val_loss=1.7769 train_f1_score=0.7756 train_accuracy=0.7655 val_f1_score=0.3536 val_accuracy=0.3418\n",
      "\n",
      "Epoch 20, train_loss=1.1323 val_loss=1.7868 train_f1_score=0.7978 train_accuracy=0.7940 val_f1_score=0.3577 val_accuracy=0.3418\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=1.1323,val_loss=1.7868,train_f1_score=0.7978,train_accuracy=0.7940,val_f1_score=0.3577,val_accuracy=0.3418\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=SGD,loss=CrossEntropyLoss,activation=Tanh,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=2.0973 val_loss=2.0976 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 2, train_loss=2.0969 val_loss=2.0975 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 3, train_loss=2.0972 val_loss=2.0973 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 4, train_loss=2.0950 val_loss=2.0972 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 5, train_loss=2.0960 val_loss=2.0971 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 6, train_loss=2.0964 val_loss=2.0970 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 7, train_loss=2.0958 val_loss=2.0968 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 8, train_loss=2.0966 val_loss=2.0967 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 9, train_loss=2.0970 val_loss=2.0966 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 10, train_loss=2.0956 val_loss=2.0965 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 11, train_loss=2.0943 val_loss=2.0964 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 12, train_loss=2.0948 val_loss=2.0963 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 13, train_loss=2.0938 val_loss=2.0962 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 14, train_loss=2.0951 val_loss=2.0961 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 15, train_loss=2.0954 val_loss=2.0960 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 16, train_loss=2.0951 val_loss=2.0958 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 17, train_loss=2.0961 val_loss=2.0957 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 18, train_loss=2.0951 val_loss=2.0956 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 19, train_loss=2.0942 val_loss=2.0955 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "Epoch 20, train_loss=2.0928 val_loss=2.0954 train_f1_score=0.1657 train_accuracy=0.0903 val_f1_score=0.1734 val_accuracy=0.0949\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=2.0928,val_loss=2.0954,train_f1_score=0.1657,train_accuracy=0.0903,val_f1_score=0.1734,val_accuracy=0.0949\n",
      "\n",
      "\n",
      "\n",
      "\tTraining optimizer=RMSprop,loss=CrossEntropyLoss,activation=Tanh,dropout=0.2\n",
      "\n",
      "Started Trianing ...\n",
      "\n",
      "Epoch 1, train_loss=1.9889 val_loss=2.0318 train_f1_score=0.2860 train_accuracy=0.2282 val_f1_score=0.2502 val_accuracy=0.1899\n",
      "\n",
      "Epoch 2, train_loss=1.8969 val_loss=1.9903 train_f1_score=0.3160 train_accuracy=0.2536 val_f1_score=0.2698 val_accuracy=0.2089\n",
      "\n",
      "Epoch 3, train_loss=1.8404 val_loss=1.9281 train_f1_score=0.4025 train_accuracy=0.3423 val_f1_score=0.3271 val_accuracy=0.2658\n",
      "\n",
      "Epoch 4, train_loss=1.7760 val_loss=1.8940 train_f1_score=0.4495 train_accuracy=0.3677 val_f1_score=0.3417 val_accuracy=0.2658\n",
      "\n",
      "Epoch 5, train_loss=1.7205 val_loss=1.9060 train_f1_score=0.4661 train_accuracy=0.4073 val_f1_score=0.3392 val_accuracy=0.2785\n",
      "\n",
      "Epoch 6, train_loss=1.6844 val_loss=1.8528 train_f1_score=0.5043 train_accuracy=0.4834 val_f1_score=0.3628 val_accuracy=0.3228\n",
      "\n",
      "Epoch 7, train_loss=1.6163 val_loss=1.8430 train_f1_score=0.5192 train_accuracy=0.4945 val_f1_score=0.3485 val_accuracy=0.3038\n",
      "\n",
      "Epoch 8, train_loss=1.5714 val_loss=1.8961 train_f1_score=0.5291 train_accuracy=0.4897 val_f1_score=0.3181 val_accuracy=0.2595\n",
      "\n",
      "Epoch 9, train_loss=1.4978 val_loss=1.8507 train_f1_score=0.4861 train_accuracy=0.4897 val_f1_score=0.3017 val_accuracy=0.2911\n",
      "\n",
      "Epoch 10, train_loss=1.4811 val_loss=1.8880 train_f1_score=0.5400 train_accuracy=0.5151 val_f1_score=0.3616 val_accuracy=0.3038\n",
      "\n",
      "Epoch 11, train_loss=1.4253 val_loss=1.8575 train_f1_score=0.5956 train_accuracy=0.5705 val_f1_score=0.3149 val_accuracy=0.2722\n",
      "\n",
      "Epoch 12, train_loss=1.3395 val_loss=1.8284 train_f1_score=0.6815 train_accuracy=0.6719 val_f1_score=0.3552 val_accuracy=0.3291\n",
      "\n",
      "Epoch 13, train_loss=1.3180 val_loss=1.8441 train_f1_score=0.6671 train_accuracy=0.6545 val_f1_score=0.2963 val_accuracy=0.2785\n",
      "\n",
      "Epoch 14, train_loss=1.2682 val_loss=1.7917 train_f1_score=0.7054 train_accuracy=0.6989 val_f1_score=0.3526 val_accuracy=0.3291\n",
      "\n",
      "Epoch 15, train_loss=1.1940 val_loss=1.8719 train_f1_score=0.7217 train_accuracy=0.7132 val_f1_score=0.2608 val_accuracy=0.2468\n",
      "\n",
      "Epoch 16, train_loss=1.1212 val_loss=1.8548 train_f1_score=0.7598 train_accuracy=0.7559 val_f1_score=0.3096 val_accuracy=0.3038\n",
      "\n",
      "Epoch 17, train_loss=1.1391 val_loss=1.8245 train_f1_score=0.7730 train_accuracy=0.7686 val_f1_score=0.3340 val_accuracy=0.3228\n",
      "\n",
      "Epoch 18, train_loss=1.0239 val_loss=1.8940 train_f1_score=0.7463 train_accuracy=0.7480 val_f1_score=0.3029 val_accuracy=0.2848\n",
      "\n",
      "Epoch 19, train_loss=0.9911 val_loss=1.8762 train_f1_score=0.7913 train_accuracy=0.7940 val_f1_score=0.3078 val_accuracy=0.2911\n",
      "\n",
      "Epoch 20, train_loss=0.9252 val_loss=1.8456 train_f1_score=0.8457 train_accuracy=0.8447 val_f1_score=0.3207 val_accuracy=0.3101\n",
      "\n",
      "\n",
      "\n",
      "Finished Training with metrics = train_loss=0.9252,val_loss=1.8456,train_f1_score=0.8457,train_accuracy=0.8447,val_f1_score=0.3207,val_accuracy=0.3101\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_f1_score</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>1.5243</td>\n",
       "      <td>1.9079</td>\n",
       "      <td>0.5205</td>\n",
       "      <td>0.4881</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>0.2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>2.0778</td>\n",
       "      <td>2.0835</td>\n",
       "      <td>0.1893</td>\n",
       "      <td>0.1078</td>\n",
       "      <td>0.1719</td>\n",
       "      <td>0.0949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>1.4207</td>\n",
       "      <td>1.9114</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.5737</td>\n",
       "      <td>0.2899</td>\n",
       "      <td>0.2658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>2.0582</td>\n",
       "      <td>0.7313</td>\n",
       "      <td>0.7021</td>\n",
       "      <td>0.3352</td>\n",
       "      <td>0.3165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>2.0671</td>\n",
       "      <td>2.0601</td>\n",
       "      <td>0.3546</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>1.6525</td>\n",
       "      <td>1.9678</td>\n",
       "      <td>0.4574</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.3548</td>\n",
       "      <td>0.2785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>1.7553</td>\n",
       "      <td>1.9041</td>\n",
       "      <td>0.4551</td>\n",
       "      <td>0.3597</td>\n",
       "      <td>0.2911</td>\n",
       "      <td>0.2215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>2.0754</td>\n",
       "      <td>2.0714</td>\n",
       "      <td>0.3546</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>1.5877</td>\n",
       "      <td>1.7798</td>\n",
       "      <td>0.5424</td>\n",
       "      <td>0.5135</td>\n",
       "      <td>0.3916</td>\n",
       "      <td>0.3481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>1.0029</td>\n",
       "      <td>1.9095</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>0.8130</td>\n",
       "      <td>0.3886</td>\n",
       "      <td>0.3861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>2.0582</td>\n",
       "      <td>2.0471</td>\n",
       "      <td>0.3546</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>1.7509</td>\n",
       "      <td>2.0101</td>\n",
       "      <td>0.3774</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.2199</td>\n",
       "      <td>0.1899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>1.9903</td>\n",
       "      <td>1.9906</td>\n",
       "      <td>0.3546</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>2.1424</td>\n",
       "      <td>2.1402</td>\n",
       "      <td>0.1684</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>0.1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>1.9268</td>\n",
       "      <td>1.9455</td>\n",
       "      <td>0.4407</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.4020</td>\n",
       "      <td>0.2848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>1.8815</td>\n",
       "      <td>2.0359</td>\n",
       "      <td>0.4142</td>\n",
       "      <td>0.3043</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>0.2152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>2.0468</td>\n",
       "      <td>2.0628</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>1.7947</td>\n",
       "      <td>1.8255</td>\n",
       "      <td>0.4368</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>0.3998</td>\n",
       "      <td>0.2848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>2.0040</td>\n",
       "      <td>1.9968</td>\n",
       "      <td>0.3546</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>2.2395</td>\n",
       "      <td>2.2334</td>\n",
       "      <td>0.1684</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>0.1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>1.9606</td>\n",
       "      <td>1.9355</td>\n",
       "      <td>0.3546</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>1.8667</td>\n",
       "      <td>2.0185</td>\n",
       "      <td>0.4203</td>\n",
       "      <td>0.3122</td>\n",
       "      <td>0.2901</td>\n",
       "      <td>0.2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>2.0712</td>\n",
       "      <td>2.0608</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>optimizer=type,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>2.0265</td>\n",
       "      <td>2.0026</td>\n",
       "      <td>0.3546</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>optimizer=Adam,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>0.2897</td>\n",
       "      <td>2.4998</td>\n",
       "      <td>0.9587</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.2823</td>\n",
       "      <td>0.2785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>optimizer=SGD,loss=CrossEntropyLoss,activation...</td>\n",
       "      <td>2.0704</td>\n",
       "      <td>2.0766</td>\n",
       "      <td>0.2356</td>\n",
       "      <td>0.1585</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.1329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>optimizer=RMSprop,loss=CrossEntropyLoss,activa...</td>\n",
       "      <td>1.4096</td>\n",
       "      <td>2.1570</td>\n",
       "      <td>0.5643</td>\n",
       "      <td>0.5388</td>\n",
       "      <td>0.2734</td>\n",
       "      <td>0.2405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>optimizer=Adam,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>1.8944</td>\n",
       "      <td>0.8653</td>\n",
       "      <td>0.8653</td>\n",
       "      <td>0.2886</td>\n",
       "      <td>0.2658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>optimizer=SGD,loss=CrossEntropyLoss,activation...</td>\n",
       "      <td>2.0826</td>\n",
       "      <td>2.0919</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.0696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>optimizer=RMSprop,loss=CrossEntropyLoss,activa...</td>\n",
       "      <td>0.7480</td>\n",
       "      <td>1.9144</td>\n",
       "      <td>0.8894</td>\n",
       "      <td>0.8891</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>optimizer=Adam,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>0.4149</td>\n",
       "      <td>2.4174</td>\n",
       "      <td>0.9365</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.2785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>optimizer=SGD,loss=CrossEntropyLoss,activation...</td>\n",
       "      <td>2.0357</td>\n",
       "      <td>2.0609</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.2536</td>\n",
       "      <td>0.3031</td>\n",
       "      <td>0.2089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>optimizer=RMSprop,loss=CrossEntropyLoss,activa...</td>\n",
       "      <td>2.0322</td>\n",
       "      <td>2.0892</td>\n",
       "      <td>0.3653</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.2919</td>\n",
       "      <td>0.1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>optimizer=Adam,loss=CrossEntropyLoss,activatio...</td>\n",
       "      <td>1.1323</td>\n",
       "      <td>1.7868</td>\n",
       "      <td>0.7978</td>\n",
       "      <td>0.7940</td>\n",
       "      <td>0.3577</td>\n",
       "      <td>0.3418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>optimizer=SGD,loss=CrossEntropyLoss,activation...</td>\n",
       "      <td>2.0928</td>\n",
       "      <td>2.0954</td>\n",
       "      <td>0.1657</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.1734</td>\n",
       "      <td>0.0949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>optimizer=RMSprop,loss=CrossEntropyLoss,activa...</td>\n",
       "      <td>0.9252</td>\n",
       "      <td>1.8456</td>\n",
       "      <td>0.8457</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.3101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name train_loss val_loss  \\\n",
       "0   optimizer=type,loss=CrossEntropyLoss,activatio...     1.5243   1.9079   \n",
       "1   optimizer=type,loss=CrossEntropyLoss,activatio...     2.0778   2.0835   \n",
       "2   optimizer=type,loss=CrossEntropyLoss,activatio...     1.4207   1.9114   \n",
       "3   optimizer=type,loss=CrossEntropyLoss,activatio...     0.9671   2.0582   \n",
       "4   optimizer=type,loss=CrossEntropyLoss,activatio...     2.0671   2.0601   \n",
       "5   optimizer=type,loss=CrossEntropyLoss,activatio...     1.6525   1.9678   \n",
       "6   optimizer=type,loss=CrossEntropyLoss,activatio...     1.7553   1.9041   \n",
       "7   optimizer=type,loss=CrossEntropyLoss,activatio...     2.0754   2.0714   \n",
       "8   optimizer=type,loss=CrossEntropyLoss,activatio...     1.5877   1.7798   \n",
       "9   optimizer=type,loss=CrossEntropyLoss,activatio...     1.0029   1.9095   \n",
       "10  optimizer=type,loss=CrossEntropyLoss,activatio...     2.0582   2.0471   \n",
       "11  optimizer=type,loss=CrossEntropyLoss,activatio...     1.7509   2.0101   \n",
       "12  optimizer=type,loss=CrossEntropyLoss,activatio...     1.9903   1.9906   \n",
       "13  optimizer=type,loss=CrossEntropyLoss,activatio...     2.1424   2.1402   \n",
       "14  optimizer=type,loss=CrossEntropyLoss,activatio...     1.9268   1.9455   \n",
       "15  optimizer=type,loss=CrossEntropyLoss,activatio...     1.8815   2.0359   \n",
       "16  optimizer=type,loss=CrossEntropyLoss,activatio...     2.0468   2.0628   \n",
       "17  optimizer=type,loss=CrossEntropyLoss,activatio...     1.7947   1.8255   \n",
       "18  optimizer=type,loss=CrossEntropyLoss,activatio...     2.0040   1.9968   \n",
       "19  optimizer=type,loss=CrossEntropyLoss,activatio...     2.2395   2.2334   \n",
       "20  optimizer=type,loss=CrossEntropyLoss,activatio...     1.9606   1.9355   \n",
       "21  optimizer=type,loss=CrossEntropyLoss,activatio...     1.8667   2.0185   \n",
       "22  optimizer=type,loss=CrossEntropyLoss,activatio...     2.0712   2.0608   \n",
       "23  optimizer=type,loss=CrossEntropyLoss,activatio...     2.0265   2.0026   \n",
       "24  optimizer=Adam,loss=CrossEntropyLoss,activatio...     0.2897   2.4998   \n",
       "25  optimizer=SGD,loss=CrossEntropyLoss,activation...     2.0704   2.0766   \n",
       "26  optimizer=RMSprop,loss=CrossEntropyLoss,activa...     1.4096   2.1570   \n",
       "27  optimizer=Adam,loss=CrossEntropyLoss,activatio...     0.9018   1.8944   \n",
       "28  optimizer=SGD,loss=CrossEntropyLoss,activation...     2.0826   2.0919   \n",
       "29  optimizer=RMSprop,loss=CrossEntropyLoss,activa...     0.7480   1.9144   \n",
       "30  optimizer=Adam,loss=CrossEntropyLoss,activatio...     0.4149   2.4174   \n",
       "31  optimizer=SGD,loss=CrossEntropyLoss,activation...     2.0357   2.0609   \n",
       "32  optimizer=RMSprop,loss=CrossEntropyLoss,activa...     2.0322   2.0892   \n",
       "33  optimizer=Adam,loss=CrossEntropyLoss,activatio...     1.1323   1.7868   \n",
       "34  optimizer=SGD,loss=CrossEntropyLoss,activation...     2.0928   2.0954   \n",
       "35  optimizer=RMSprop,loss=CrossEntropyLoss,activa...     0.9252   1.8456   \n",
       "\n",
       "   train_f1_score train_accuracy val_f1_score val_accuracy  \n",
       "0          0.5205         0.4881       0.3340       0.2975  \n",
       "1          0.1893         0.1078       0.1719       0.0949  \n",
       "2          0.5914         0.5737       0.2899       0.2658  \n",
       "3          0.7313         0.7021       0.3352       0.3165  \n",
       "4          0.3546         0.2155       0.3368       0.2025  \n",
       "5          0.4574         0.3740       0.3548       0.2785  \n",
       "6          0.4551         0.3597       0.2911       0.2215  \n",
       "7          0.3546         0.2155       0.3368       0.2025  \n",
       "8          0.5424         0.5135       0.3916       0.3481  \n",
       "9          0.8145         0.8130       0.3886       0.3861  \n",
       "10         0.3546         0.2155       0.3368       0.2025  \n",
       "11         0.3774         0.3185       0.2199       0.1899  \n",
       "12         0.3546         0.2155       0.3368       0.2025  \n",
       "13         0.1684         0.0919       0.2045       0.1139  \n",
       "14         0.4407         0.3185       0.4020       0.2848  \n",
       "15         0.4142         0.3043       0.3077       0.2152  \n",
       "16         0.3196         0.1902       0.3368       0.2025  \n",
       "17         0.4368         0.3170       0.3998       0.2848  \n",
       "18         0.3546         0.2155       0.3368       0.2025  \n",
       "19         0.1684         0.0919       0.2045       0.1139  \n",
       "20         0.3546         0.2155       0.3368       0.2025  \n",
       "21         0.4203         0.3122       0.2901       0.2025  \n",
       "22         0.3196         0.1902       0.3368       0.2025  \n",
       "23         0.3546         0.2155       0.3368       0.2025  \n",
       "24         0.9587         0.9588       0.2823       0.2785  \n",
       "25         0.2356         0.1585       0.2083       0.1329  \n",
       "26         0.5643         0.5388       0.2734       0.2405  \n",
       "27         0.8653         0.8653       0.2886       0.2658  \n",
       "28         0.2125         0.1189       0.1302       0.0696  \n",
       "29         0.8894         0.8891       0.3100       0.2975  \n",
       "30         0.9365         0.9366       0.2937       0.2785  \n",
       "31         0.3564         0.2536       0.3031       0.2089  \n",
       "32         0.3653         0.2235       0.2919       0.1709  \n",
       "33         0.7978         0.7940       0.3577       0.3418  \n",
       "34         0.1657         0.0903       0.1734       0.0949  \n",
       "35         0.8457         0.8447       0.3207       0.3101  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "result = collections.defaultdict(list)\n",
    "temp = collections.defaultdict(list)\n",
    "\n",
    "x = open(\"logs\", \"r\").readlines()\n",
    "for line in x:\n",
    "    print(line)\n",
    "    line = line.strip()\n",
    "    if line.startswith(\"Training\"):\n",
    "#         print(line)\n",
    "        for k, v in temp.items():\n",
    "            result[k].append(v[-1])\n",
    "        name = line.split(\" \")[-1]\n",
    "        result[\"name\"].append(name)\n",
    "        temp = collections.defaultdict(list)\n",
    "        \n",
    "    elif line.startswith(\"Epoch\"):\n",
    "        for a in line.split(\" \")[2:]:\n",
    "#             print(a)\n",
    "            k, v = a.split(\"=\")[0], a.split(\"=\")[1]\n",
    "            temp[k].append(v)\n",
    "        \n",
    "for k, v in temp.items():\n",
    "    result[k].append(v[-1])\n",
    "\n",
    "df = pd.DataFrame.from_dict(result)\n",
    "df.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98414584",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import collections\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "\n",
    "result = collections.defaultdict(list)\n",
    "temp = collections.defaultdict(list)    \n",
    "x = open(\"data_prep/logs\", \"r\").readlines()\n",
    "i = 0\n",
    "for line in x:\n",
    "    print(line.replace(\"\\n\", ''))\n",
    "    line = line.strip()\n",
    "    if line.startswith(\"Training\"):\n",
    "#         print(line)\n",
    "        for k, v in temp.items():\n",
    "            result[k].append(v[-1])\n",
    "        name = line.split(\" \")[-1]\n",
    "        result[\"name\"].append(name)\n",
    "        temp = collections.defaultdict(list)\n",
    "        \n",
    "    elif line.startswith(\"Epoch\"):\n",
    "        for a in line.split(\" \")[2:]:\n",
    "            k, v = a.split(\"=\")[0], a.split(\"=\")[1]\n",
    "            temp[k].append(v)\n",
    "            \n",
    "    if line.startswith(\"Finished\"):\n",
    "        plt.figure(figsize=(15, 8))  # Adjust width and height as needed\n",
    "\n",
    "        # Load the image using matplotlib.image\n",
    "        img = mpimg.imread(f'data_prep/images/download-{i}.png')\n",
    "\n",
    "        # Display the image using matplotlib.pyplot\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')  # Turn off axis labels and ticks\n",
    "        plt.show()\n",
    "        i += 1\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
